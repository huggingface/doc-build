import{S as Vt,i as Wt,s as Xt,e as o,k as m,w as C,t as s,M as Yt,c as l,d as t,m as c,a as n,x as D,h as r,b as f,G as a,g as i,y as q,q as z,o as L,B as I,v as Zt}from"../chunks/vendor-hf-doc-builder.js";import{T as es}from"../chunks/Tip-hf-doc-builder.js";import{I as vt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Se}from"../chunks/CodeBlock-hf-doc-builder.js";function as(Ne){let h,B,u,y,x,_,X,j,$,S,E,b,N,w;return{c(){h=o("p"),B=s("The following example uses "),u=o("a"),y=s("torchvision"),x=s(", but feel free to use other data augmentation libraries like "),_=o("a"),X=s("Albumentations"),j=s(", "),$=o("a"),S=s("Kornia"),E=s(", and "),b=o("a"),N=s("imgaug"),w=s("."),this.h()},l(g){h=l(g,"P",{});var d=n(h);B=r(d,"The following example uses "),u=l(d,"A",{href:!0,rel:!0});var A=n(u);y=r(A,"torchvision"),A.forEach(t),x=r(d,", but feel free to use other data augmentation libraries like "),_=l(d,"A",{href:!0,rel:!0});var fe=n(_);X=r(fe,"Albumentations"),fe.forEach(t),j=r(d,", "),$=l(d,"A",{href:!0,rel:!0});var me=n($);S=r(me,"Kornia"),me.forEach(t),E=r(d,", and "),b=l(d,"A",{href:!0,rel:!0});var ce=n(b);N=r(ce,"imgaug"),ce.forEach(t),w=r(d,"."),d.forEach(t),this.h()},h(){f(u,"href","https://pytorch.org/vision/stable/index.html"),f(u,"rel","nofollow"),f(_,"href","https://albumentations.ai/docs/"),f(_,"rel","nofollow"),f($,"href","https://kornia.readthedocs.io/en/latest/"),f($,"rel","nofollow"),f(b,"href","https://imgaug.readthedocs.io/en/latest/"),f(b,"rel","nofollow")},m(g,d){i(g,h,d),a(h,B),a(h,u),a(u,y),a(h,x),a(h,_),a(_,X),a(h,j),a(h,$),a($,S),a(h,E),a(h,b),a(b,N),a(h,w)},d(g){g&&t(h)}}}function ts(Ne){let h,B,u,y,x,_,X,j,$,S,E,b,N,w,g,d,A,fe,me,ce,Y,wa,he,$a,ba,Re,R,Ea,Z,ka,xa,Fe,P,F,je,ee,ja,Ae,Aa,Oe,O,Pa,ue,Ta,Ca,Je,J,Da,ae,Pe,qa,za,Ge,te,Me,v,La,de,Ia,Ba,Te,Sa,Na,Ce,Ra,Fa,De,Oa,Ja,Ue,se,He,G,Ga,_e,Ma,Ua,Ke,re,ve,Ha,Ka,Qe,M,ge,ye,qe,Qa,Va,Wa,we,$e,ze,Xa,Ya,Ve,U,Za,be,et,at,We,T,H,Le,oe,tt,Ie,st,Xe,K,rt,Ee,ot,lt,Ye,Q,Ze,ke,nt,ea,le,aa,V,pt,Be,it,ft,ta,ne,sa,W,mt,xe,ct,ht,ra,pe,oa;return _=new vt({}),ee=new vt({}),te=new Se({props:{code:`def transforms(examples):
    examples["pixel_values"] = [image.convert("RGB").resize((100,100)) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [image.convert(<span class="hljs-string">&quot;RGB&quot;</span>).resize((<span class="hljs-number">100</span>,<span class="hljs-number">100</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),se=new Se({props:{code:`dataset = dataset.map(transforms, remove_columns=["image"], batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(transforms, remove_columns=[<span class="hljs-string">&quot;image&quot;</span>], batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at <span class="hljs-number">0x7F058237BB10</span>&gt;}`}}),oe=new vt({}),Q=new es({props:{$$slots:{default:[as]},$$scope:{ctx:Ne}}}),le=new Se({props:{code:`from torchvision.transforms import Compose, ColorJitter, ToTensor

jitter = Compose(
    [
         ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
         ToTensor(),
    ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>         ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.7</span>),
<span class="hljs-meta">... </span>         ToTensor(),
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)`}}),ne=new Se({props:{code:`def transforms(examples):
    examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),pe=new Se({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),{c(){h=o("meta"),B=m(),u=o("h1"),y=o("a"),x=o("span"),C(_.$$.fragment),X=m(),j=o("span"),$=s("Process image data"),S=m(),E=o("p"),b=s("This guide shows specific methods for processing image datasets. Learn how to:"),N=m(),w=o("ul"),g=o("li"),d=s("Use "),A=o("a"),fe=s("map()"),me=s(" with image dataset."),ce=m(),Y=o("li"),wa=s("Apply data augmentations to a dataset with "),he=o("a"),$a=s("set_transform()"),ba=s("."),Re=m(),R=o("p"),Ea=s("For a guide on how to process any type of dataset, take a look at the "),Z=o("a"),ka=s("general process guide"),xa=s("."),Fe=m(),P=o("h2"),F=o("a"),je=o("span"),C(ee.$$.fragment),ja=m(),Ae=o("span"),Aa=s("Map"),Oe=m(),O=o("p"),Pa=s("The "),ue=o("a"),Ta=s("map()"),Ca=s(" function can apply transforms over an entire dataset."),Je=m(),J=o("p"),Da=s("For example, create a basic "),ae=o("a"),Pe=o("code"),qa=s("Resize"),za=s(" function:"),Ge=m(),C(te.$$.fragment),Me=m(),v=o("p"),La=s("Now use the "),de=o("a"),Ia=s("map()"),Ba=s(" function to resize the entire dataset, and set "),Te=o("code"),Sa=s("batched=True"),Na=s(" to speed up the process by accepting batches of examples. The transform returns "),Ce=o("code"),Ra=s("pixel_values"),Fa=s(" as a cacheable "),De=o("code"),Oa=s("PIL.Image"),Ja=s(" object:"),Ue=m(),C(se.$$.fragment),He=m(),G=o("p"),Ga=s("The cache file saves time because you don\u2019t have to execute the same transform twice. The "),_e=o("a"),Ma=s("map()"),Ua=s(" function is best for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),Ke=m(),re=o("p"),ve=o("a"),Ha=s("map()"),Ka=s(" takes up some memory, but you can reduce its memory requirements with the following parameters:"),Qe=m(),M=o("ul"),ge=o("li"),ye=o("a"),qe=o("code"),Qa=s("batch_size"),Va=s(" determines the number of examples that are processed in one call to the transform function."),Wa=m(),we=o("li"),$e=o("a"),ze=o("code"),Xa=s("writer_batch_size"),Ya=s(" determines the number of processed examples that are kept in memory before they are stored away."),Ve=m(),U=o("p"),Za=s("Both parameter values default to 1000, which can be expensive if you are storing images. Lower these values to use less memory when you use "),be=o("a"),et=s("map()"),at=s("."),We=m(),T=o("h2"),H=o("a"),Le=o("span"),C(oe.$$.fragment),tt=m(),Ie=o("span"),st=s("Apply transforms"),Xe=m(),K=o("p"),rt=s("\u{1F917} Datasets applies data augmentations from any library or package to your dataset. Transforms can be applied on-the-fly on batches of data with "),Ee=o("a"),ot=s("set_transform()"),lt=s(", which consumes less disk space."),Ye=m(),C(Q.$$.fragment),Ze=m(),ke=o("p"),nt=s("For example, if you\u2019d like to change the color properties of an image randomly:"),ea=m(),C(le.$$.fragment),aa=m(),V=o("p"),pt=s("Create a function to apply the "),Be=o("code"),it=s("ColorJitter"),ft=s(" transform:"),ta=m(),C(ne.$$.fragment),sa=m(),W=o("p"),mt=s("Apply the transform with the "),xe=o("a"),ct=s("set_transform()"),ht=s(" function:"),ra=m(),C(pe.$$.fragment),this.h()},l(e){const p=Yt('[data-svelte="svelte-1phssyn"]',document.head);h=l(p,"META",{name:!0,content:!0}),p.forEach(t),B=c(e),u=l(e,"H1",{class:!0});var ie=n(u);y=l(ie,"A",{id:!0,class:!0,href:!0});var gt=n(y);x=l(gt,"SPAN",{});var yt=n(x);D(_.$$.fragment,yt),yt.forEach(t),gt.forEach(t),X=c(ie),j=l(ie,"SPAN",{});var wt=n(j);$=r(wt,"Process image data"),wt.forEach(t),ie.forEach(t),S=c(e),E=l(e,"P",{});var $t=n(E);b=r($t,"This guide shows specific methods for processing image datasets. Learn how to:"),$t.forEach(t),N=c(e),w=l(e,"UL",{});var la=n(w);g=l(la,"LI",{});var na=n(g);d=r(na,"Use "),A=l(na,"A",{href:!0});var bt=n(A);fe=r(bt,"map()"),bt.forEach(t),me=r(na," with image dataset."),na.forEach(t),ce=c(la),Y=l(la,"LI",{});var pa=n(Y);wa=r(pa,"Apply data augmentations to a dataset with "),he=l(pa,"A",{href:!0});var Et=n(he);$a=r(Et,"set_transform()"),Et.forEach(t),ba=r(pa,"."),pa.forEach(t),la.forEach(t),Re=c(e),R=l(e,"P",{});var ia=n(R);Ea=r(ia,"For a guide on how to process any type of dataset, take a look at the "),Z=l(ia,"A",{class:!0,href:!0});var kt=n(Z);ka=r(kt,"general process guide"),kt.forEach(t),xa=r(ia,"."),ia.forEach(t),Fe=c(e),P=l(e,"H2",{class:!0});var fa=n(P);F=l(fa,"A",{id:!0,class:!0,href:!0});var xt=n(F);je=l(xt,"SPAN",{});var jt=n(je);D(ee.$$.fragment,jt),jt.forEach(t),xt.forEach(t),ja=c(fa),Ae=l(fa,"SPAN",{});var At=n(Ae);Aa=r(At,"Map"),At.forEach(t),fa.forEach(t),Oe=c(e),O=l(e,"P",{});var ma=n(O);Pa=r(ma,"The "),ue=l(ma,"A",{href:!0});var Pt=n(ue);Ta=r(Pt,"map()"),Pt.forEach(t),Ca=r(ma," function can apply transforms over an entire dataset."),ma.forEach(t),Je=c(e),J=l(e,"P",{});var ca=n(J);Da=r(ca,"For example, create a basic "),ae=l(ca,"A",{href:!0,rel:!0});var Tt=n(ae);Pe=l(Tt,"CODE",{});var Ct=n(Pe);qa=r(Ct,"Resize"),Ct.forEach(t),Tt.forEach(t),za=r(ca," function:"),ca.forEach(t),Ge=c(e),D(te.$$.fragment,e),Me=c(e),v=l(e,"P",{});var k=n(v);La=r(k,"Now use the "),de=l(k,"A",{href:!0});var Dt=n(de);Ia=r(Dt,"map()"),Dt.forEach(t),Ba=r(k," function to resize the entire dataset, and set "),Te=l(k,"CODE",{});var qt=n(Te);Sa=r(qt,"batched=True"),qt.forEach(t),Na=r(k," to speed up the process by accepting batches of examples. The transform returns "),Ce=l(k,"CODE",{});var zt=n(Ce);Ra=r(zt,"pixel_values"),zt.forEach(t),Fa=r(k," as a cacheable "),De=l(k,"CODE",{});var Lt=n(De);Oa=r(Lt,"PIL.Image"),Lt.forEach(t),Ja=r(k," object:"),k.forEach(t),Ue=c(e),D(se.$$.fragment,e),He=c(e),G=l(e,"P",{});var ha=n(G);Ga=r(ha,"The cache file saves time because you don\u2019t have to execute the same transform twice. The "),_e=l(ha,"A",{href:!0});var It=n(_e);Ma=r(It,"map()"),It.forEach(t),Ua=r(ha," function is best for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),ha.forEach(t),Ke=c(e),re=l(e,"P",{});var ut=n(re);ve=l(ut,"A",{href:!0});var Bt=n(ve);Ha=r(Bt,"map()"),Bt.forEach(t),Ka=r(ut," takes up some memory, but you can reduce its memory requirements with the following parameters:"),ut.forEach(t),Qe=c(e),M=l(e,"UL",{});var ua=n(M);ge=l(ua,"LI",{});var dt=n(ge);ye=l(dt,"A",{href:!0});var St=n(ye);qe=l(St,"CODE",{});var Nt=n(qe);Qa=r(Nt,"batch_size"),Nt.forEach(t),St.forEach(t),Va=r(dt," determines the number of examples that are processed in one call to the transform function."),dt.forEach(t),Wa=c(ua),we=l(ua,"LI",{});var _t=n(we);$e=l(_t,"A",{href:!0});var Rt=n($e);ze=l(Rt,"CODE",{});var Ft=n(ze);Xa=r(Ft,"writer_batch_size"),Ft.forEach(t),Rt.forEach(t),Ya=r(_t," determines the number of processed examples that are kept in memory before they are stored away."),_t.forEach(t),ua.forEach(t),Ve=c(e),U=l(e,"P",{});var da=n(U);Za=r(da,"Both parameter values default to 1000, which can be expensive if you are storing images. Lower these values to use less memory when you use "),be=l(da,"A",{href:!0});var Ot=n(be);et=r(Ot,"map()"),Ot.forEach(t),at=r(da,"."),da.forEach(t),We=c(e),T=l(e,"H2",{class:!0});var _a=n(T);H=l(_a,"A",{id:!0,class:!0,href:!0});var Jt=n(H);Le=l(Jt,"SPAN",{});var Gt=n(Le);D(oe.$$.fragment,Gt),Gt.forEach(t),Jt.forEach(t),tt=c(_a),Ie=l(_a,"SPAN",{});var Mt=n(Ie);st=r(Mt,"Apply transforms"),Mt.forEach(t),_a.forEach(t),Xe=c(e),K=l(e,"P",{});var va=n(K);rt=r(va,"\u{1F917} Datasets applies data augmentations from any library or package to your dataset. Transforms can be applied on-the-fly on batches of data with "),Ee=l(va,"A",{href:!0});var Ut=n(Ee);ot=r(Ut,"set_transform()"),Ut.forEach(t),lt=r(va,", which consumes less disk space."),va.forEach(t),Ye=c(e),D(Q.$$.fragment,e),Ze=c(e),ke=l(e,"P",{});var Ht=n(ke);nt=r(Ht,"For example, if you\u2019d like to change the color properties of an image randomly:"),Ht.forEach(t),ea=c(e),D(le.$$.fragment,e),aa=c(e),V=l(e,"P",{});var ga=n(V);pt=r(ga,"Create a function to apply the "),Be=l(ga,"CODE",{});var Kt=n(Be);it=r(Kt,"ColorJitter"),Kt.forEach(t),ft=r(ga," transform:"),ga.forEach(t),ta=c(e),D(ne.$$.fragment,e),sa=c(e),W=l(e,"P",{});var ya=n(W);mt=r(ya,"Apply the transform with the "),xe=l(ya,"A",{href:!0});var Qt=n(xe);ct=r(Qt,"set_transform()"),Qt.forEach(t),ht=r(ya," function:"),ya.forEach(t),ra=c(e),D(pe.$$.fragment,e),this.h()},h(){f(h,"name","hf:doc:metadata"),f(h,"content",JSON.stringify(ss)),f(y,"id","process-image-data"),f(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(y,"href","#process-image-data"),f(u,"class","relative group"),f(A,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(he,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.set_transform"),f(Z,"class","underline decoration-sky-400 decoration-2 font-semibold"),f(Z,"href","./process"),f(F,"id","map"),f(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(F,"href","#map"),f(P,"class","relative group"),f(ue,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(ae,"href","https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html"),f(ae,"rel","nofollow"),f(de,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(_e,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(ve,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(ye,"href","./package_reference/main_classes#datasets.DatasetDict.map.batch_size"),f($e,"href","./package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size"),f(be,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.map"),f(H,"id","apply-transforms"),f(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(H,"href","#apply-transforms"),f(T,"class","relative group"),f(Ee,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.set_transform"),f(xe,"href","/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.set_transform")},m(e,p){a(document.head,h),i(e,B,p),i(e,u,p),a(u,y),a(y,x),q(_,x,null),a(u,X),a(u,j),a(j,$),i(e,S,p),i(e,E,p),a(E,b),i(e,N,p),i(e,w,p),a(w,g),a(g,d),a(g,A),a(A,fe),a(g,me),a(w,ce),a(w,Y),a(Y,wa),a(Y,he),a(he,$a),a(Y,ba),i(e,Re,p),i(e,R,p),a(R,Ea),a(R,Z),a(Z,ka),a(R,xa),i(e,Fe,p),i(e,P,p),a(P,F),a(F,je),q(ee,je,null),a(P,ja),a(P,Ae),a(Ae,Aa),i(e,Oe,p),i(e,O,p),a(O,Pa),a(O,ue),a(ue,Ta),a(O,Ca),i(e,Je,p),i(e,J,p),a(J,Da),a(J,ae),a(ae,Pe),a(Pe,qa),a(J,za),i(e,Ge,p),q(te,e,p),i(e,Me,p),i(e,v,p),a(v,La),a(v,de),a(de,Ia),a(v,Ba),a(v,Te),a(Te,Sa),a(v,Na),a(v,Ce),a(Ce,Ra),a(v,Fa),a(v,De),a(De,Oa),a(v,Ja),i(e,Ue,p),q(se,e,p),i(e,He,p),i(e,G,p),a(G,Ga),a(G,_e),a(_e,Ma),a(G,Ua),i(e,Ke,p),i(e,re,p),a(re,ve),a(ve,Ha),a(re,Ka),i(e,Qe,p),i(e,M,p),a(M,ge),a(ge,ye),a(ye,qe),a(qe,Qa),a(ge,Va),a(M,Wa),a(M,we),a(we,$e),a($e,ze),a(ze,Xa),a(we,Ya),i(e,Ve,p),i(e,U,p),a(U,Za),a(U,be),a(be,et),a(U,at),i(e,We,p),i(e,T,p),a(T,H),a(H,Le),q(oe,Le,null),a(T,tt),a(T,Ie),a(Ie,st),i(e,Xe,p),i(e,K,p),a(K,rt),a(K,Ee),a(Ee,ot),a(K,lt),i(e,Ye,p),q(Q,e,p),i(e,Ze,p),i(e,ke,p),a(ke,nt),i(e,ea,p),q(le,e,p),i(e,aa,p),i(e,V,p),a(V,pt),a(V,Be),a(Be,it),a(V,ft),i(e,ta,p),q(ne,e,p),i(e,sa,p),i(e,W,p),a(W,mt),a(W,xe),a(xe,ct),a(W,ht),i(e,ra,p),q(pe,e,p),oa=!0},p(e,[p]){const ie={};p&2&&(ie.$$scope={dirty:p,ctx:e}),Q.$set(ie)},i(e){oa||(z(_.$$.fragment,e),z(ee.$$.fragment,e),z(te.$$.fragment,e),z(se.$$.fragment,e),z(oe.$$.fragment,e),z(Q.$$.fragment,e),z(le.$$.fragment,e),z(ne.$$.fragment,e),z(pe.$$.fragment,e),oa=!0)},o(e){L(_.$$.fragment,e),L(ee.$$.fragment,e),L(te.$$.fragment,e),L(se.$$.fragment,e),L(oe.$$.fragment,e),L(Q.$$.fragment,e),L(le.$$.fragment,e),L(ne.$$.fragment,e),L(pe.$$.fragment,e),oa=!1},d(e){t(h),e&&t(B),e&&t(u),I(_),e&&t(S),e&&t(E),e&&t(N),e&&t(w),e&&t(Re),e&&t(R),e&&t(Fe),e&&t(P),I(ee),e&&t(Oe),e&&t(O),e&&t(Je),e&&t(J),e&&t(Ge),I(te,e),e&&t(Me),e&&t(v),e&&t(Ue),I(se,e),e&&t(He),e&&t(G),e&&t(Ke),e&&t(re),e&&t(Qe),e&&t(M),e&&t(Ve),e&&t(U),e&&t(We),e&&t(T),I(oe),e&&t(Xe),e&&t(K),e&&t(Ye),I(Q,e),e&&t(Ze),e&&t(ke),e&&t(ea),I(le,e),e&&t(aa),e&&t(V),e&&t(ta),I(ne,e),e&&t(sa),e&&t(W),e&&t(ra),I(pe,e)}}}const ss={local:"process-image-data",sections:[{local:"map",title:"Map"},{local:"apply-transforms",title:"Apply transforms"}],title:"Process image data"};function rs(Ne){return Zt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class is extends Vt{constructor(h){super();Wt(this,h,rs,ts,Xt,{})}}export{is as default,ss as metadata};
