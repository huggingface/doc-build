import{S as Ka,i as Qa,s as Va,e as l,k as m,w as A,t as p,M as Wa,c as t,d as a,m as i,a as r,x as P,h as o,b as c,G as n,g as h,y as T,L as Xa,q as z,o as L,B as N,v as Za}from"../chunks/vendor-hf-doc-builder.js";import{I as ka}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as cs}from"../chunks/CodeBlock-hf-doc-builder.js";function sn(xa){let f,ms,j,_,as,S,Fs,ns,Hs,is,J,Os,us,v,I,Bs,R,Us,Ys,Gs,es,Js,bs,$,Rs,M,Ks,Qs,fs,d,w,ls,D,Vs,ts,Ws,js,k,Xs,K,Zs,sa,ds,x,aa,C,na,ea,gs,F,_s,u,la,ps,ta,pa,rs,ra,oa,Q,ha,ca,vs,H,$s,g,y,os,O,ma,hs,ia,ws,b,ua,V,ba,fa,B,ja,da,ks,U,xs,W,ga,ys,Y,Es,E,_a,X,va,$a,qs,G,As,Z,wa,Ps;return S=new ka({}),D=new ka({}),F=new cs({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),H=new cs({props:{code:`dataset = dataset.map(lambda examples: tokenizer(examples["text"]), batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> examples: tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>]), batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;the rock is destined to be the 21st century\\&#x27;s new &quot; conan &quot; and that he\\&#x27;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#x27;</span>, 
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>, 
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2600</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">16036</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">2022</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">7398</span>, <span class="hljs-number">2301</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">2047</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">16608</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1998</span>, <span class="hljs-number">2008</span>, <span class="hljs-number">2002</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">2183</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">2191</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17624</span>, <span class="hljs-number">2130</span>, <span class="hljs-number">3618</span>, <span class="hljs-number">2084</span>, <span class="hljs-number">7779</span>, <span class="hljs-number">29058</span>, <span class="hljs-number">8625</span>, <span class="hljs-number">13327</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">3744</span>, <span class="hljs-number">1011</span>, <span class="hljs-number">18856</span>, <span class="hljs-number">19513</span>, <span class="hljs-number">3158</span>, <span class="hljs-number">5477</span>, <span class="hljs-number">4168</span>, <span class="hljs-number">2030</span>, <span class="hljs-number">7112</span>, <span class="hljs-number">16562</span>, <span class="hljs-number">2140</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),O=new ka({}),U=new cs({props:{code:'label2id = {"entailment": 0, "neutral": 1, "contradiction": 2}',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {<span class="hljs-string">&quot;entailment&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;neutral&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;contradiction&quot;</span>: <span class="hljs-number">2</span>}'}}),Y=new cs({props:{code:'label2id = {"contradiction": 0, "neutral": 1, "entailment": 2}',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {<span class="hljs-string">&quot;contradiction&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;neutral&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;entailment&quot;</span>: <span class="hljs-number">2</span>}'}}),G=new cs({props:{code:`from datasets import load_dataset

mnli = load_dataset("glue", "mnli", split="train")
mnli_aligned = mnli.align_labels_with_mapping(label2id, "label")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>mnli = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mnli_aligned = mnli.align_labels_with_mapping(label2id, <span class="hljs-string">&quot;label&quot;</span>)`}}),{c(){f=l("meta"),ms=m(),j=l("h1"),_=l("a"),as=l("span"),A(S.$$.fragment),Fs=m(),ns=l("span"),Hs=p("Process text data"),is=m(),J=l("p"),Os=p("This guide shows specific methods for processing text datasets. Learn how to:"),us=m(),v=l("ul"),I=l("li"),Bs=p("Tokenize a dataset with "),R=l("a"),Us=p("map()"),Ys=p("."),Gs=m(),es=l("li"),Js=p("Align dataset labels with label ids for NLI datasets."),bs=m(),$=l("p"),Rs=p("For a guide on how to process any type of dataset, take a look at the "),M=l("a"),Ks=p("general process guide"),Qs=p("."),fs=m(),d=l("h2"),w=l("a"),ls=l("span"),A(D.$$.fragment),Vs=m(),ts=l("span"),Ws=p("Map"),js=m(),k=l("p"),Xs=p("The "),K=l("a"),Zs=p("map()"),sa=p(" function supports processing batches of examples at once which speeds up tokenization."),ds=m(),x=l("p"),aa=p("Load a tokenizer from \u{1F917} "),C=l("a"),na=p("Transformers"),ea=p(":"),gs=m(),A(F.$$.fragment),_s=m(),u=l("p"),la=p("Set the "),ps=l("code"),ta=p("batched"),pa=p(" parameter to "),rs=l("code"),ra=p("True"),oa=p(" in the "),Q=l("a"),ha=p("map()"),ca=p(" function to apply the tokenizer to batches of examples:"),vs=m(),A(H.$$.fragment),$s=m(),g=l("h2"),y=l("a"),os=l("span"),A(O.$$.fragment),ma=m(),hs=l("span"),ia=p("Align"),ws=m(),b=l("p"),ua=p("The "),V=l("a"),ba=p("align_labels_with_mapping()"),fa=p(" function aligns a dataset label id with the label name. Not all \u{1F917} Transformers models follow the prescribed label mapping of the original dataset, especially for NLI datasets. For example, the "),B=l("a"),ja=p("MNLI"),da=p(" dataset uses the following label mapping:"),ks=m(),A(U.$$.fragment),xs=m(),W=l("p"),ga=p("To align the dataset label mapping with the mapping used by a model, create a dictionary of the label name and id to align on:"),ys=m(),A(Y.$$.fragment),Es=m(),E=l("p"),_a=p("Pass the dictionary of the label mappings to the "),X=l("a"),va=p("align_labels_with_mapping()"),$a=p(" function, and the column to align on:"),qs=m(),A(G.$$.fragment),As=m(),Z=l("p"),wa=p("You can also use this function to assign a custom mapping of labels to ids."),this.h()},l(s){const e=Wa('[data-svelte="svelte-1phssyn"]',document.head);f=t(e,"META",{name:!0,content:!0}),e.forEach(a),ms=i(s),j=t(s,"H1",{class:!0});var Ts=r(j);_=t(Ts,"A",{id:!0,class:!0,href:!0});var ya=r(_);as=t(ya,"SPAN",{});var Ea=r(as);P(S.$$.fragment,Ea),Ea.forEach(a),ya.forEach(a),Fs=i(Ts),ns=t(Ts,"SPAN",{});var qa=r(ns);Hs=o(qa,"Process text data"),qa.forEach(a),Ts.forEach(a),is=i(s),J=t(s,"P",{});var Aa=r(J);Os=o(Aa,"This guide shows specific methods for processing text datasets. Learn how to:"),Aa.forEach(a),us=i(s),v=t(s,"UL",{});var zs=r(v);I=t(zs,"LI",{});var Ls=r(I);Bs=o(Ls,"Tokenize a dataset with "),R=t(Ls,"A",{href:!0});var Pa=r(R);Us=o(Pa,"map()"),Pa.forEach(a),Ys=o(Ls,"."),Ls.forEach(a),Gs=i(zs),es=t(zs,"LI",{});var Ta=r(es);Js=o(Ta,"Align dataset labels with label ids for NLI datasets."),Ta.forEach(a),zs.forEach(a),bs=i(s),$=t(s,"P",{});var Ns=r($);Rs=o(Ns,"For a guide on how to process any type of dataset, take a look at the "),M=t(Ns,"A",{class:!0,href:!0});var za=r(M);Ks=o(za,"general process guide"),za.forEach(a),Qs=o(Ns,"."),Ns.forEach(a),fs=i(s),d=t(s,"H2",{class:!0});var Ss=r(d);w=t(Ss,"A",{id:!0,class:!0,href:!0});var La=r(w);ls=t(La,"SPAN",{});var Na=r(ls);P(D.$$.fragment,Na),Na.forEach(a),La.forEach(a),Vs=i(Ss),ts=t(Ss,"SPAN",{});var Sa=r(ts);Ws=o(Sa,"Map"),Sa.forEach(a),Ss.forEach(a),js=i(s),k=t(s,"P",{});var Is=r(k);Xs=o(Is,"The "),K=t(Is,"A",{href:!0});var Ia=r(K);Zs=o(Ia,"map()"),Ia.forEach(a),sa=o(Is," function supports processing batches of examples at once which speeds up tokenization."),Is.forEach(a),ds=i(s),x=t(s,"P",{});var Ms=r(x);aa=o(Ms,"Load a tokenizer from \u{1F917} "),C=t(Ms,"A",{href:!0,rel:!0});var Ma=r(C);na=o(Ma,"Transformers"),Ma.forEach(a),ea=o(Ms,":"),Ms.forEach(a),gs=i(s),P(F.$$.fragment,s),_s=i(s),u=t(s,"P",{});var q=r(u);la=o(q,"Set the "),ps=t(q,"CODE",{});var Da=r(ps);ta=o(Da,"batched"),Da.forEach(a),pa=o(q," parameter to "),rs=t(q,"CODE",{});var Ca=r(rs);ra=o(Ca,"True"),Ca.forEach(a),oa=o(q," in the "),Q=t(q,"A",{href:!0});var Fa=r(Q);ha=o(Fa,"map()"),Fa.forEach(a),ca=o(q," function to apply the tokenizer to batches of examples:"),q.forEach(a),vs=i(s),P(H.$$.fragment,s),$s=i(s),g=t(s,"H2",{class:!0});var Ds=r(g);y=t(Ds,"A",{id:!0,class:!0,href:!0});var Ha=r(y);os=t(Ha,"SPAN",{});var Oa=r(os);P(O.$$.fragment,Oa),Oa.forEach(a),Ha.forEach(a),ma=i(Ds),hs=t(Ds,"SPAN",{});var Ba=r(hs);ia=o(Ba,"Align"),Ba.forEach(a),Ds.forEach(a),ws=i(s),b=t(s,"P",{});var ss=r(b);ua=o(ss,"The "),V=t(ss,"A",{href:!0});var Ua=r(V);ba=o(Ua,"align_labels_with_mapping()"),Ua.forEach(a),fa=o(ss," function aligns a dataset label id with the label name. Not all \u{1F917} Transformers models follow the prescribed label mapping of the original dataset, especially for NLI datasets. For example, the "),B=t(ss,"A",{href:!0,rel:!0});var Ya=r(B);ja=o(Ya,"MNLI"),Ya.forEach(a),da=o(ss," dataset uses the following label mapping:"),ss.forEach(a),ks=i(s),P(U.$$.fragment,s),xs=i(s),W=t(s,"P",{});var Ga=r(W);ga=o(Ga,"To align the dataset label mapping with the mapping used by a model, create a dictionary of the label name and id to align on:"),Ga.forEach(a),ys=i(s),P(Y.$$.fragment,s),Es=i(s),E=t(s,"P",{});var Cs=r(E);_a=o(Cs,"Pass the dictionary of the label mappings to the "),X=t(Cs,"A",{href:!0});var Ja=r(X);va=o(Ja,"align_labels_with_mapping()"),Ja.forEach(a),$a=o(Cs," function, and the column to align on:"),Cs.forEach(a),qs=i(s),P(G.$$.fragment,s),As=i(s),Z=t(s,"P",{});var Ra=r(Z);wa=o(Ra,"You can also use this function to assign a custom mapping of labels to ids."),Ra.forEach(a),this.h()},h(){c(f,"name","hf:doc:metadata"),c(f,"content",JSON.stringify(an)),c(_,"id","process-text-data"),c(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_,"href","#process-text-data"),c(j,"class","relative group"),c(R,"href","/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.map"),c(M,"class","underline decoration-sky-400 decoration-2 font-semibold"),c(M,"href","./process"),c(w,"id","map"),c(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w,"href","#map"),c(d,"class","relative group"),c(K,"href","/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.map"),c(C,"href","https://huggingface.co/transformers/"),c(C,"rel","nofollow"),c(Q,"href","/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.map"),c(y,"id","align"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#align"),c(g,"class","relative group"),c(V,"href","/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping"),c(B,"href","https://huggingface.co/datasets/glue"),c(B,"rel","nofollow"),c(X,"href","/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping")},m(s,e){n(document.head,f),h(s,ms,e),h(s,j,e),n(j,_),n(_,as),T(S,as,null),n(j,Fs),n(j,ns),n(ns,Hs),h(s,is,e),h(s,J,e),n(J,Os),h(s,us,e),h(s,v,e),n(v,I),n(I,Bs),n(I,R),n(R,Us),n(I,Ys),n(v,Gs),n(v,es),n(es,Js),h(s,bs,e),h(s,$,e),n($,Rs),n($,M),n(M,Ks),n($,Qs),h(s,fs,e),h(s,d,e),n(d,w),n(w,ls),T(D,ls,null),n(d,Vs),n(d,ts),n(ts,Ws),h(s,js,e),h(s,k,e),n(k,Xs),n(k,K),n(K,Zs),n(k,sa),h(s,ds,e),h(s,x,e),n(x,aa),n(x,C),n(C,na),n(x,ea),h(s,gs,e),T(F,s,e),h(s,_s,e),h(s,u,e),n(u,la),n(u,ps),n(ps,ta),n(u,pa),n(u,rs),n(rs,ra),n(u,oa),n(u,Q),n(Q,ha),n(u,ca),h(s,vs,e),T(H,s,e),h(s,$s,e),h(s,g,e),n(g,y),n(y,os),T(O,os,null),n(g,ma),n(g,hs),n(hs,ia),h(s,ws,e),h(s,b,e),n(b,ua),n(b,V),n(V,ba),n(b,fa),n(b,B),n(B,ja),n(b,da),h(s,ks,e),T(U,s,e),h(s,xs,e),h(s,W,e),n(W,ga),h(s,ys,e),T(Y,s,e),h(s,Es,e),h(s,E,e),n(E,_a),n(E,X),n(X,va),n(E,$a),h(s,qs,e),T(G,s,e),h(s,As,e),h(s,Z,e),n(Z,wa),Ps=!0},p:Xa,i(s){Ps||(z(S.$$.fragment,s),z(D.$$.fragment,s),z(F.$$.fragment,s),z(H.$$.fragment,s),z(O.$$.fragment,s),z(U.$$.fragment,s),z(Y.$$.fragment,s),z(G.$$.fragment,s),Ps=!0)},o(s){L(S.$$.fragment,s),L(D.$$.fragment,s),L(F.$$.fragment,s),L(H.$$.fragment,s),L(O.$$.fragment,s),L(U.$$.fragment,s),L(Y.$$.fragment,s),L(G.$$.fragment,s),Ps=!1},d(s){a(f),s&&a(ms),s&&a(j),N(S),s&&a(is),s&&a(J),s&&a(us),s&&a(v),s&&a(bs),s&&a($),s&&a(fs),s&&a(d),N(D),s&&a(js),s&&a(k),s&&a(ds),s&&a(x),s&&a(gs),N(F,s),s&&a(_s),s&&a(u),s&&a(vs),N(H,s),s&&a($s),s&&a(g),N(O),s&&a(ws),s&&a(b),s&&a(ks),N(U,s),s&&a(xs),s&&a(W),s&&a(ys),N(Y,s),s&&a(Es),s&&a(E),s&&a(qs),N(G,s),s&&a(As),s&&a(Z)}}}const an={local:"process-text-data",sections:[{local:"map",title:"Map"},{local:"align",title:"Align"}],title:"Process text data"};function nn(xa){return Za(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pn extends Ka{constructor(f){super();Qa(this,f,nn,sn,Va,{})}}export{pn as default,an as metadata};
