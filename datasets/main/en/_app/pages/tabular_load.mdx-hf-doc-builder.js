import{S as Ql,i as Nl,s as Il,e as o,k as f,w as h,t as l,M as Rl,c as n,d as t,m as d,a as i,x as u,h as r,b as c,G as s,g as p,y as m,L as Ul,q as _,o as g,B as v,v as Vl}from"../chunks/vendor-hf-doc-builder.js";import{I as Ra}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as w}from"../chunks/CodeBlock-hf-doc-builder.js";function Ol(Ie){let D,pt,x,T,Ua,B,fs,Va,ds,ft,ya,cs,dt,q,Oa,hs,us,Ya,ms,_s,Ha,gs,ct,S,F,Ma,J,vs,za,ys,ht,b,bs,Wa,$s,ws,ba,qs,js,Ga,Es,ks,ut,K,mt,$a,Ds,_t,X,gt,wa,xs,vt,Z,yt,qa,Ss,bt,aa,$t,P,Q,Ba,ta,Ps,Ja,Ls,wt,j,As,sa,Cs,Ts,ja,Fs,Qs,qt,ea,jt,N,Ns,Ka,Is,Rs,Et,la,kt,y,Us,Ea,Vs,Os,ra,Ys,Hs,Xa,Ms,zs,Za,Ws,Gs,at,Bs,Js,Dt,L,I,tt,oa,Ks,st,Xs,xt,ka,Zs,St,A,R,et,na,ae,lt,te,Pt,Da,se,Lt,U,ee,ia,le,re,At,pa,Ct,E,oe,rt,ne,ie,ot,pe,fe,Tt,k,de,fa,ce,he,da,ue,me,Ft,xa,_e,Qt,ca,Nt,V,ge,Sa,ve,ye,It,ha,Rt,O,be,Pa,$e,we,Ut,ua,Vt,La,qe,Ot,Y,je,Aa,Ee,ke,Yt,ma,Ht,H,De,Ca,xe,Se,Mt,_a,zt,C,M,nt,ga,Pe,it,Le,Wt,z,Ae,va,Ce,Te,Gt,W,Fe,Ta,Qe,Ne,Bt;return B=new Ra({}),J=new Ra({}),K=new w({props:{code:`from datasets import load_dataset
dataset = load_dataset("csv", data_files="my_file.csv")

dataset = load_dataset("csv", data_files=["my_file_1.csv", "my_file_2.csv", "my_file_3.csv"])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=<span class="hljs-string">&quot;my_file.csv&quot;</span>)

<span class="hljs-comment"># load multiple CSV files</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=[<span class="hljs-string">&quot;my_file_1.csv&quot;</span>, <span class="hljs-string">&quot;my_file_2.csv&quot;</span>, <span class="hljs-string">&quot;my_file_3.csv&quot;</span>])`}}),X=new w({props:{code:'dataset = load_dataset("csv", data_files={"train": ["my_train_file_1.csv", "my_train_file_2.csv"], "test": "my_test_file.csv"})',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: [<span class="hljs-string">&quot;my_train_file_1.csv&quot;</span>, <span class="hljs-string">&quot;my_train_file_2.csv&quot;</span>], <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;my_test_file.csv&quot;</span>})'}}),Z=new w({props:{code:`base_url = "https://huggingface.co/datasets/lhoestq/demo1/resolve/main/data/"
dataset = load_dataset('csv', data_files={"train": base_url + "train.csv", "test": base_url + "test.csv"})`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>base_url = <span class="hljs-string">&quot;https://huggingface.co/datasets/lhoestq/demo1/resolve/main/data/&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;csv&#x27;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: base_url + <span class="hljs-string">&quot;train.csv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: base_url + <span class="hljs-string">&quot;test.csv&quot;</span>})`}}),aa=new w({props:{code:`url = "https://domain.org/train_data.zip"
data_files = {"train": url}
dataset = load_dataset("csv", data_files=data_files)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>url = <span class="hljs-string">&quot;https://domain.org/train_data.zip&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>data_files = {<span class="hljs-string">&quot;train&quot;</span>: url}
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files)`}}),ta=new Ra({}),ea=new w({props:{code:`from datasets import Dataset
import pandas as pd

df = pd.read_csv("https://huggingface.co/datasets/imodels/credit-card/raw/main/train.csv")
df = pd.DataFrame(df)
dataset = Dataset.from_pandas(df)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-comment"># create a Pandas DataFrame</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>df = pd.read_csv(<span class="hljs-string">&quot;https://huggingface.co/datasets/imodels/credit-card/raw/main/train.csv&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>df = pd.DataFrame(df)
<span class="hljs-comment"># load Dataset from Pandas DataFrame</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = Dataset.from_pandas(df)`}}),la=new w({props:{code:`train_ds = Dataset.from_pandas(train_df, split="train")
test_ds = Dataset.from_pandas(test_df, split="test")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>train_ds = Dataset.from_pandas(train_df, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>test_ds = Dataset.from_pandas(test_df, split=<span class="hljs-string">&quot;test&quot;</span>)`}}),oa=new Ra({}),na=new Ra({}),pa=new w({props:{code:`import sqlite3
import pandas as pd

conn = sqlite3.connect("us_covid_data.db")
df = pd.read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
df.to_sql("states", conn, if_exists="replace")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> sqlite3
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-meta">&gt;&gt;&gt; </span>conn = sqlite3.connect(<span class="hljs-string">&quot;us_covid_data.db&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>df = pd.read_csv(<span class="hljs-string">&quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>df.to_sql(<span class="hljs-string">&quot;states&quot;</span>, conn, if_exists=<span class="hljs-string">&quot;replace&quot;</span>)`}}),ca=new w({props:{code:'uri = "sqlite:///us_covid_data.db"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>uri = <span class="hljs-string">&quot;sqlite:///us_covid_data.db&quot;</span>'}}),ha=new w({props:{code:`from datasets import Dataset

ds = Dataset.from_sql("states", uri)
ds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_sql(<span class="hljs-string">&quot;states&quot;</span>, uri)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds
Dataset({
    features: [<span class="hljs-string">&#x27;index&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;fips&#x27;</span>, <span class="hljs-string">&#x27;cases&#x27;</span>, <span class="hljs-string">&#x27;deaths&#x27;</span>],
    num_rows: <span class="hljs-number">54382</span>
})`}}),ua=new w({props:{code:'ds.filter(lambda x: x["state"] == "California")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>ds.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;state&quot;</span>] == <span class="hljs-string">&quot;California&quot;</span>)'}}),ma=new w({props:{code:`from datasets import Dataset

ds = Dataset.from_sql('SELECT * FROM states WHERE state="California";', uri)
ds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_sql(<span class="hljs-string">&#x27;SELECT * FROM states WHERE state=&quot;California&quot;;&#x27;</span>, uri)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds
Dataset({
    features: [<span class="hljs-string">&#x27;index&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;fips&#x27;</span>, <span class="hljs-string">&#x27;cases&#x27;</span>, <span class="hljs-string">&#x27;deaths&#x27;</span>],
    num_rows: <span class="hljs-number">1019</span>
})`}}),_a=new w({props:{code:'ds.filter(lambda x: x["cases"] > 10000)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>ds.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;cases&quot;</span>] &gt; <span class="hljs-number">10000</span>)'}}),ga=new Ra({}),{c(){D=o("meta"),pt=f(),x=o("h1"),T=o("a"),Ua=o("span"),h(B.$$.fragment),fs=f(),Va=o("span"),ds=l("Load tabular data"),ft=f(),ya=o("p"),cs=l("A tabular dataset is a generic dataset used to describe any data stored in rows and columns, where the rows represent an example and the columns represent a feature (can be continuous or categorical). These datasets are commonly stored in CSV files, Pandas DataFrames, and in database tables. This guide will show you how to load and create a tabular dataset from:"),dt=f(),q=o("ul"),Oa=o("li"),hs=l("CSV files"),us=f(),Ya=o("li"),ms=l("Pandas DataFrames"),_s=f(),Ha=o("li"),gs=l("Databases"),ct=f(),S=o("h2"),F=o("a"),Ma=o("span"),h(J.$$.fragment),vs=f(),za=o("span"),ys=l("CSV files"),ht=f(),b=o("p"),bs=l("\u{1F917} Datasets can read CSV files by specifying the generic "),Wa=o("code"),$s=l("csv"),ws=l(" dataset script in the "),ba=o("a"),qs=l("load_dataset()"),js=l(" method. To load more than one CSV file, pass them as a list to the "),Ga=o("code"),Es=l("data_files"),ks=l(" parameter:"),ut=f(),h(K.$$.fragment),mt=f(),$a=o("p"),Ds=l("You can also map specific CSV files to the train and test splits:"),_t=f(),h(X.$$.fragment),gt=f(),wa=o("p"),xs=l("To load remote CSV files, pass the URLs instead:"),vt=f(),h(Z.$$.fragment),yt=f(),qa=o("p"),Ss=l("To load zipped CSV files:"),bt=f(),h(aa.$$.fragment),$t=f(),P=o("h2"),Q=o("a"),Ba=o("span"),h(ta.$$.fragment),Ps=f(),Ja=o("span"),Ls=l("Pandas DataFrames"),wt=f(),j=o("p"),As=l("\u{1F917} Datasets also supports loading datasets from "),sa=o("a"),Cs=l("Pandas DataFrames"),Ts=l(" with the "),ja=o("a"),Fs=l("from_pandas()"),Qs=l(" method:"),qt=f(),h(ea.$$.fragment),jt=f(),N=o("p"),Ns=l("Use the "),Ka=o("code"),Is=l("splits"),Rs=l(" parameter to specify the name of the dataset split:"),Et=f(),h(la.$$.fragment),kt=f(),y=o("p"),Us=l("If the dataset doesn\u2019t look as expected, you should explicitly "),Ea=o("a"),Vs=l("specify your dataset features"),Os=l(". A "),ra=o("a"),Ys=l("pandas.Series"),Hs=l(" may not always carry enough information for Arrow to automatically infer a data type. For example, if a DataFrame is of length "),Xa=o("code"),Ms=l("0"),zs=l(" or if the Series only contains "),Za=o("code"),Ws=l("None/NaN"),Gs=l(" objects, the type is set to "),at=o("code"),Bs=l("null"),Js=l("."),Dt=f(),L=o("h2"),I=o("a"),tt=o("span"),h(oa.$$.fragment),Ks=f(),st=o("span"),Xs=l("Databases"),xt=f(),ka=o("p"),Zs=l("Datasets stored in databases are typically accessed with SQL queries. With \u{1F917} Datasets, you can connect to a database, query for the data you need, and create a dataset out of it. Then you can use all the processing features of \u{1F917} Datasets to prepare your dataset for training."),St=f(),A=o("h3"),R=o("a"),et=o("span"),h(na.$$.fragment),ae=f(),lt=o("span"),te=l("SQLite"),Pt=f(),Da=o("p"),se=l("SQLite is a small, lightweight database that is fast and easy to set up. You can use an existing database if you\u2019d like, or follow along and start from scratch."),Lt=f(),U=o("p"),ee=l("Start by creating a quick SQLite database with this "),ia=o("a"),le=l("Covid-19 data"),re=l(" from the New York Times:"),At=f(),h(pa.$$.fragment),Ct=f(),E=o("p"),oe=l("This creates a "),rt=o("code"),ne=l("states"),ie=l(" table in the "),ot=o("code"),pe=l("us_covid_data.db"),fe=l(" database which you can now load into a dataset."),Tt=f(),k=o("p"),de=l("To connect to the database, you\u2019ll need the "),fa=o("a"),ce=l("URI string"),he=l(" that identifies your database. Connecting to a database with a URI caches the returned dataset. The URI string differs for each database dialect, so be sure to check the "),da=o("a"),ue=l("Database URLs"),me=l(" for whichever database you\u2019re using."),Ft=f(),xa=o("p"),_e=l("For SQLite, it is:"),Qt=f(),h(ca.$$.fragment),Nt=f(),V=o("p"),ge=l("Load the table by passing the table name and URI to "),Sa=o("a"),ve=l("from_sql()"),ye=l(":"),It=f(),h(ha.$$.fragment),Rt=f(),O=o("p"),be=l("Then you can use all of \u{1F917} Datasets process features like "),Pa=o("a"),$e=l("filter()"),we=l(" for example:"),Ut=f(),h(ua.$$.fragment),Vt=f(),La=o("p"),qe=l("You can also load a dataset from a SQL query instead of an entire table, which is useful for querying and joining multiple tables."),Ot=f(),Y=o("p"),je=l("Load the dataset by passing your query and URI to "),Aa=o("a"),Ee=l("from_sql()"),ke=l(":"),Yt=f(),h(ma.$$.fragment),Ht=f(),H=o("p"),De=l("Then you can use all of \u{1F917} Datasets process features like "),Ca=o("a"),xe=l("filter()"),Se=l(" for example:"),Mt=f(),h(_a.$$.fragment),zt=f(),C=o("h3"),M=o("a"),nt=o("span"),h(ga.$$.fragment),Pe=f(),it=o("span"),Le=l("PostgreSQL"),Wt=f(),z=o("p"),Ae=l("You can also connect and load a dataset from a PostgreSQL database, however we won\u2019t directly demonstrate how in the documentation because the example is only meant to be run in a notebook. Instead, take a look at how to install and setup a PostgreSQL server in this "),va=o("a"),Ce=l("notebook"),Te=l("!"),Gt=f(),W=o("p"),Fe=l("After you\u2019ve setup your PostgreSQL database, you can use the "),Ta=o("a"),Qe=l("from_sql()"),Ne=l(" method to load a dataset from a table or query."),this.h()},l(a){const e=Rl('[data-svelte="svelte-1phssyn"]',document.head);D=n(e,"META",{name:!0,content:!0}),e.forEach(t),pt=d(a),x=n(a,"H1",{class:!0});var Jt=i(x);T=n(Jt,"A",{id:!0,class:!0,href:!0});var Re=i(T);Ua=n(Re,"SPAN",{});var Ue=i(Ua);u(B.$$.fragment,Ue),Ue.forEach(t),Re.forEach(t),fs=d(Jt),Va=n(Jt,"SPAN",{});var Ve=i(Va);ds=r(Ve,"Load tabular data"),Ve.forEach(t),Jt.forEach(t),ft=d(a),ya=n(a,"P",{});var Oe=i(ya);cs=r(Oe,"A tabular dataset is a generic dataset used to describe any data stored in rows and columns, where the rows represent an example and the columns represent a feature (can be continuous or categorical). These datasets are commonly stored in CSV files, Pandas DataFrames, and in database tables. This guide will show you how to load and create a tabular dataset from:"),Oe.forEach(t),dt=d(a),q=n(a,"UL",{});var Fa=i(q);Oa=n(Fa,"LI",{});var Ye=i(Oa);hs=r(Ye,"CSV files"),Ye.forEach(t),us=d(Fa),Ya=n(Fa,"LI",{});var He=i(Ya);ms=r(He,"Pandas DataFrames"),He.forEach(t),_s=d(Fa),Ha=n(Fa,"LI",{});var Me=i(Ha);gs=r(Me,"Databases"),Me.forEach(t),Fa.forEach(t),ct=d(a),S=n(a,"H2",{class:!0});var Kt=i(S);F=n(Kt,"A",{id:!0,class:!0,href:!0});var ze=i(F);Ma=n(ze,"SPAN",{});var We=i(Ma);u(J.$$.fragment,We),We.forEach(t),ze.forEach(t),vs=d(Kt),za=n(Kt,"SPAN",{});var Ge=i(za);ys=r(Ge,"CSV files"),Ge.forEach(t),Kt.forEach(t),ht=d(a),b=n(a,"P",{});var G=i(b);bs=r(G,"\u{1F917} Datasets can read CSV files by specifying the generic "),Wa=n(G,"CODE",{});var Be=i(Wa);$s=r(Be,"csv"),Be.forEach(t),ws=r(G," dataset script in the "),ba=n(G,"A",{href:!0});var Je=i(ba);qs=r(Je,"load_dataset()"),Je.forEach(t),js=r(G," method. To load more than one CSV file, pass them as a list to the "),Ga=n(G,"CODE",{});var Ke=i(Ga);Es=r(Ke,"data_files"),Ke.forEach(t),ks=r(G," parameter:"),G.forEach(t),ut=d(a),u(K.$$.fragment,a),mt=d(a),$a=n(a,"P",{});var Xe=i($a);Ds=r(Xe,"You can also map specific CSV files to the train and test splits:"),Xe.forEach(t),_t=d(a),u(X.$$.fragment,a),gt=d(a),wa=n(a,"P",{});var Ze=i(wa);xs=r(Ze,"To load remote CSV files, pass the URLs instead:"),Ze.forEach(t),vt=d(a),u(Z.$$.fragment,a),yt=d(a),qa=n(a,"P",{});var al=i(qa);Ss=r(al,"To load zipped CSV files:"),al.forEach(t),bt=d(a),u(aa.$$.fragment,a),$t=d(a),P=n(a,"H2",{class:!0});var Xt=i(P);Q=n(Xt,"A",{id:!0,class:!0,href:!0});var tl=i(Q);Ba=n(tl,"SPAN",{});var sl=i(Ba);u(ta.$$.fragment,sl),sl.forEach(t),tl.forEach(t),Ps=d(Xt),Ja=n(Xt,"SPAN",{});var el=i(Ja);Ls=r(el,"Pandas DataFrames"),el.forEach(t),Xt.forEach(t),wt=d(a),j=n(a,"P",{});var Qa=i(j);As=r(Qa,"\u{1F917} Datasets also supports loading datasets from "),sa=n(Qa,"A",{href:!0,rel:!0});var ll=i(sa);Cs=r(ll,"Pandas DataFrames"),ll.forEach(t),Ts=r(Qa," with the "),ja=n(Qa,"A",{href:!0});var rl=i(ja);Fs=r(rl,"from_pandas()"),rl.forEach(t),Qs=r(Qa," method:"),Qa.forEach(t),qt=d(a),u(ea.$$.fragment,a),jt=d(a),N=n(a,"P",{});var Zt=i(N);Ns=r(Zt,"Use the "),Ka=n(Zt,"CODE",{});var ol=i(Ka);Is=r(ol,"splits"),ol.forEach(t),Rs=r(Zt," parameter to specify the name of the dataset split:"),Zt.forEach(t),Et=d(a),u(la.$$.fragment,a),kt=d(a),y=n(a,"P",{});var $=i(y);Us=r($,"If the dataset doesn\u2019t look as expected, you should explicitly "),Ea=n($,"A",{href:!0});var nl=i(Ea);Vs=r(nl,"specify your dataset features"),nl.forEach(t),Os=r($,". A "),ra=n($,"A",{href:!0,rel:!0});var il=i(ra);Ys=r(il,"pandas.Series"),il.forEach(t),Hs=r($," may not always carry enough information for Arrow to automatically infer a data type. For example, if a DataFrame is of length "),Xa=n($,"CODE",{});var pl=i(Xa);Ms=r(pl,"0"),pl.forEach(t),zs=r($," or if the Series only contains "),Za=n($,"CODE",{});var fl=i(Za);Ws=r(fl,"None/NaN"),fl.forEach(t),Gs=r($," objects, the type is set to "),at=n($,"CODE",{});var dl=i(at);Bs=r(dl,"null"),dl.forEach(t),Js=r($,"."),$.forEach(t),Dt=d(a),L=n(a,"H2",{class:!0});var as=i(L);I=n(as,"A",{id:!0,class:!0,href:!0});var cl=i(I);tt=n(cl,"SPAN",{});var hl=i(tt);u(oa.$$.fragment,hl),hl.forEach(t),cl.forEach(t),Ks=d(as),st=n(as,"SPAN",{});var ul=i(st);Xs=r(ul,"Databases"),ul.forEach(t),as.forEach(t),xt=d(a),ka=n(a,"P",{});var ml=i(ka);Zs=r(ml,"Datasets stored in databases are typically accessed with SQL queries. With \u{1F917} Datasets, you can connect to a database, query for the data you need, and create a dataset out of it. Then you can use all the processing features of \u{1F917} Datasets to prepare your dataset for training."),ml.forEach(t),St=d(a),A=n(a,"H3",{class:!0});var ts=i(A);R=n(ts,"A",{id:!0,class:!0,href:!0});var _l=i(R);et=n(_l,"SPAN",{});var gl=i(et);u(na.$$.fragment,gl),gl.forEach(t),_l.forEach(t),ae=d(ts),lt=n(ts,"SPAN",{});var vl=i(lt);te=r(vl,"SQLite"),vl.forEach(t),ts.forEach(t),Pt=d(a),Da=n(a,"P",{});var yl=i(Da);se=r(yl,"SQLite is a small, lightweight database that is fast and easy to set up. You can use an existing database if you\u2019d like, or follow along and start from scratch."),yl.forEach(t),Lt=d(a),U=n(a,"P",{});var ss=i(U);ee=r(ss,"Start by creating a quick SQLite database with this "),ia=n(ss,"A",{href:!0,rel:!0});var bl=i(ia);le=r(bl,"Covid-19 data"),bl.forEach(t),re=r(ss," from the New York Times:"),ss.forEach(t),At=d(a),u(pa.$$.fragment,a),Ct=d(a),E=n(a,"P",{});var Na=i(E);oe=r(Na,"This creates a "),rt=n(Na,"CODE",{});var $l=i(rt);ne=r($l,"states"),$l.forEach(t),ie=r(Na," table in the "),ot=n(Na,"CODE",{});var wl=i(ot);pe=r(wl,"us_covid_data.db"),wl.forEach(t),fe=r(Na," database which you can now load into a dataset."),Na.forEach(t),Tt=d(a),k=n(a,"P",{});var Ia=i(k);de=r(Ia,"To connect to the database, you\u2019ll need the "),fa=n(Ia,"A",{href:!0,rel:!0});var ql=i(fa);ce=r(ql,"URI string"),ql.forEach(t),he=r(Ia," that identifies your database. Connecting to a database with a URI caches the returned dataset. The URI string differs for each database dialect, so be sure to check the "),da=n(Ia,"A",{href:!0,rel:!0});var jl=i(da);ue=r(jl,"Database URLs"),jl.forEach(t),me=r(Ia," for whichever database you\u2019re using."),Ia.forEach(t),Ft=d(a),xa=n(a,"P",{});var El=i(xa);_e=r(El,"For SQLite, it is:"),El.forEach(t),Qt=d(a),u(ca.$$.fragment,a),Nt=d(a),V=n(a,"P",{});var es=i(V);ge=r(es,"Load the table by passing the table name and URI to "),Sa=n(es,"A",{href:!0});var kl=i(Sa);ve=r(kl,"from_sql()"),kl.forEach(t),ye=r(es,":"),es.forEach(t),It=d(a),u(ha.$$.fragment,a),Rt=d(a),O=n(a,"P",{});var ls=i(O);be=r(ls,"Then you can use all of \u{1F917} Datasets process features like "),Pa=n(ls,"A",{href:!0});var Dl=i(Pa);$e=r(Dl,"filter()"),Dl.forEach(t),we=r(ls," for example:"),ls.forEach(t),Ut=d(a),u(ua.$$.fragment,a),Vt=d(a),La=n(a,"P",{});var xl=i(La);qe=r(xl,"You can also load a dataset from a SQL query instead of an entire table, which is useful for querying and joining multiple tables."),xl.forEach(t),Ot=d(a),Y=n(a,"P",{});var rs=i(Y);je=r(rs,"Load the dataset by passing your query and URI to "),Aa=n(rs,"A",{href:!0});var Sl=i(Aa);Ee=r(Sl,"from_sql()"),Sl.forEach(t),ke=r(rs,":"),rs.forEach(t),Yt=d(a),u(ma.$$.fragment,a),Ht=d(a),H=n(a,"P",{});var os=i(H);De=r(os,"Then you can use all of \u{1F917} Datasets process features like "),Ca=n(os,"A",{href:!0});var Pl=i(Ca);xe=r(Pl,"filter()"),Pl.forEach(t),Se=r(os," for example:"),os.forEach(t),Mt=d(a),u(_a.$$.fragment,a),zt=d(a),C=n(a,"H3",{class:!0});var ns=i(C);M=n(ns,"A",{id:!0,class:!0,href:!0});var Ll=i(M);nt=n(Ll,"SPAN",{});var Al=i(nt);u(ga.$$.fragment,Al),Al.forEach(t),Ll.forEach(t),Pe=d(ns),it=n(ns,"SPAN",{});var Cl=i(it);Le=r(Cl,"PostgreSQL"),Cl.forEach(t),ns.forEach(t),Wt=d(a),z=n(a,"P",{});var is=i(z);Ae=r(is,"You can also connect and load a dataset from a PostgreSQL database, however we won\u2019t directly demonstrate how in the documentation because the example is only meant to be run in a notebook. Instead, take a look at how to install and setup a PostgreSQL server in this "),va=n(is,"A",{href:!0,rel:!0});var Tl=i(va);Ce=r(Tl,"notebook"),Tl.forEach(t),Te=r(is,"!"),is.forEach(t),Gt=d(a),W=n(a,"P",{});var ps=i(W);Fe=r(ps,"After you\u2019ve setup your PostgreSQL database, you can use the "),Ta=n(ps,"A",{href:!0});var Fl=i(Ta);Qe=r(Fl,"from_sql()"),Fl.forEach(t),Ne=r(ps," method to load a dataset from a table or query."),ps.forEach(t),this.h()},h(){c(D,"name","hf:doc:metadata"),c(D,"content",JSON.stringify(Yl)),c(T,"id","load-tabular-data"),c(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T,"href","#load-tabular-data"),c(x,"class","relative group"),c(F,"id","csv-files"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#csv-files"),c(S,"class","relative group"),c(ba,"href","/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset"),c(Q,"id","pandas-dataframes"),c(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q,"href","#pandas-dataframes"),c(P,"class","relative group"),c(sa,"href","https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"),c(sa,"rel","nofollow"),c(ja,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_pandas"),c(Ea,"href","loading#specify-features"),c(ra,"href","https://pandas.pydata.org/docs/reference/api/pandas.Series.html"),c(ra,"rel","nofollow"),c(I,"id","databases"),c(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I,"href","#databases"),c(L,"class","relative group"),c(R,"id","sqlite"),c(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R,"href","#sqlite"),c(A,"class","relative group"),c(ia,"href","https://github.com/nytimes/covid-19-data/blob/master/us-states.csv"),c(ia,"rel","nofollow"),c(fa,"href","https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls"),c(fa,"rel","nofollow"),c(da,"href","https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls"),c(da,"rel","nofollow"),c(Sa,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_sql"),c(Pa,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.filter"),c(Aa,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_sql"),c(Ca,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.filter"),c(M,"id","postgresql"),c(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M,"href","#postgresql"),c(C,"class","relative group"),c(va,"href","https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi"),c(va,"rel","nofollow"),c(Ta,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_sql")},m(a,e){s(document.head,D),p(a,pt,e),p(a,x,e),s(x,T),s(T,Ua),m(B,Ua,null),s(x,fs),s(x,Va),s(Va,ds),p(a,ft,e),p(a,ya,e),s(ya,cs),p(a,dt,e),p(a,q,e),s(q,Oa),s(Oa,hs),s(q,us),s(q,Ya),s(Ya,ms),s(q,_s),s(q,Ha),s(Ha,gs),p(a,ct,e),p(a,S,e),s(S,F),s(F,Ma),m(J,Ma,null),s(S,vs),s(S,za),s(za,ys),p(a,ht,e),p(a,b,e),s(b,bs),s(b,Wa),s(Wa,$s),s(b,ws),s(b,ba),s(ba,qs),s(b,js),s(b,Ga),s(Ga,Es),s(b,ks),p(a,ut,e),m(K,a,e),p(a,mt,e),p(a,$a,e),s($a,Ds),p(a,_t,e),m(X,a,e),p(a,gt,e),p(a,wa,e),s(wa,xs),p(a,vt,e),m(Z,a,e),p(a,yt,e),p(a,qa,e),s(qa,Ss),p(a,bt,e),m(aa,a,e),p(a,$t,e),p(a,P,e),s(P,Q),s(Q,Ba),m(ta,Ba,null),s(P,Ps),s(P,Ja),s(Ja,Ls),p(a,wt,e),p(a,j,e),s(j,As),s(j,sa),s(sa,Cs),s(j,Ts),s(j,ja),s(ja,Fs),s(j,Qs),p(a,qt,e),m(ea,a,e),p(a,jt,e),p(a,N,e),s(N,Ns),s(N,Ka),s(Ka,Is),s(N,Rs),p(a,Et,e),m(la,a,e),p(a,kt,e),p(a,y,e),s(y,Us),s(y,Ea),s(Ea,Vs),s(y,Os),s(y,ra),s(ra,Ys),s(y,Hs),s(y,Xa),s(Xa,Ms),s(y,zs),s(y,Za),s(Za,Ws),s(y,Gs),s(y,at),s(at,Bs),s(y,Js),p(a,Dt,e),p(a,L,e),s(L,I),s(I,tt),m(oa,tt,null),s(L,Ks),s(L,st),s(st,Xs),p(a,xt,e),p(a,ka,e),s(ka,Zs),p(a,St,e),p(a,A,e),s(A,R),s(R,et),m(na,et,null),s(A,ae),s(A,lt),s(lt,te),p(a,Pt,e),p(a,Da,e),s(Da,se),p(a,Lt,e),p(a,U,e),s(U,ee),s(U,ia),s(ia,le),s(U,re),p(a,At,e),m(pa,a,e),p(a,Ct,e),p(a,E,e),s(E,oe),s(E,rt),s(rt,ne),s(E,ie),s(E,ot),s(ot,pe),s(E,fe),p(a,Tt,e),p(a,k,e),s(k,de),s(k,fa),s(fa,ce),s(k,he),s(k,da),s(da,ue),s(k,me),p(a,Ft,e),p(a,xa,e),s(xa,_e),p(a,Qt,e),m(ca,a,e),p(a,Nt,e),p(a,V,e),s(V,ge),s(V,Sa),s(Sa,ve),s(V,ye),p(a,It,e),m(ha,a,e),p(a,Rt,e),p(a,O,e),s(O,be),s(O,Pa),s(Pa,$e),s(O,we),p(a,Ut,e),m(ua,a,e),p(a,Vt,e),p(a,La,e),s(La,qe),p(a,Ot,e),p(a,Y,e),s(Y,je),s(Y,Aa),s(Aa,Ee),s(Y,ke),p(a,Yt,e),m(ma,a,e),p(a,Ht,e),p(a,H,e),s(H,De),s(H,Ca),s(Ca,xe),s(H,Se),p(a,Mt,e),m(_a,a,e),p(a,zt,e),p(a,C,e),s(C,M),s(M,nt),m(ga,nt,null),s(C,Pe),s(C,it),s(it,Le),p(a,Wt,e),p(a,z,e),s(z,Ae),s(z,va),s(va,Ce),s(z,Te),p(a,Gt,e),p(a,W,e),s(W,Fe),s(W,Ta),s(Ta,Qe),s(W,Ne),Bt=!0},p:Ul,i(a){Bt||(_(B.$$.fragment,a),_(J.$$.fragment,a),_(K.$$.fragment,a),_(X.$$.fragment,a),_(Z.$$.fragment,a),_(aa.$$.fragment,a),_(ta.$$.fragment,a),_(ea.$$.fragment,a),_(la.$$.fragment,a),_(oa.$$.fragment,a),_(na.$$.fragment,a),_(pa.$$.fragment,a),_(ca.$$.fragment,a),_(ha.$$.fragment,a),_(ua.$$.fragment,a),_(ma.$$.fragment,a),_(_a.$$.fragment,a),_(ga.$$.fragment,a),Bt=!0)},o(a){g(B.$$.fragment,a),g(J.$$.fragment,a),g(K.$$.fragment,a),g(X.$$.fragment,a),g(Z.$$.fragment,a),g(aa.$$.fragment,a),g(ta.$$.fragment,a),g(ea.$$.fragment,a),g(la.$$.fragment,a),g(oa.$$.fragment,a),g(na.$$.fragment,a),g(pa.$$.fragment,a),g(ca.$$.fragment,a),g(ha.$$.fragment,a),g(ua.$$.fragment,a),g(ma.$$.fragment,a),g(_a.$$.fragment,a),g(ga.$$.fragment,a),Bt=!1},d(a){t(D),a&&t(pt),a&&t(x),v(B),a&&t(ft),a&&t(ya),a&&t(dt),a&&t(q),a&&t(ct),a&&t(S),v(J),a&&t(ht),a&&t(b),a&&t(ut),v(K,a),a&&t(mt),a&&t($a),a&&t(_t),v(X,a),a&&t(gt),a&&t(wa),a&&t(vt),v(Z,a),a&&t(yt),a&&t(qa),a&&t(bt),v(aa,a),a&&t($t),a&&t(P),v(ta),a&&t(wt),a&&t(j),a&&t(qt),v(ea,a),a&&t(jt),a&&t(N),a&&t(Et),v(la,a),a&&t(kt),a&&t(y),a&&t(Dt),a&&t(L),v(oa),a&&t(xt),a&&t(ka),a&&t(St),a&&t(A),v(na),a&&t(Pt),a&&t(Da),a&&t(Lt),a&&t(U),a&&t(At),v(pa,a),a&&t(Ct),a&&t(E),a&&t(Tt),a&&t(k),a&&t(Ft),a&&t(xa),a&&t(Qt),v(ca,a),a&&t(Nt),a&&t(V),a&&t(It),v(ha,a),a&&t(Rt),a&&t(O),a&&t(Ut),v(ua,a),a&&t(Vt),a&&t(La),a&&t(Ot),a&&t(Y),a&&t(Yt),v(ma,a),a&&t(Ht),a&&t(H),a&&t(Mt),v(_a,a),a&&t(zt),a&&t(C),v(ga),a&&t(Wt),a&&t(z),a&&t(Gt),a&&t(W)}}}const Yl={local:"load-tabular-data",sections:[{local:"csv-files",title:"CSV files"},{local:"pandas-dataframes",title:"Pandas DataFrames"},{local:"databases",sections:[{local:"sqlite",title:"SQLite"},{local:"postgresql",title:"PostgreSQL"}],title:"Databases"}],title:"Load tabular data"};function Hl(Ie){return Vl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gl extends Ql{constructor(D){super();Nl(this,D,Hl,Ol,Il,{})}}export{Gl as default,Yl as metadata};
