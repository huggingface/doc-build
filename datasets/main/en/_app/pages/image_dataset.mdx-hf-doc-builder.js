import{S as ac,i as sc,s as oc,e as l,k as p,w as _,t as s,M as lc,c as r,d as a,m as f,a as n,x as v,h as o,b as h,G as t,g as d,y as $,q as y,o as b,B as w,v as rc}from"../chunks/vendor-hf-doc-builder.js";import{T as Vt}from"../chunks/Tip-hf-doc-builder.js";import{I as R}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as I}from"../chunks/CodeBlock-hf-doc-builder.js";function nc(P){let c,q,u,E,j;return{c(){c=l("p"),q=s("You can control access to your dataset by requiring users to share their contact information first. Check out the "),u=l("a"),E=s("Gated datasets"),j=s(" guide for more information about how to enable this feature on the Hub."),this.h()},l(m){c=r(m,"P",{});var g=n(c);q=o(g,"You can control access to your dataset by requiring users to share their contact information first. Check out the "),u=r(g,"A",{href:!0,rel:!0});var A=n(u);E=o(A,"Gated datasets"),A.forEach(a),j=o(g," guide for more information about how to enable this feature on the Hub."),g.forEach(a),this.h()},h(){h(u,"href","https://huggingface.co/docs/hub/datasets-gated"),h(u,"rel","nofollow")},m(m,g){d(m,c,g),t(c,q),t(c,u),t(u,E),t(c,j)},d(m){m&&a(c)}}}function ic(P){let c,q,u,E,j,m,g,A;return{c(){c=l("p"),q=s("If all image files are contained in a single directory or if they are not on the same level of directory structure, "),u=l("code"),E=s("label"),j=s(" column won\u2019t be added automatically. If you need it, set "),m=l("code"),g=s("drop_labels=False"),A=s(" explicitly.")},l(C){c=r(C,"P",{});var k=n(c);q=o(k,"If all image files are contained in a single directory or if they are not on the same level of directory structure, "),u=r(k,"CODE",{});var S=n(u);E=o(S,"label"),S.forEach(a),j=o(k," column won\u2019t be added automatically. If you need it, set "),m=r(k,"CODE",{});var G=n(m);g=o(G,"drop_labels=False"),G.forEach(a),A=o(k," explicitly."),k.forEach(a)},m(C,k){d(C,c,k),t(c,q),t(c,u),t(u,E),t(c,j),t(c,m),t(m,g),t(c,A)},d(C){C&&a(c)}}}function dc(P){let c,q,u,E,j,m,g,A;return{c(){c=l("p"),q=s("If metadata files are present, the inferred labels based on the directory name are dropped by default. To include those labels, set "),u=l("code"),E=s("drop_labels=False"),j=s(" in "),m=l("code"),g=s("load_dataset"),A=s(".")},l(C){c=r(C,"P",{});var k=n(c);q=o(k,"If metadata files are present, the inferred labels based on the directory name are dropped by default. To include those labels, set "),u=r(k,"CODE",{});var S=n(u);E=o(S,"drop_labels=False"),S.forEach(a),j=o(k," in "),m=r(k,"CODE",{});var G=n(m);g=o(G,"load_dataset"),G.forEach(a),A=o(k,"."),k.forEach(a)},m(C,k){d(C,c,k),t(c,q),t(c,u),t(u,E),t(c,j),t(c,m),t(m,g),t(c,A)},d(C){C&&a(c)}}}function pc(P){let c,q,u,E,j;return{c(){c=l("p"),q=s("To help you get started, we created a loading script "),u=l("a"),E=s("template"),j=s(" you can copy and use as a starting point!"),this.h()},l(m){c=r(m,"P",{});var g=n(c);q=o(g,"To help you get started, we created a loading script "),u=r(g,"A",{href:!0,rel:!0});var A=n(u);E=o(A,"template"),A.forEach(a),j=o(g," you can copy and use as a starting point!"),g.forEach(a),this.h()},h(){h(u,"href","https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py"),h(u,"rel","nofollow")},m(m,g){d(m,c,g),t(c,q),t(c,u),t(u,E),t(c,j)},d(m){m&&a(c)}}}function fc(P){let c,q,u,E,j;return{c(){c=l("p"),q=s("You\u2019ll notice a lot of the dataset information is defined earlier in the loading script which makes it easier to read. There are also other "),u=l("code"),E=s("~Datasets.Features"),j=s(" you can input, so be sure to check out the full list for more details.")},l(m){c=r(m,"P",{});var g=n(c);q=o(g,"You\u2019ll notice a lot of the dataset information is defined earlier in the loading script which makes it easier to read. There are also other "),u=r(g,"CODE",{});var A=n(u);E=o(A,"~Datasets.Features"),A.forEach(a),j=o(g," you can input, so be sure to check out the full list for more details."),g.forEach(a)},m(m,g){d(m,c,g),t(c,q),t(c,u),t(u,E),t(c,j)},d(m){m&&a(c)}}}function hc(P){let c,q,u,E,j,m,g,A;return{c(){c=l("p"),q=s("To stream a TAR archive file, you need to use "),u=l("a"),E=s("DownloadManager.iter_archive()"),j=s("! The "),m=l("a"),g=s("DownloadManager.download_and_extract()"),A=s(" function does not support TAR archives in streaming mode."),this.h()},l(C){c=r(C,"P",{});var k=n(c);q=o(k,"To stream a TAR archive file, you need to use "),u=r(k,"A",{href:!0});var S=n(u);E=o(S,"DownloadManager.iter_archive()"),S.forEach(a),j=o(k,"! The "),m=r(k,"A",{href:!0});var G=n(m);g=o(G,"DownloadManager.download_and_extract()"),G.forEach(a),A=o(k," function does not support TAR archives in streaming mode."),k.forEach(a),this.h()},h(){h(u,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),h(m,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract")},m(C,k){d(C,c,k),t(c,q),t(c,u),t(u,E),t(c,j),t(c,m),t(m,g),t(c,A)},d(C){C&&a(c)}}}function cc(P){let c,q,u,E,j;return{c(){c=l("p"),q=s("To stream a TAR archive file, the "),u=l("code"),E=s("metadata_path"),j=s(" needs to be opened and read first. TAR files are accessed and yielded sequentially. This means you need to have the metadata information in hand first so you can yield it with its corresponding image.")},l(m){c=r(m,"P",{});var g=n(c);q=o(g,"To stream a TAR archive file, the "),u=r(g,"CODE",{});var A=n(u);E=o(A,"metadata_path"),A.forEach(a),j=o(g," needs to be opened and read first. TAR files are accessed and yielded sequentially. This means you need to have the metadata information in hand first so you can yield it with its corresponding image."),g.forEach(a)},m(m,g){d(m,c,g),t(c,q),t(c,u),t(u,E),t(c,j)},d(m){m&&a(c)}}}function uc(P){let c,q,u,E,j,m,g,A,C,k,S,G,_o,ge,tt,vr,Sa,$r,yr,br,La,wr,vo,_e,$o,te,ve,Fa,at,Er,Na,jr,yo,z,qr,Ba,kr,Ar,Ra,Ir,Cr,bo,st,wo,M,xr,Ga,Dr,Tr,Wt,Pr,Or,Ma,Sr,Lr,Eo,ot,jo,$e,Fr,Ua,Nr,Br,qo,lt,ko,ye,Ao,be,Rr,Ha,Gr,Mr,Io,rt,Co,V,Ur,Ya,Hr,Yr,za,zr,Vr,xo,nt,Do,we,To,ae,Ee,Va,it,Wr,Wa,Jr,Po,je,Xr,Ja,Kr,Qr,Oo,dt,So,W,Zr,Xa,en,tn,Ka,an,sn,Lo,pt,Fo,se,qe,Qa,ft,on,Za,ln,No,ke,rn,es,nn,dn,Bo,ht,Ro,J,pn,ts,fn,hn,as,cn,un,Go,ct,Mo,oe,Ae,ss,ut,mn,os,gn,Uo,U,_n,Jt,vn,$n,mt,yn,bn,Xt,wn,En,Ho,Ie,jn,Kt,qn,kn,Yo,gt,zo,le,Ce,ls,_t,An,rs,In,Vo,Qt,Cn,Wo,vt,Jo,Zt,xn,Xo,$t,Ko,xe,Dn,yt,Tn,Pn,Qo,x,ns,On,Sn,is,Ln,Fn,ds,Nn,Bn,ps,Rn,Gn,fs,Mn,Un,hs,Hn,Yn,cs,zn,Zo,De,Vn,bt,Wn,Jn,el,Te,tl,re,Pe,us,wt,Xn,ms,Kn,al,Et,ea,Qn,Zn,sl,X,ta,gs,ei,ti,ai,aa,_s,si,oi,li,sa,vs,ri,ni,ol,Oe,ii,oa,di,pi,ll,jt,rl,ne,Se,$s,qt,fi,ys,hi,nl,Le,ci,kt,ui,mi,il,H,gi,la,_i,vi,bs,$i,yi,ws,bi,wi,dl,At,pl,Fe,Ei,ra,ji,qi,fl,Ne,ie,ki,Es,Ai,Ii,js,Ci,xi,Di,qs,Ti,hl,It,cl,Be,Pi,ks,Oi,Si,ul,Ct,ml,de,Re,As,xt,Li,Is,Fi,gl,K,Ni,na,Bi,Ri,Cs,Gi,Mi,_l,Dt,vl,ia,Ui,$l,O,da,xs,Hi,Yi,zi,Ge,Ds,Vi,Wi,pa,Ji,Xi,Ki,fa,Ts,Qi,Zi,ed,ha,Ps,td,ad,sd,ca,Os,od,ld,rd,ua,Ss,nd,id,yl,Me,bl,Tt,wl,pe,Ue,Ls,Pt,dd,Fs,pd,El,ma,fd,jl,He,fe,Ot,hd,ga,cd,ud,md,he,St,gd,Ns,_d,vd,$d,Bs,yd,bd,Rs,wd,Ed,Gs,jd,qd,Lt,B,kd,_a,Ad,Id,Ms,Cd,xd,Us,Dd,Td,Hs,Pd,Od,Sd,T,Ld,Ys,Fd,Nd,zs,Bd,Rd,va,Gd,Md,Vs,Ud,Hd,Ws,Yd,zd,Js,Vd,Wd,ql,Ye,kl,Ft,Al,ce,ze,Xs,Nt,Jd,Ks,Xd,Il,D,Kd,$a,Qd,Zd,Qs,ep,tp,Zs,ap,sp,eo,op,lp,to,rp,np,ao,ip,dp,Cl,Ve,xl,ya,pp,Dl,Bt,Tl,ue,We,so,Rt,fp,oo,hp,Pl,Je,cp,lo,up,mp,Ol,Xe,gp,ro,_p,vp,Sl,Gt,Ll,Q,$p,no,yp,bp,io,wp,Ep,Fl,me,Ke,po,Mt,jp,fo,qp,Nl,Z,kp,ba,Ap,Ip,wa,Cp,xp,Bl,Ea,Dp,Rl,Ut,Gl;return m=new R({}),_e=new Vt({props:{$$slots:{default:[nc]},$$scope:{ctx:P}}}),at=new R({}),st=new I({props:{code:`folder/train/dog/golden_retriever.png
folder/train/dog/german_shepherd.png
folder/train/dog/chihuahua.png

folder/train/cat/maine_coon.png
folder/train/cat/bengal.png
folder/train/cat/birman.png`,highlighted:`folder<span class="hljs-regexp">/train/</span>dog/golden_retriever.png
folder<span class="hljs-regexp">/train/</span>dog/german_shepherd.png
folder<span class="hljs-regexp">/train/</span>dog/chihuahua.png

folder<span class="hljs-regexp">/train/</span>cat/maine_coon.png
folder<span class="hljs-regexp">/train/</span>cat/bengal.png
folder<span class="hljs-regexp">/train/</span>cat/birman.png`}}),ot=new I({props:{code:`from datasets import load_dataset

dataset = load_dataset("imagefolder", data_dir="/path/to/folder")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>)`}}),lt=new I({props:{code:`folder/train/dog/golden_retriever.png
folder/train/cat/maine_coon.png
folder/test/dog/german_shepherd.png
folder/test/cat/bengal.png`,highlighted:`folder<span class="hljs-regexp">/train/</span>dog/golden_retriever.png
folder<span class="hljs-regexp">/train/</span>cat/maine_coon.png
folder<span class="hljs-regexp">/test/</span>dog/german_shepherd.png
folder<span class="hljs-regexp">/test/</span>cat/bengal.png`}}),ye=new Vt({props:{warning:!0,$$slots:{default:[ic]},$$scope:{ctx:P}}}),rt=new I({props:{code:`folder/train/metadata.jsonl
folder/train/0001.png
folder/train/0002.png
folder/train/0003.png`,highlighted:`folder<span class="hljs-regexp">/train/m</span>etadata.jsonl
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0001</span>.png
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0002</span>.png
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0003</span>.png`}}),nt=new I({props:{code:`{"file_name": "0001.png", "additional_feature": "This is a first value of a text feature you added to your images"}
{"file_name": "0002.png", "additional_feature": "This is a second value of a text feature you added to your images"}
{"file_name": "0003.png", "additional_feature": "This is a third value of a text feature you added to your images"}`,highlighted:`{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0001.png&quot;</span>, <span class="hljs-comment">&quot;additional_feature&quot;</span>: <span class="hljs-comment">&quot;This is a first value of a text feature you added to your images&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0002.png&quot;</span>, <span class="hljs-comment">&quot;additional_feature&quot;</span>: <span class="hljs-comment">&quot;This is a second value of a text feature you added to your images&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0003.png&quot;</span>, <span class="hljs-comment">&quot;additional_feature&quot;</span>: <span class="hljs-comment">&quot;This is a third value of a text feature you added to your images&quot;</span>}`}}),we=new Vt({props:{$$slots:{default:[dc]},$$scope:{ctx:P}}}),it=new R({}),dt=new I({props:{code:`{"file_name": "0001.png", "text": "This is a golden retriever playing with a ball"}
{"file_name": "0002.png", "text": "A german shepherd"}
{"file_name": "0003.png", "text": "One chihuahua"}`,highlighted:`{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0001.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;This is a golden retriever playing with a ball&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0002.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;A german shepherd&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0003.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;One chihuahua&quot;</span>}`}}),pt=new I({props:{code:`dataset = load_dataset("imagefolder", data_dir="/path/to/folder", split="train")
dataset[0]["text"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>]
<span class="hljs-string">&quot;This is a golden retriever playing with a ball&quot;</span>`}}),ft=new R({}),ht=new I({props:{code:`{"file_name": "0001.png", "objects": {"bbox": [[302.0, 109.0, 73.0, 52.0]], "categories": [0]}}
{"file_name": "0002.png", "objects": {"bbox": [[810.0, 100.0, 57.0, 28.0]], "categories": [1]}}
{"file_name": "0003.png", "objects": {"bbox": [[160.0, 31.0, 248.0, 616.0], [741.0, 68.0, 202.0, 401.0]], "categories": [2, 2]}}`,highlighted:`{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0001.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[302.0, 109.0, 73.0, 52.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">0</span>]}}
{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0002.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[810.0, 100.0, 57.0, 28.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">1</span>]}}
{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0003.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[160.0, 31.0, 248.0, 616.0], [741.0, 68.0, 202.0, 401.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]}}`}}),ct=new I({props:{code:`dataset = load_dataset("imagefolder", data_dir="/path/to/folder", split="train")
dataset[0]["objects"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;objects&quot;</span>]
{<span class="hljs-string">&quot;bbox&quot;</span>: [[<span class="hljs-number">302.0</span>, <span class="hljs-number">109.0</span>, <span class="hljs-number">73.0</span>, <span class="hljs-number">52.0</span>]], <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">0</span>]}`}}),ut=new R({}),gt=new I({props:{code:`from datasets import load_dataset

dataset = load_dataset("imagefolder", data_dir="/path/to/folder", split="train")
dataset.push_to_hub("stevhliu/my-image-captioning-dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.push_to_hub(<span class="hljs-string">&quot;stevhliu/my-image-captioning-dataset&quot;</span>)`}}),_t=new R({}),vt=new I({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 my_dataset.py
\u2514\u2500\u2500 data/  # optional, may contain your images or TAR archives`,highlighted:`my_dataset/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 my_dataset.py
\u2514\u2500\u2500 <span class="hljs-title">data</span>/  <span class="hljs-comment"># optional, may contain your images or TAR archives</span>`}}),$t=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset("path/to/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;path/to/my_dataset&quot;</span>)`}}),Te=new Vt({props:{$$slots:{default:[pc]},$$scope:{ctx:P}}}),wt=new R({}),jt=new I({props:{code:`class Food101(datasets.GeneratorBasedBuilder):
    """Food-101 Images dataset"""

    def _info(self):

    def _split_generators(self, dl_manager):

    def _generate_examples(self, images, metadata_path):`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">Food101</span>(datasets.GeneratorBasedBuilder):
    <span class="hljs-string">&quot;&quot;&quot;Food-101 Images dataset&quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager</span>):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, images, metadata_path</span>):`}}),qt=new R({}),At=new I({props:{code:`class Food101Config(datasets.BuilderConfig):
    """Builder Config for Food-101"""
 
    def __init__(self, data_url, metadata_urls, **kwargs):
        """BuilderConfig for Food-101.
        Args:
          data_url: \`string\`, url to download the zip file from.
          metadata_urls: dictionary with keys 'train' and 'validation' containing the archive metadata URLs
          **kwargs: keyword arguments forwarded to super.
        """
        super(Food101Config, self).__init__(version=datasets.Version("1.0.0"), **kwargs)
        self.data_url = data_url
        self.metadata_urls = metadata_urls`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">Food101Config</span>(datasets.BuilderConfig):
    <span class="hljs-string">&quot;&quot;&quot;Builder Config for Food-101&quot;&quot;&quot;</span>
 
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data_url, metadata_urls, **kwargs</span>):
        <span class="hljs-string">&quot;&quot;&quot;BuilderConfig for Food-101.
        Args:
          data_url: \`string\`, url to download the zip file from.
          metadata_urls: dictionary with keys &#x27;train&#x27; and &#x27;validation&#x27; containing the archive metadata URLs
          **kwargs: keyword arguments forwarded to super.
        &quot;&quot;&quot;</span>
        <span class="hljs-built_in">super</span>(Food101Config, self).__init__(version=datasets.Version(<span class="hljs-string">&quot;1.0.0&quot;</span>), **kwargs)
        self.data_url = data_url
        self.metadata_urls = metadata_urls`}}),It=new I({props:{code:`class Food101(datasets.GeneratorBasedBuilder):
    """Food-101 Images dataset"""
 
    BUILDER_CONFIGS = [
        Food101Config(
            name="breakfast",
            description="Food types commonly eaten during breakfast.",
            data_url="https://link-to-breakfast-foods.zip",
            metadata_urls={
                "train": "https://link-to-breakfast-foods-train.txt", 
                "validation": "https://link-to-breakfast-foods-validation.txt"
            },
        ,
        Food101Config(
            name="dinner",
            description="Food types commonly eaten during dinner.",
            data_url="https://link-to-dinner-foods.zip",
            metadata_urls={
                "train": "https://link-to-dinner-foods-train.txt", 
                "validation": "https://link-to-dinner-foods-validation.txt"
            },
        )...
    ]`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">Food101</span>(datasets.GeneratorBasedBuilder):
    <span class="hljs-string">&quot;&quot;&quot;Food-101 Images dataset&quot;&quot;&quot;</span>
 
    BUILDER_CONFIGS = [
        Food101Config(
            name=<span class="hljs-string">&quot;breakfast&quot;</span>,
            description=<span class="hljs-string">&quot;Food types commonly eaten during breakfast.&quot;</span>,
            data_url=<span class="hljs-string">&quot;https://link-to-breakfast-foods.zip&quot;</span>,
            metadata_urls={
                <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;https://link-to-breakfast-foods-train.txt&quot;</span>, 
                <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;https://link-to-breakfast-foods-validation.txt&quot;</span>
            },
        ,
        Food101Config(
            name=<span class="hljs-string">&quot;dinner&quot;</span>,
            description=<span class="hljs-string">&quot;Food types commonly eaten during dinner.&quot;</span>,
            data_url=<span class="hljs-string">&quot;https://link-to-dinner-foods.zip&quot;</span>,
            metadata_urls={
                <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;https://link-to-dinner-foods-train.txt&quot;</span>, 
                <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;https://link-to-dinner-foods-validation.txt&quot;</span>
            },
        )...
    ]`}}),Ct=new I({props:{code:`from datasets import load_dataset
ds = load_dataset("food101", "breakfast", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, <span class="hljs-string">&quot;breakfast&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),xt=new R({}),Dt=new I({props:{code:`from datasets import load_dataset_builder
ds_builder = load_dataset_builder("food101")
ds_builder.info`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder = load_dataset_builder(<span class="hljs-string">&quot;food101&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder.info`}}),Me=new Vt({props:{$$slots:{default:[fc]},$$scope:{ctx:P}}}),Tt=new I({props:{code:`def _info(self):
    return datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                "image": datasets.Image(),
                "label": datasets.ClassLabel(names=_NAMES),
            }
        ),
        supervised_keys=("image", "label"),
        homepage=_HOMEPAGE,
        citation=_CITATION,
        license=_LICENSE,
        task_templates=[ImageClassification(image_column="image", label_column="label")],
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">return</span> datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                <span class="hljs-string">&quot;image&quot;</span>: datasets.Image(),
                <span class="hljs-string">&quot;label&quot;</span>: datasets.ClassLabel(names=_NAMES),
            }
        ),
        supervised_keys=(<span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>),
        homepage=_HOMEPAGE,
        citation=_CITATION,
        license=_LICENSE,
        task_templates=[ImageClassification(image_column=<span class="hljs-string">&quot;image&quot;</span>, label_column=<span class="hljs-string">&quot;label&quot;</span>)],
    )`}}),Pt=new R({}),Ye=new Vt({props:{warning:!0,$$slots:{default:[hc]},$$scope:{ctx:P}}}),Ft=new I({props:{code:`def _split_generators(self, dl_manager):
    archive_path = dl_manager.download(_BASE_URL)
    split_metadata_paths = dl_manager.download(_METADATA_URLS)
    return [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                "images": dl_manager.iter_archive(archive_path),
                "metadata_path": split_metadata_paths["train"],
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.VALIDATION,
            gen_kwargs={
                "images": dl_manager.iter_archive(archive_path),
                "metadata_path": split_metadata_paths["test"],
            },
        ),
    ]`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager</span>):
    archive_path = dl_manager.download(_BASE_URL)
    split_metadata_paths = dl_manager.download(_METADATA_URLS)
    <span class="hljs-keyword">return</span> [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                <span class="hljs-string">&quot;images&quot;</span>: dl_manager.iter_archive(archive_path),
                <span class="hljs-string">&quot;metadata_path&quot;</span>: split_metadata_paths[<span class="hljs-string">&quot;train&quot;</span>],
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.VALIDATION,
            gen_kwargs={
                <span class="hljs-string">&quot;images&quot;</span>: dl_manager.iter_archive(archive_path),
                <span class="hljs-string">&quot;metadata_path&quot;</span>: split_metadata_paths[<span class="hljs-string">&quot;test&quot;</span>],
            },
        ),
    ]`}}),Nt=new R({}),Ve=new Vt({props:{warning:!0,$$slots:{default:[cc]},$$scope:{ctx:P}}}),Bt=new I({props:{code:`def _generate_examples(self, images, metadata_path):
    """Generate images and labels for splits."""
    with open(metadata_path, encoding="utf-8") as f:
        files_to_keep = set(f.read().split("\\n"))
    for file_path, file_obj in images:
        if file_path.startswith(_IMAGES_DIR):
            if file_path[len(_IMAGES_DIR) : -len(".jpg")] in files_to_keep:
                label = file_path.split("/")[2]
                yield file_path, {
                    "image": {"path": file_path, "bytes": file_obj.read()},
                    "label": label,
                }`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, images, metadata_path</span>):
    <span class="hljs-string">&quot;&quot;&quot;Generate images and labels for splits.&quot;&quot;&quot;</span>
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(metadata_path, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
        files_to_keep = <span class="hljs-built_in">set</span>(f.read().split(<span class="hljs-string">&quot;\\n&quot;</span>))
    <span class="hljs-keyword">for</span> file_path, file_obj <span class="hljs-keyword">in</span> images:
        <span class="hljs-keyword">if</span> file_path.startswith(_IMAGES_DIR):
            <span class="hljs-keyword">if</span> file_path[<span class="hljs-built_in">len</span>(_IMAGES_DIR) : -<span class="hljs-built_in">len</span>(<span class="hljs-string">&quot;.jpg&quot;</span>)] <span class="hljs-keyword">in</span> files_to_keep:
                label = file_path.split(<span class="hljs-string">&quot;/&quot;</span>)[<span class="hljs-number">2</span>]
                <span class="hljs-keyword">yield</span> file_path, {
                    <span class="hljs-string">&quot;image&quot;</span>: {<span class="hljs-string">&quot;path&quot;</span>: file_path, <span class="hljs-string">&quot;bytes&quot;</span>: file_obj.read()},
                    <span class="hljs-string">&quot;label&quot;</span>: label,
                }`}}),Rt=new R({}),Gt=new I({props:{code:"datasets-cli test path/to/<your-dataset-loading-script> --save_info --all_configs",highlighted:'datasets-cli <span class="hljs-built_in">test</span> path/to/&lt;your-dataset-loading-script&gt; --save_info --all_configs'}}),Mt=new R({}),Ut=new I({props:{code:`from datasets import load_dataset
load_dataset("<username>/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)`}}),{c(){c=l("meta"),q=p(),u=l("h1"),E=l("a"),j=l("span"),_(m.$$.fragment),g=p(),A=l("span"),C=s("Create an image dataset"),k=p(),S=l("p"),G=s("There are two methods for creating and sharing an image dataset. This guide will show you how to:"),_o=p(),ge=l("ul"),tt=l("li"),vr=s("Create an image dataset with "),Sa=l("code"),$r=s("ImageFolder"),yr=s(" and some metadata. This is a no-code solution for quickly creating an image dataset."),br=p(),La=l("li"),wr=s("Create an image dataset by writing a loading script. This method is a bit more involved, but you have greater flexibility over how a dataset is defined, downloaded, and generated."),vo=p(),_(_e.$$.fragment),$o=p(),te=l("h2"),ve=l("a"),Fa=l("span"),_(at.$$.fragment),Er=p(),Na=l("span"),jr=s("ImageFolder"),yo=p(),z=l("p"),qr=s("The "),Ba=l("code"),kr=s("ImageFolder"),Ar=s(" is a dataset builder designed to quickly load an image dataset without requiring you to write any code. "),Ra=l("code"),Ir=s("ImageFolder"),Cr=s(" automatically infers the class labels of your dataset based on the directory name. Just store your dataset in a directory structure like:"),bo=p(),_(st.$$.fragment),wo=p(),M=l("p"),xr=s("Then users can load your dataset by specifying "),Ga=l("code"),Dr=s("imagefolder"),Tr=s(" in "),Wt=l("a"),Pr=s("load_dataset()"),Or=s(" and the directory in "),Ma=l("code"),Sr=s("data_dir"),Lr=s(":"),Eo=p(),_(ot.$$.fragment),jo=p(),$e=l("p"),Fr=s("You can also use "),Ua=l("code"),Nr=s("imagefolder"),Br=s(" to load datasets involving multiple splits. To do so, your dataset directory should have the following structure:"),qo=p(),_(lt.$$.fragment),ko=p(),_(ye.$$.fragment),Ao=p(),be=l("p"),Rr=s("If there is additional information you\u2019d like to include about your dataset, like text captions or bounding boxes, add it as a "),Ha=l("code"),Gr=s("metadata.jsonl"),Mr=s(" file in your folder. This lets you quickly create datasets for different computer vision tasks like text captioning or object detection."),Io=p(),_(rt.$$.fragment),Co=p(),V=l("p"),Ur=s("Your "),Ya=l("code"),Hr=s("metadata.jsonl"),Yr=s(" file must have a "),za=l("code"),zr=s("file_name"),Vr=s(" column which links image files with their metadata:"),xo=p(),_(nt.$$.fragment),Do=p(),_(we.$$.fragment),To=p(),ae=l("h3"),Ee=l("a"),Va=l("span"),_(it.$$.fragment),Wr=p(),Wa=l("span"),Jr=s("Image captioning"),Po=p(),je=l("p"),Xr=s("Image captioning datasets have text describing an image. An example "),Ja=l("code"),Kr=s("metadata.jsonl"),Qr=s(" may look like:"),Oo=p(),_(dt.$$.fragment),So=p(),W=l("p"),Zr=s("Load the dataset with "),Xa=l("code"),en=s("ImageFolder"),tn=s(", and it will create a "),Ka=l("code"),an=s("text"),sn=s(" column for the image captions:"),Lo=p(),_(pt.$$.fragment),Fo=p(),se=l("h3"),qe=l("a"),Qa=l("span"),_(ft.$$.fragment),on=p(),Za=l("span"),ln=s("Object detection"),No=p(),ke=l("p"),rn=s("Object detection datasets have bounding boxes and categories identifying objects in an image. An example "),es=l("code"),nn=s("metadata.jsonl"),dn=s(" may look like:"),Bo=p(),_(ht.$$.fragment),Ro=p(),J=l("p"),pn=s("Load the dataset with "),ts=l("code"),fn=s("ImageFolder"),hn=s(", and it will create a "),as=l("code"),cn=s("objects"),un=s(" column with the bounding boxes and the categories:"),Go=p(),_(ct.$$.fragment),Mo=p(),oe=l("h3"),Ae=l("a"),ss=l("span"),_(ut.$$.fragment),mn=p(),os=l("span"),gn=s("Upload dataset to the Hub"),Uo=p(),U=l("p"),_n=s("Once you\u2019ve created a dataset, you can share it to the Hub with the "),Jt=l("a"),vn=s("push_to_hub()"),$n=s(" method. Make sure you have the "),mt=l("a"),yn=s("huggingface_hub"),bn=s(" library installed and you\u2019re logged in to your Hugging Face account (see the "),Xt=l("a"),wn=s("Upload with Python tutorial"),En=s(" for more details)."),Ho=p(),Ie=l("p"),jn=s("Upload your dataset with "),Kt=l("a"),qn=s("push_to_hub()"),kn=s(":"),Yo=p(),_(gt.$$.fragment),zo=p(),le=l("h2"),Ce=l("a"),ls=l("span"),_(_t.$$.fragment),An=p(),rs=l("span"),In=s("Loading script"),Vo=p(),Qt=l("p"),Cn=s("Write a dataset loading script to share a dataset. It defines a dataset\u2019s splits and configurations, and handles downloading and generating a dataset. The script is located in the same folder or repository as the dataset and should have the same name."),Wo=p(),_(vt.$$.fragment),Jo=p(),Zt=l("p"),xn=s("This structure allows your dataset to be loaded in one line:"),Xo=p(),_($t.$$.fragment),Ko=p(),xe=l("p"),Dn=s("This guide will show you how to create a dataset loading script for image datasets, which is a bit different from "),yt=l("a"),Tn=s("creating a loading script for text datasets"),Pn=s(". You\u2019ll learn how to:"),Qo=p(),x=l("ul"),ns=l("li"),On=s("Create a dataset builder class."),Sn=p(),is=l("li"),Ln=s("Create dataset configurations."),Fn=p(),ds=l("li"),Nn=s("Add dataset metadata."),Bn=p(),ps=l("li"),Rn=s("Download and define the dataset splits."),Gn=p(),fs=l("li"),Mn=s("Generate the dataset."),Un=p(),hs=l("li"),Hn=s("Generate the dataset metadata (optional)."),Yn=p(),cs=l("li"),zn=s("Upload the dataset to the Hub."),Zo=p(),De=l("p"),Vn=s("The best way to learn is to open up an existing image dataset loading script, like "),bt=l("a"),Wn=s("Food-101"),Jn=s(", and follow along!"),el=p(),_(Te.$$.fragment),tl=p(),re=l("h3"),Pe=l("a"),us=l("span"),_(wt.$$.fragment),Xn=p(),ms=l("span"),Kn=s("Create a dataset builder class"),al=p(),Et=l("p"),ea=l("a"),Qn=s("GeneratorBasedBuilder"),Zn=s(" is the base class for datasets generated from a dictionary generator. Within this class, there are three methods to help create your dataset:"),sl=p(),X=l("ul"),ta=l("li"),gs=l("code"),ei=s("info"),ti=s(" stores information about your dataset like its description, license, and features."),ai=p(),aa=l("li"),_s=l("code"),si=s("split_generators"),oi=s(" downloads the dataset and defines its splits."),li=p(),sa=l("li"),vs=l("code"),ri=s("generate_examples"),ni=s(" generates the images and labels for each split."),ol=p(),Oe=l("p"),ii=s("Start by creating your dataset class as a subclass of "),oa=l("a"),di=s("GeneratorBasedBuilder"),pi=s(" and add the three methods. Don\u2019t worry about filling in each of these methods yet, you\u2019ll develop those over the next few sections:"),ll=p(),_(jt.$$.fragment),rl=p(),ne=l("h4"),Se=l("a"),$s=l("span"),_(qt.$$.fragment),fi=p(),ys=l("span"),hi=s("Multiple configurations"),nl=p(),Le=l("p"),ci=s("In some cases, a dataset may have more than one configuration. For example, if you check out the "),kt=l("a"),ui=s("Imagenette dataset"),mi=s(", you\u2019ll notice there are three subsets."),il=p(),H=l("p"),gi=s("To create different configurations, use the "),la=l("a"),_i=s("BuilderConfig"),vi=s(" class to create a subclass for your dataset. Provide the links to download the images and labels in "),bs=l("code"),$i=s("data_url"),yi=s(" and "),ws=l("code"),bi=s("metadata_urls"),wi=s(":"),dl=p(),_(At.$$.fragment),pl=p(),Fe=l("p"),Ei=s("Now you can define your subsets at the top of "),ra=l("a"),ji=s("GeneratorBasedBuilder"),qi=s(". Imagine you want to create two subsets in the Food-101 dataset based on whether it is a breakfast or dinner food."),fl=p(),Ne=l("ol"),ie=l("li"),ki=s("Define your subsets with "),Es=l("code"),Ai=s("Food101Config"),Ii=s(" in a list in "),js=l("code"),Ci=s("BUILDER_CONFIGS"),xi=s("."),Di=p(),qs=l("li"),Ti=s("For each configuration, provide a name, description, and where to download the images and labels from."),hl=p(),_(It.$$.fragment),cl=p(),Be=l("p"),Pi=s("Now if users want to load the "),ks=l("code"),Oi=s("breakfast"),Si=s(" configuration, they can use the configuration name:"),ul=p(),_(Ct.$$.fragment),ml=p(),de=l("h3"),Re=l("a"),As=l("span"),_(xt.$$.fragment),Li=p(),Is=l("span"),Fi=s("Add dataset metadata"),gl=p(),K=l("p"),Ni=s("Adding information about your dataset is useful for users to learn more about it. This information is stored in the "),na=l("a"),Bi=s("DatasetInfo"),Ri=s(" class which is returned by the "),Cs=l("code"),Gi=s("info"),Mi=s(" method. Users can access this information by:"),_l=p(),_(Dt.$$.fragment),vl=p(),ia=l("p"),Ui=s("There is a lot of information you can specify about your dataset, but some important ones to include are:"),$l=p(),O=l("ol"),da=l("li"),xs=l("code"),Hi=s("description"),Yi=s(" provides a concise description of the dataset."),zi=p(),Ge=l("li"),Ds=l("code"),Vi=s("features"),Wi=s(" specify the dataset column types. Since you\u2019re creating an image loading script, you\u2019ll need to include the "),pa=l("a"),Ji=s("Image"),Xi=s(" feature."),Ki=p(),fa=l("li"),Ts=l("code"),Qi=s("supervised_keys"),Zi=s(" specify the input feature and label."),ed=p(),ha=l("li"),Ps=l("code"),td=s("homepage"),ad=s(" provides a link to the dataset homepage."),sd=p(),ca=l("li"),Os=l("code"),od=s("citation"),ld=s(" is a BibTeX citation of the dataset."),rd=p(),ua=l("li"),Ss=l("code"),nd=s("license"),id=s(" states the dataset\u2019s license."),yl=p(),_(Me.$$.fragment),bl=p(),_(Tt.$$.fragment),wl=p(),pe=l("h3"),Ue=l("a"),Ls=l("span"),_(Pt.$$.fragment),dd=p(),Fs=l("span"),pd=s("Download and define the dataset splits"),El=p(),ma=l("p"),fd=s("Now that you\u2019ve added some information about your dataset, the next step is to download the dataset and generate the splits."),jl=p(),He=l("ol"),fe=l("li"),Ot=l("p"),hd=s("Use the "),ga=l("a"),cd=s("DownloadManager.download()"),ud=s(" method to download the dataset and any other metadata you\u2019d like to associate with it. This method accepts:"),md=p(),he=l("ul"),St=l("li"),gd=s("a name to a file inside a Hub dataset repository (in other words, the "),Ns=l("code"),_d=s("data/"),vd=s(" folder)"),$d=p(),Bs=l("li"),yd=s("a URL to a file hosted somewhere else"),bd=p(),Rs=l("li"),wd=s("a list or dictionary of file names or URLs"),Ed=p(),Gs=l("p"),jd=s("In the Food-101 loading script, you\u2019ll notice again the URLs are defined earlier in the script."),qd=p(),Lt=l("li"),B=l("p"),kd=s("After you\u2019ve downloaded the dataset, use the "),_a=l("a"),Ad=s("SplitGenerator"),Id=s(" to organize the images and labels in each split. Name each split with a standard name like: "),Ms=l("code"),Cd=s("Split.TRAIN"),xd=s(", "),Us=l("code"),Dd=s("Split.TEST"),Td=s(", and "),Hs=l("code"),Pd=s("SPLIT.Validation"),Od=s("."),Sd=p(),T=l("p"),Ld=s("In the "),Ys=l("code"),Fd=s("gen_kwargs"),Nd=s(" parameter, specify the file paths to the "),zs=l("code"),Bd=s("images"),Rd=s(" to iterate over and load. If necessary, you can use "),va=l("a"),Gd=s("DownloadManager.iter_archive()"),Md=s(" to iterate over images in TAR archives. You can also specify the associated labels in the "),Vs=l("code"),Ud=s("metadata_path"),Hd=s(". The "),Ws=l("code"),Yd=s("images"),zd=s(" and "),Js=l("code"),Vd=s("metadata_path"),Wd=s(" are actually passed onto the next step where you\u2019ll actually generate the dataset."),ql=p(),_(Ye.$$.fragment),kl=p(),_(Ft.$$.fragment),Al=p(),ce=l("h3"),ze=l("a"),Xs=l("span"),_(Nt.$$.fragment),Jd=p(),Ks=l("span"),Xd=s("Generate the dataset"),Il=p(),D=l("p"),Kd=s("The last method in the "),$a=l("a"),Qd=s("GeneratorBasedBuilder"),Zd=s(" class actually generates the images and labels in the dataset. It yields a dataset according to the stucture specified in "),Qs=l("code"),ep=s("features"),tp=s(" from the "),Zs=l("code"),ap=s("info"),sp=s(" method. As you can see, "),eo=l("code"),op=s("generate_examples"),lp=s(" accepts the "),to=l("code"),rp=s("images"),np=s(" and "),ao=l("code"),ip=s("metadata_path"),dp=s(" from the previous method as arguments."),Cl=p(),_(Ve.$$.fragment),xl=p(),ya=l("p"),pp=s("Now you can write a function for opening and loading examples from the dataset:"),Dl=p(),_(Bt.$$.fragment),Tl=p(),ue=l("h3"),We=l("a"),so=l("span"),_(Rt.$$.fragment),fp=p(),oo=l("span"),hp=s("Generate the dataset metadata (optional)"),Pl=p(),Je=l("p"),cp=s("The dataset metadata can be generated and stored in the dataset card ("),lo=l("code"),up=s("README.md"),mp=s(" file)."),Ol=p(),Xe=l("p"),gp=s("Run the following command to generate your dataset metadata in "),ro=l("code"),_p=s("README.md"),vp=s(" and make sure your new loading script works correctly:"),Sl=p(),_(Gt.$$.fragment),Ll=p(),Q=l("p"),$p=s("If your loading script passed the test, you should now have the "),no=l("code"),yp=s("dataset_info"),bp=s(" YAML fields in the header of the "),io=l("code"),wp=s("README.md"),Ep=s(" file in your dataset folder."),Fl=p(),me=l("h3"),Ke=l("a"),po=l("span"),_(Mt.$$.fragment),jp=p(),fo=l("span"),qp=s("Upload the dataset to the Hub"),Nl=p(),Z=l("p"),kp=s("Once your script is ready, "),ba=l("a"),Ap=s("create a dataset card"),Ip=s(" and "),wa=l("a"),Cp=s("upload it to the Hub"),xp=s("."),Bl=p(),Ea=l("p"),Dp=s("Congratulations, you can now load your dataset from the Hub! \u{1F973}"),Rl=p(),_(Ut.$$.fragment),this.h()},l(e){const i=lc('[data-svelte="svelte-1phssyn"]',document.head);c=r(i,"META",{name:!0,content:!0}),i.forEach(a),q=f(e),u=r(e,"H1",{class:!0});var Ht=n(u);E=r(Ht,"A",{id:!0,class:!0,href:!0});var ho=n(E);j=r(ho,"SPAN",{});var co=n(j);v(m.$$.fragment,co),co.forEach(a),ho.forEach(a),g=f(Ht),A=r(Ht,"SPAN",{});var uo=n(A);C=o(uo,"Create an image dataset"),uo.forEach(a),Ht.forEach(a),k=f(e),S=r(e,"P",{});var mo=n(S);G=o(mo,"There are two methods for creating and sharing an image dataset. This guide will show you how to:"),mo.forEach(a),_o=f(e),ge=r(e,"UL",{});var Yt=n(ge);tt=r(Yt,"LI",{});var zt=n(tt);vr=o(zt,"Create an image dataset with "),Sa=r(zt,"CODE",{});var Gp=n(Sa);$r=o(Gp,"ImageFolder"),Gp.forEach(a),yr=o(zt," and some metadata. This is a no-code solution for quickly creating an image dataset."),zt.forEach(a),br=f(Yt),La=r(Yt,"LI",{});var Mp=n(La);wr=o(Mp,"Create an image dataset by writing a loading script. This method is a bit more involved, but you have greater flexibility over how a dataset is defined, downloaded, and generated."),Mp.forEach(a),Yt.forEach(a),vo=f(e),v(_e.$$.fragment,e),$o=f(e),te=r(e,"H2",{class:!0});var Ml=n(te);ve=r(Ml,"A",{id:!0,class:!0,href:!0});var Up=n(ve);Fa=r(Up,"SPAN",{});var Hp=n(Fa);v(at.$$.fragment,Hp),Hp.forEach(a),Up.forEach(a),Er=f(Ml),Na=r(Ml,"SPAN",{});var Yp=n(Na);jr=o(Yp,"ImageFolder"),Yp.forEach(a),Ml.forEach(a),yo=f(e),z=r(e,"P",{});var ja=n(z);qr=o(ja,"The "),Ba=r(ja,"CODE",{});var zp=n(Ba);kr=o(zp,"ImageFolder"),zp.forEach(a),Ar=o(ja," is a dataset builder designed to quickly load an image dataset without requiring you to write any code. "),Ra=r(ja,"CODE",{});var Vp=n(Ra);Ir=o(Vp,"ImageFolder"),Vp.forEach(a),Cr=o(ja," automatically infers the class labels of your dataset based on the directory name. Just store your dataset in a directory structure like:"),ja.forEach(a),bo=f(e),v(st.$$.fragment,e),wo=f(e),M=r(e,"P",{});var Qe=n(M);xr=o(Qe,"Then users can load your dataset by specifying "),Ga=r(Qe,"CODE",{});var Wp=n(Ga);Dr=o(Wp,"imagefolder"),Wp.forEach(a),Tr=o(Qe," in "),Wt=r(Qe,"A",{href:!0});var Jp=n(Wt);Pr=o(Jp,"load_dataset()"),Jp.forEach(a),Or=o(Qe," and the directory in "),Ma=r(Qe,"CODE",{});var Xp=n(Ma);Sr=o(Xp,"data_dir"),Xp.forEach(a),Lr=o(Qe,":"),Qe.forEach(a),Eo=f(e),v(ot.$$.fragment,e),jo=f(e),$e=r(e,"P",{});var Ul=n($e);Fr=o(Ul,"You can also use "),Ua=r(Ul,"CODE",{});var Kp=n(Ua);Nr=o(Kp,"imagefolder"),Kp.forEach(a),Br=o(Ul," to load datasets involving multiple splits. To do so, your dataset directory should have the following structure:"),Ul.forEach(a),qo=f(e),v(lt.$$.fragment,e),ko=f(e),v(ye.$$.fragment,e),Ao=f(e),be=r(e,"P",{});var Hl=n(be);Rr=o(Hl,"If there is additional information you\u2019d like to include about your dataset, like text captions or bounding boxes, add it as a "),Ha=r(Hl,"CODE",{});var Qp=n(Ha);Gr=o(Qp,"metadata.jsonl"),Qp.forEach(a),Mr=o(Hl," file in your folder. This lets you quickly create datasets for different computer vision tasks like text captioning or object detection."),Hl.forEach(a),Io=f(e),v(rt.$$.fragment,e),Co=f(e),V=r(e,"P",{});var qa=n(V);Ur=o(qa,"Your "),Ya=r(qa,"CODE",{});var Zp=n(Ya);Hr=o(Zp,"metadata.jsonl"),Zp.forEach(a),Yr=o(qa," file must have a "),za=r(qa,"CODE",{});var ef=n(za);zr=o(ef,"file_name"),ef.forEach(a),Vr=o(qa," column which links image files with their metadata:"),qa.forEach(a),xo=f(e),v(nt.$$.fragment,e),Do=f(e),v(we.$$.fragment,e),To=f(e),ae=r(e,"H3",{class:!0});var Yl=n(ae);Ee=r(Yl,"A",{id:!0,class:!0,href:!0});var tf=n(Ee);Va=r(tf,"SPAN",{});var af=n(Va);v(it.$$.fragment,af),af.forEach(a),tf.forEach(a),Wr=f(Yl),Wa=r(Yl,"SPAN",{});var sf=n(Wa);Jr=o(sf,"Image captioning"),sf.forEach(a),Yl.forEach(a),Po=f(e),je=r(e,"P",{});var zl=n(je);Xr=o(zl,"Image captioning datasets have text describing an image. An example "),Ja=r(zl,"CODE",{});var of=n(Ja);Kr=o(of,"metadata.jsonl"),of.forEach(a),Qr=o(zl," may look like:"),zl.forEach(a),Oo=f(e),v(dt.$$.fragment,e),So=f(e),W=r(e,"P",{});var ka=n(W);Zr=o(ka,"Load the dataset with "),Xa=r(ka,"CODE",{});var lf=n(Xa);en=o(lf,"ImageFolder"),lf.forEach(a),tn=o(ka,", and it will create a "),Ka=r(ka,"CODE",{});var rf=n(Ka);an=o(rf,"text"),rf.forEach(a),sn=o(ka," column for the image captions:"),ka.forEach(a),Lo=f(e),v(pt.$$.fragment,e),Fo=f(e),se=r(e,"H3",{class:!0});var Vl=n(se);qe=r(Vl,"A",{id:!0,class:!0,href:!0});var nf=n(qe);Qa=r(nf,"SPAN",{});var df=n(Qa);v(ft.$$.fragment,df),df.forEach(a),nf.forEach(a),on=f(Vl),Za=r(Vl,"SPAN",{});var pf=n(Za);ln=o(pf,"Object detection"),pf.forEach(a),Vl.forEach(a),No=f(e),ke=r(e,"P",{});var Wl=n(ke);rn=o(Wl,"Object detection datasets have bounding boxes and categories identifying objects in an image. An example "),es=r(Wl,"CODE",{});var ff=n(es);nn=o(ff,"metadata.jsonl"),ff.forEach(a),dn=o(Wl," may look like:"),Wl.forEach(a),Bo=f(e),v(ht.$$.fragment,e),Ro=f(e),J=r(e,"P",{});var Aa=n(J);pn=o(Aa,"Load the dataset with "),ts=r(Aa,"CODE",{});var hf=n(ts);fn=o(hf,"ImageFolder"),hf.forEach(a),hn=o(Aa,", and it will create a "),as=r(Aa,"CODE",{});var cf=n(as);cn=o(cf,"objects"),cf.forEach(a),un=o(Aa," column with the bounding boxes and the categories:"),Aa.forEach(a),Go=f(e),v(ct.$$.fragment,e),Mo=f(e),oe=r(e,"H3",{class:!0});var Jl=n(oe);Ae=r(Jl,"A",{id:!0,class:!0,href:!0});var uf=n(Ae);ss=r(uf,"SPAN",{});var mf=n(ss);v(ut.$$.fragment,mf),mf.forEach(a),uf.forEach(a),mn=f(Jl),os=r(Jl,"SPAN",{});var gf=n(os);gn=o(gf,"Upload dataset to the Hub"),gf.forEach(a),Jl.forEach(a),Uo=f(e),U=r(e,"P",{});var Ze=n(U);_n=o(Ze,"Once you\u2019ve created a dataset, you can share it to the Hub with the "),Jt=r(Ze,"A",{href:!0});var _f=n(Jt);vn=o(_f,"push_to_hub()"),_f.forEach(a),$n=o(Ze," method. Make sure you have the "),mt=r(Ze,"A",{href:!0,rel:!0});var vf=n(mt);yn=o(vf,"huggingface_hub"),vf.forEach(a),bn=o(Ze," library installed and you\u2019re logged in to your Hugging Face account (see the "),Xt=r(Ze,"A",{href:!0});var $f=n(Xt);wn=o($f,"Upload with Python tutorial"),$f.forEach(a),En=o(Ze," for more details)."),Ze.forEach(a),Ho=f(e),Ie=r(e,"P",{});var Xl=n(Ie);jn=o(Xl,"Upload your dataset with "),Kt=r(Xl,"A",{href:!0});var yf=n(Kt);qn=o(yf,"push_to_hub()"),yf.forEach(a),kn=o(Xl,":"),Xl.forEach(a),Yo=f(e),v(gt.$$.fragment,e),zo=f(e),le=r(e,"H2",{class:!0});var Kl=n(le);Ce=r(Kl,"A",{id:!0,class:!0,href:!0});var bf=n(Ce);ls=r(bf,"SPAN",{});var wf=n(ls);v(_t.$$.fragment,wf),wf.forEach(a),bf.forEach(a),An=f(Kl),rs=r(Kl,"SPAN",{});var Ef=n(rs);In=o(Ef,"Loading script"),Ef.forEach(a),Kl.forEach(a),Vo=f(e),Qt=r(e,"P",{});var jf=n(Qt);Cn=o(jf,"Write a dataset loading script to share a dataset. It defines a dataset\u2019s splits and configurations, and handles downloading and generating a dataset. The script is located in the same folder or repository as the dataset and should have the same name."),jf.forEach(a),Wo=f(e),v(vt.$$.fragment,e),Jo=f(e),Zt=r(e,"P",{});var qf=n(Zt);xn=o(qf,"This structure allows your dataset to be loaded in one line:"),qf.forEach(a),Xo=f(e),v($t.$$.fragment,e),Ko=f(e),xe=r(e,"P",{});var Ql=n(xe);Dn=o(Ql,"This guide will show you how to create a dataset loading script for image datasets, which is a bit different from "),yt=r(Ql,"A",{class:!0,href:!0});var kf=n(yt);Tn=o(kf,"creating a loading script for text datasets"),kf.forEach(a),Pn=o(Ql,". You\u2019ll learn how to:"),Ql.forEach(a),Qo=f(e),x=r(e,"UL",{});var L=n(x);ns=r(L,"LI",{});var Af=n(ns);On=o(Af,"Create a dataset builder class."),Af.forEach(a),Sn=f(L),is=r(L,"LI",{});var If=n(is);Ln=o(If,"Create dataset configurations."),If.forEach(a),Fn=f(L),ds=r(L,"LI",{});var Cf=n(ds);Nn=o(Cf,"Add dataset metadata."),Cf.forEach(a),Bn=f(L),ps=r(L,"LI",{});var xf=n(ps);Rn=o(xf,"Download and define the dataset splits."),xf.forEach(a),Gn=f(L),fs=r(L,"LI",{});var Df=n(fs);Mn=o(Df,"Generate the dataset."),Df.forEach(a),Un=f(L),hs=r(L,"LI",{});var Tf=n(hs);Hn=o(Tf,"Generate the dataset metadata (optional)."),Tf.forEach(a),Yn=f(L),cs=r(L,"LI",{});var Pf=n(cs);zn=o(Pf,"Upload the dataset to the Hub."),Pf.forEach(a),L.forEach(a),Zo=f(e),De=r(e,"P",{});var Zl=n(De);Vn=o(Zl,"The best way to learn is to open up an existing image dataset loading script, like "),bt=r(Zl,"A",{href:!0,rel:!0});var Of=n(bt);Wn=o(Of,"Food-101"),Of.forEach(a),Jn=o(Zl,", and follow along!"),Zl.forEach(a),el=f(e),v(Te.$$.fragment,e),tl=f(e),re=r(e,"H3",{class:!0});var er=n(re);Pe=r(er,"A",{id:!0,class:!0,href:!0});var Sf=n(Pe);us=r(Sf,"SPAN",{});var Lf=n(us);v(wt.$$.fragment,Lf),Lf.forEach(a),Sf.forEach(a),Xn=f(er),ms=r(er,"SPAN",{});var Ff=n(ms);Kn=o(Ff,"Create a dataset builder class"),Ff.forEach(a),er.forEach(a),al=f(e),Et=r(e,"P",{});var Tp=n(Et);ea=r(Tp,"A",{href:!0});var Nf=n(ea);Qn=o(Nf,"GeneratorBasedBuilder"),Nf.forEach(a),Zn=o(Tp," is the base class for datasets generated from a dictionary generator. Within this class, there are three methods to help create your dataset:"),Tp.forEach(a),sl=f(e),X=r(e,"UL",{});var Ia=n(X);ta=r(Ia,"LI",{});var Pp=n(ta);gs=r(Pp,"CODE",{});var Bf=n(gs);ei=o(Bf,"info"),Bf.forEach(a),ti=o(Pp," stores information about your dataset like its description, license, and features."),Pp.forEach(a),ai=f(Ia),aa=r(Ia,"LI",{});var Op=n(aa);_s=r(Op,"CODE",{});var Rf=n(_s);si=o(Rf,"split_generators"),Rf.forEach(a),oi=o(Op," downloads the dataset and defines its splits."),Op.forEach(a),li=f(Ia),sa=r(Ia,"LI",{});var Sp=n(sa);vs=r(Sp,"CODE",{});var Gf=n(vs);ri=o(Gf,"generate_examples"),Gf.forEach(a),ni=o(Sp," generates the images and labels for each split."),Sp.forEach(a),Ia.forEach(a),ol=f(e),Oe=r(e,"P",{});var tr=n(Oe);ii=o(tr,"Start by creating your dataset class as a subclass of "),oa=r(tr,"A",{href:!0});var Mf=n(oa);di=o(Mf,"GeneratorBasedBuilder"),Mf.forEach(a),pi=o(tr," and add the three methods. Don\u2019t worry about filling in each of these methods yet, you\u2019ll develop those over the next few sections:"),tr.forEach(a),ll=f(e),v(jt.$$.fragment,e),rl=f(e),ne=r(e,"H4",{class:!0});var ar=n(ne);Se=r(ar,"A",{id:!0,class:!0,href:!0});var Uf=n(Se);$s=r(Uf,"SPAN",{});var Hf=n($s);v(qt.$$.fragment,Hf),Hf.forEach(a),Uf.forEach(a),fi=f(ar),ys=r(ar,"SPAN",{});var Yf=n(ys);hi=o(Yf,"Multiple configurations"),Yf.forEach(a),ar.forEach(a),nl=f(e),Le=r(e,"P",{});var sr=n(Le);ci=o(sr,"In some cases, a dataset may have more than one configuration. For example, if you check out the "),kt=r(sr,"A",{href:!0,rel:!0});var zf=n(kt);ui=o(zf,"Imagenette dataset"),zf.forEach(a),mi=o(sr,", you\u2019ll notice there are three subsets."),sr.forEach(a),il=f(e),H=r(e,"P",{});var et=n(H);gi=o(et,"To create different configurations, use the "),la=r(et,"A",{href:!0});var Vf=n(la);_i=o(Vf,"BuilderConfig"),Vf.forEach(a),vi=o(et," class to create a subclass for your dataset. Provide the links to download the images and labels in "),bs=r(et,"CODE",{});var Wf=n(bs);$i=o(Wf,"data_url"),Wf.forEach(a),yi=o(et," and "),ws=r(et,"CODE",{});var Jf=n(ws);bi=o(Jf,"metadata_urls"),Jf.forEach(a),wi=o(et,":"),et.forEach(a),dl=f(e),v(At.$$.fragment,e),pl=f(e),Fe=r(e,"P",{});var or=n(Fe);Ei=o(or,"Now you can define your subsets at the top of "),ra=r(or,"A",{href:!0});var Xf=n(ra);ji=o(Xf,"GeneratorBasedBuilder"),Xf.forEach(a),qi=o(or,". Imagine you want to create two subsets in the Food-101 dataset based on whether it is a breakfast or dinner food."),or.forEach(a),fl=f(e),Ne=r(e,"OL",{});var lr=n(Ne);ie=r(lr,"LI",{});var Ca=n(ie);ki=o(Ca,"Define your subsets with "),Es=r(Ca,"CODE",{});var Kf=n(Es);Ai=o(Kf,"Food101Config"),Kf.forEach(a),Ii=o(Ca," in a list in "),js=r(Ca,"CODE",{});var Qf=n(js);Ci=o(Qf,"BUILDER_CONFIGS"),Qf.forEach(a),xi=o(Ca,"."),Ca.forEach(a),Di=f(lr),qs=r(lr,"LI",{});var Zf=n(qs);Ti=o(Zf,"For each configuration, provide a name, description, and where to download the images and labels from."),Zf.forEach(a),lr.forEach(a),hl=f(e),v(It.$$.fragment,e),cl=f(e),Be=r(e,"P",{});var rr=n(Be);Pi=o(rr,"Now if users want to load the "),ks=r(rr,"CODE",{});var eh=n(ks);Oi=o(eh,"breakfast"),eh.forEach(a),Si=o(rr," configuration, they can use the configuration name:"),rr.forEach(a),ul=f(e),v(Ct.$$.fragment,e),ml=f(e),de=r(e,"H3",{class:!0});var nr=n(de);Re=r(nr,"A",{id:!0,class:!0,href:!0});var th=n(Re);As=r(th,"SPAN",{});var ah=n(As);v(xt.$$.fragment,ah),ah.forEach(a),th.forEach(a),Li=f(nr),Is=r(nr,"SPAN",{});var sh=n(Is);Fi=o(sh,"Add dataset metadata"),sh.forEach(a),nr.forEach(a),gl=f(e),K=r(e,"P",{});var xa=n(K);Ni=o(xa,"Adding information about your dataset is useful for users to learn more about it. This information is stored in the "),na=r(xa,"A",{href:!0});var oh=n(na);Bi=o(oh,"DatasetInfo"),oh.forEach(a),Ri=o(xa," class which is returned by the "),Cs=r(xa,"CODE",{});var lh=n(Cs);Gi=o(lh,"info"),lh.forEach(a),Mi=o(xa," method. Users can access this information by:"),xa.forEach(a),_l=f(e),v(Dt.$$.fragment,e),vl=f(e),ia=r(e,"P",{});var rh=n(ia);Ui=o(rh,"There is a lot of information you can specify about your dataset, but some important ones to include are:"),rh.forEach(a),$l=f(e),O=r(e,"OL",{});var Y=n(O);da=r(Y,"LI",{});var Lp=n(da);xs=r(Lp,"CODE",{});var nh=n(xs);Hi=o(nh,"description"),nh.forEach(a),Yi=o(Lp," provides a concise description of the dataset."),Lp.forEach(a),zi=f(Y),Ge=r(Y,"LI",{});var go=n(Ge);Ds=r(go,"CODE",{});var ih=n(Ds);Vi=o(ih,"features"),ih.forEach(a),Wi=o(go," specify the dataset column types. Since you\u2019re creating an image loading script, you\u2019ll need to include the "),pa=r(go,"A",{href:!0});var dh=n(pa);Ji=o(dh,"Image"),dh.forEach(a),Xi=o(go," feature."),go.forEach(a),Ki=f(Y),fa=r(Y,"LI",{});var Fp=n(fa);Ts=r(Fp,"CODE",{});var ph=n(Ts);Qi=o(ph,"supervised_keys"),ph.forEach(a),Zi=o(Fp," specify the input feature and label."),Fp.forEach(a),ed=f(Y),ha=r(Y,"LI",{});var Np=n(ha);Ps=r(Np,"CODE",{});var fh=n(Ps);td=o(fh,"homepage"),fh.forEach(a),ad=o(Np," provides a link to the dataset homepage."),Np.forEach(a),sd=f(Y),ca=r(Y,"LI",{});var Bp=n(ca);Os=r(Bp,"CODE",{});var hh=n(Os);od=o(hh,"citation"),hh.forEach(a),ld=o(Bp," is a BibTeX citation of the dataset."),Bp.forEach(a),rd=f(Y),ua=r(Y,"LI",{});var Rp=n(ua);Ss=r(Rp,"CODE",{});var ch=n(Ss);nd=o(ch,"license"),ch.forEach(a),id=o(Rp," states the dataset\u2019s license."),Rp.forEach(a),Y.forEach(a),yl=f(e),v(Me.$$.fragment,e),bl=f(e),v(Tt.$$.fragment,e),wl=f(e),pe=r(e,"H3",{class:!0});var ir=n(pe);Ue=r(ir,"A",{id:!0,class:!0,href:!0});var uh=n(Ue);Ls=r(uh,"SPAN",{});var mh=n(Ls);v(Pt.$$.fragment,mh),mh.forEach(a),uh.forEach(a),dd=f(ir),Fs=r(ir,"SPAN",{});var gh=n(Fs);pd=o(gh,"Download and define the dataset splits"),gh.forEach(a),ir.forEach(a),El=f(e),ma=r(e,"P",{});var _h=n(ma);fd=o(_h,"Now that you\u2019ve added some information about your dataset, the next step is to download the dataset and generate the splits."),_h.forEach(a),jl=f(e),He=r(e,"OL",{});var dr=n(He);fe=r(dr,"LI",{});var Da=n(fe);Ot=r(Da,"P",{});var pr=n(Ot);hd=o(pr,"Use the "),ga=r(pr,"A",{href:!0});var vh=n(ga);cd=o(vh,"DownloadManager.download()"),vh.forEach(a),ud=o(pr," method to download the dataset and any other metadata you\u2019d like to associate with it. This method accepts:"),pr.forEach(a),md=f(Da),he=r(Da,"UL",{});var Ta=n(he);St=r(Ta,"LI",{});var fr=n(St);gd=o(fr,"a name to a file inside a Hub dataset repository (in other words, the "),Ns=r(fr,"CODE",{});var $h=n(Ns);_d=o($h,"data/"),$h.forEach(a),vd=o(fr," folder)"),fr.forEach(a),$d=f(Ta),Bs=r(Ta,"LI",{});var yh=n(Bs);yd=o(yh,"a URL to a file hosted somewhere else"),yh.forEach(a),bd=f(Ta),Rs=r(Ta,"LI",{});var bh=n(Rs);wd=o(bh,"a list or dictionary of file names or URLs"),bh.forEach(a),Ta.forEach(a),Ed=f(Da),Gs=r(Da,"P",{});var wh=n(Gs);jd=o(wh,"In the Food-101 loading script, you\u2019ll notice again the URLs are defined earlier in the script."),wh.forEach(a),Da.forEach(a),qd=f(dr),Lt=r(dr,"LI",{});var hr=n(Lt);B=r(hr,"P",{});var ee=n(B);kd=o(ee,"After you\u2019ve downloaded the dataset, use the "),_a=r(ee,"A",{href:!0});var Eh=n(_a);Ad=o(Eh,"SplitGenerator"),Eh.forEach(a),Id=o(ee," to organize the images and labels in each split. Name each split with a standard name like: "),Ms=r(ee,"CODE",{});var jh=n(Ms);Cd=o(jh,"Split.TRAIN"),jh.forEach(a),xd=o(ee,", "),Us=r(ee,"CODE",{});var qh=n(Us);Dd=o(qh,"Split.TEST"),qh.forEach(a),Td=o(ee,", and "),Hs=r(ee,"CODE",{});var kh=n(Hs);Pd=o(kh,"SPLIT.Validation"),kh.forEach(a),Od=o(ee,"."),ee.forEach(a),Sd=f(hr),T=r(hr,"P",{});var F=n(T);Ld=o(F,"In the "),Ys=r(F,"CODE",{});var Ah=n(Ys);Fd=o(Ah,"gen_kwargs"),Ah.forEach(a),Nd=o(F," parameter, specify the file paths to the "),zs=r(F,"CODE",{});var Ih=n(zs);Bd=o(Ih,"images"),Ih.forEach(a),Rd=o(F," to iterate over and load. If necessary, you can use "),va=r(F,"A",{href:!0});var Ch=n(va);Gd=o(Ch,"DownloadManager.iter_archive()"),Ch.forEach(a),Md=o(F," to iterate over images in TAR archives. You can also specify the associated labels in the "),Vs=r(F,"CODE",{});var xh=n(Vs);Ud=o(xh,"metadata_path"),xh.forEach(a),Hd=o(F,". The "),Ws=r(F,"CODE",{});var Dh=n(Ws);Yd=o(Dh,"images"),Dh.forEach(a),zd=o(F," and "),Js=r(F,"CODE",{});var Th=n(Js);Vd=o(Th,"metadata_path"),Th.forEach(a),Wd=o(F," are actually passed onto the next step where you\u2019ll actually generate the dataset."),F.forEach(a),hr.forEach(a),dr.forEach(a),ql=f(e),v(Ye.$$.fragment,e),kl=f(e),v(Ft.$$.fragment,e),Al=f(e),ce=r(e,"H3",{class:!0});var cr=n(ce);ze=r(cr,"A",{id:!0,class:!0,href:!0});var Ph=n(ze);Xs=r(Ph,"SPAN",{});var Oh=n(Xs);v(Nt.$$.fragment,Oh),Oh.forEach(a),Ph.forEach(a),Jd=f(cr),Ks=r(cr,"SPAN",{});var Sh=n(Ks);Xd=o(Sh,"Generate the dataset"),Sh.forEach(a),cr.forEach(a),Il=f(e),D=r(e,"P",{});var N=n(D);Kd=o(N,"The last method in the "),$a=r(N,"A",{href:!0});var Lh=n($a);Qd=o(Lh,"GeneratorBasedBuilder"),Lh.forEach(a),Zd=o(N," class actually generates the images and labels in the dataset. It yields a dataset according to the stucture specified in "),Qs=r(N,"CODE",{});var Fh=n(Qs);ep=o(Fh,"features"),Fh.forEach(a),tp=o(N," from the "),Zs=r(N,"CODE",{});var Nh=n(Zs);ap=o(Nh,"info"),Nh.forEach(a),sp=o(N," method. As you can see, "),eo=r(N,"CODE",{});var Bh=n(eo);op=o(Bh,"generate_examples"),Bh.forEach(a),lp=o(N," accepts the "),to=r(N,"CODE",{});var Rh=n(to);rp=o(Rh,"images"),Rh.forEach(a),np=o(N," and "),ao=r(N,"CODE",{});var Gh=n(ao);ip=o(Gh,"metadata_path"),Gh.forEach(a),dp=o(N," from the previous method as arguments."),N.forEach(a),Cl=f(e),v(Ve.$$.fragment,e),xl=f(e),ya=r(e,"P",{});var Mh=n(ya);pp=o(Mh,"Now you can write a function for opening and loading examples from the dataset:"),Mh.forEach(a),Dl=f(e),v(Bt.$$.fragment,e),Tl=f(e),ue=r(e,"H3",{class:!0});var ur=n(ue);We=r(ur,"A",{id:!0,class:!0,href:!0});var Uh=n(We);so=r(Uh,"SPAN",{});var Hh=n(so);v(Rt.$$.fragment,Hh),Hh.forEach(a),Uh.forEach(a),fp=f(ur),oo=r(ur,"SPAN",{});var Yh=n(oo);hp=o(Yh,"Generate the dataset metadata (optional)"),Yh.forEach(a),ur.forEach(a),Pl=f(e),Je=r(e,"P",{});var mr=n(Je);cp=o(mr,"The dataset metadata can be generated and stored in the dataset card ("),lo=r(mr,"CODE",{});var zh=n(lo);up=o(zh,"README.md"),zh.forEach(a),mp=o(mr," file)."),mr.forEach(a),Ol=f(e),Xe=r(e,"P",{});var gr=n(Xe);gp=o(gr,"Run the following command to generate your dataset metadata in "),ro=r(gr,"CODE",{});var Vh=n(ro);_p=o(Vh,"README.md"),Vh.forEach(a),vp=o(gr," and make sure your new loading script works correctly:"),gr.forEach(a),Sl=f(e),v(Gt.$$.fragment,e),Ll=f(e),Q=r(e,"P",{});var Pa=n(Q);$p=o(Pa,"If your loading script passed the test, you should now have the "),no=r(Pa,"CODE",{});var Wh=n(no);yp=o(Wh,"dataset_info"),Wh.forEach(a),bp=o(Pa," YAML fields in the header of the "),io=r(Pa,"CODE",{});var Jh=n(io);wp=o(Jh,"README.md"),Jh.forEach(a),Ep=o(Pa," file in your dataset folder."),Pa.forEach(a),Fl=f(e),me=r(e,"H3",{class:!0});var _r=n(me);Ke=r(_r,"A",{id:!0,class:!0,href:!0});var Xh=n(Ke);po=r(Xh,"SPAN",{});var Kh=n(po);v(Mt.$$.fragment,Kh),Kh.forEach(a),Xh.forEach(a),jp=f(_r),fo=r(_r,"SPAN",{});var Qh=n(fo);qp=o(Qh,"Upload the dataset to the Hub"),Qh.forEach(a),_r.forEach(a),Nl=f(e),Z=r(e,"P",{});var Oa=n(Z);kp=o(Oa,"Once your script is ready, "),ba=r(Oa,"A",{href:!0});var Zh=n(ba);Ap=o(Zh,"create a dataset card"),Zh.forEach(a),Ip=o(Oa," and "),wa=r(Oa,"A",{href:!0});var ec=n(wa);Cp=o(ec,"upload it to the Hub"),ec.forEach(a),xp=o(Oa,"."),Oa.forEach(a),Bl=f(e),Ea=r(e,"P",{});var tc=n(Ea);Dp=o(tc,"Congratulations, you can now load your dataset from the Hub! \u{1F973}"),tc.forEach(a),Rl=f(e),v(Ut.$$.fragment,e),this.h()},h(){h(c,"name","hf:doc:metadata"),h(c,"content",JSON.stringify(mc)),h(E,"id","create-an-image-dataset"),h(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(E,"href","#create-an-image-dataset"),h(u,"class","relative group"),h(ve,"id","imagefolder"),h(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ve,"href","#imagefolder"),h(te,"class","relative group"),h(Wt,"href","/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset"),h(Ee,"id","image-captioning"),h(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ee,"href","#image-captioning"),h(ae,"class","relative group"),h(qe,"id","object-detection"),h(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(qe,"href","#object-detection"),h(se,"class","relative group"),h(Ae,"id","upload-dataset-to-the-hub"),h(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ae,"href","#upload-dataset-to-the-hub"),h(oe,"class","relative group"),h(Jt,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict.push_to_hub"),h(mt,"href","https://huggingface.co/docs/huggingface_hub/index"),h(mt,"rel","nofollow"),h(Xt,"href","upload_dataset#upload-with-python"),h(Kt,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict.push_to_hub"),h(Ce,"id","loading-script"),h(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ce,"href","#loading-script"),h(le,"class","relative group"),h(yt,"class","underline decoration-green-400 decoration-2 font-semibold"),h(yt,"href","./dataset_script"),h(bt,"href","https://huggingface.co/datasets/food101/blob/main/food101.py"),h(bt,"rel","nofollow"),h(Pe,"id","create-a-dataset-builder-class"),h(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Pe,"href","#create-a-dataset-builder-class"),h(re,"class","relative group"),h(ea,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),h(oa,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),h(Se,"id","multiple-configurations"),h(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Se,"href","#multiple-configurations"),h(ne,"class","relative group"),h(kt,"href","https://huggingface.co/datasets/frgfm/imagenette"),h(kt,"rel","nofollow"),h(la,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.BuilderConfig"),h(ra,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),h(Re,"id","add-dataset-metadata"),h(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Re,"href","#add-dataset-metadata"),h(de,"class","relative group"),h(na,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetInfo"),h(pa,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Image"),h(Ue,"id","download-and-define-the-dataset-splits"),h(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ue,"href","#download-and-define-the-dataset-splits"),h(pe,"class","relative group"),h(ga,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download"),h(_a,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.SplitGenerator"),h(va,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),h(ze,"id","generate-the-dataset"),h(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ze,"href","#generate-the-dataset"),h(ce,"class","relative group"),h($a,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),h(We,"id","generate-the-dataset-metadata-optional"),h(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(We,"href","#generate-the-dataset-metadata-optional"),h(ue,"class","relative group"),h(Ke,"id","upload-the-dataset-to-the-hub"),h(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ke,"href","#upload-the-dataset-to-the-hub"),h(me,"class","relative group"),h(ba,"href","./dataset_card"),h(wa,"href","./share")},m(e,i){t(document.head,c),d(e,q,i),d(e,u,i),t(u,E),t(E,j),$(m,j,null),t(u,g),t(u,A),t(A,C),d(e,k,i),d(e,S,i),t(S,G),d(e,_o,i),d(e,ge,i),t(ge,tt),t(tt,vr),t(tt,Sa),t(Sa,$r),t(tt,yr),t(ge,br),t(ge,La),t(La,wr),d(e,vo,i),$(_e,e,i),d(e,$o,i),d(e,te,i),t(te,ve),t(ve,Fa),$(at,Fa,null),t(te,Er),t(te,Na),t(Na,jr),d(e,yo,i),d(e,z,i),t(z,qr),t(z,Ba),t(Ba,kr),t(z,Ar),t(z,Ra),t(Ra,Ir),t(z,Cr),d(e,bo,i),$(st,e,i),d(e,wo,i),d(e,M,i),t(M,xr),t(M,Ga),t(Ga,Dr),t(M,Tr),t(M,Wt),t(Wt,Pr),t(M,Or),t(M,Ma),t(Ma,Sr),t(M,Lr),d(e,Eo,i),$(ot,e,i),d(e,jo,i),d(e,$e,i),t($e,Fr),t($e,Ua),t(Ua,Nr),t($e,Br),d(e,qo,i),$(lt,e,i),d(e,ko,i),$(ye,e,i),d(e,Ao,i),d(e,be,i),t(be,Rr),t(be,Ha),t(Ha,Gr),t(be,Mr),d(e,Io,i),$(rt,e,i),d(e,Co,i),d(e,V,i),t(V,Ur),t(V,Ya),t(Ya,Hr),t(V,Yr),t(V,za),t(za,zr),t(V,Vr),d(e,xo,i),$(nt,e,i),d(e,Do,i),$(we,e,i),d(e,To,i),d(e,ae,i),t(ae,Ee),t(Ee,Va),$(it,Va,null),t(ae,Wr),t(ae,Wa),t(Wa,Jr),d(e,Po,i),d(e,je,i),t(je,Xr),t(je,Ja),t(Ja,Kr),t(je,Qr),d(e,Oo,i),$(dt,e,i),d(e,So,i),d(e,W,i),t(W,Zr),t(W,Xa),t(Xa,en),t(W,tn),t(W,Ka),t(Ka,an),t(W,sn),d(e,Lo,i),$(pt,e,i),d(e,Fo,i),d(e,se,i),t(se,qe),t(qe,Qa),$(ft,Qa,null),t(se,on),t(se,Za),t(Za,ln),d(e,No,i),d(e,ke,i),t(ke,rn),t(ke,es),t(es,nn),t(ke,dn),d(e,Bo,i),$(ht,e,i),d(e,Ro,i),d(e,J,i),t(J,pn),t(J,ts),t(ts,fn),t(J,hn),t(J,as),t(as,cn),t(J,un),d(e,Go,i),$(ct,e,i),d(e,Mo,i),d(e,oe,i),t(oe,Ae),t(Ae,ss),$(ut,ss,null),t(oe,mn),t(oe,os),t(os,gn),d(e,Uo,i),d(e,U,i),t(U,_n),t(U,Jt),t(Jt,vn),t(U,$n),t(U,mt),t(mt,yn),t(U,bn),t(U,Xt),t(Xt,wn),t(U,En),d(e,Ho,i),d(e,Ie,i),t(Ie,jn),t(Ie,Kt),t(Kt,qn),t(Ie,kn),d(e,Yo,i),$(gt,e,i),d(e,zo,i),d(e,le,i),t(le,Ce),t(Ce,ls),$(_t,ls,null),t(le,An),t(le,rs),t(rs,In),d(e,Vo,i),d(e,Qt,i),t(Qt,Cn),d(e,Wo,i),$(vt,e,i),d(e,Jo,i),d(e,Zt,i),t(Zt,xn),d(e,Xo,i),$($t,e,i),d(e,Ko,i),d(e,xe,i),t(xe,Dn),t(xe,yt),t(yt,Tn),t(xe,Pn),d(e,Qo,i),d(e,x,i),t(x,ns),t(ns,On),t(x,Sn),t(x,is),t(is,Ln),t(x,Fn),t(x,ds),t(ds,Nn),t(x,Bn),t(x,ps),t(ps,Rn),t(x,Gn),t(x,fs),t(fs,Mn),t(x,Un),t(x,hs),t(hs,Hn),t(x,Yn),t(x,cs),t(cs,zn),d(e,Zo,i),d(e,De,i),t(De,Vn),t(De,bt),t(bt,Wn),t(De,Jn),d(e,el,i),$(Te,e,i),d(e,tl,i),d(e,re,i),t(re,Pe),t(Pe,us),$(wt,us,null),t(re,Xn),t(re,ms),t(ms,Kn),d(e,al,i),d(e,Et,i),t(Et,ea),t(ea,Qn),t(Et,Zn),d(e,sl,i),d(e,X,i),t(X,ta),t(ta,gs),t(gs,ei),t(ta,ti),t(X,ai),t(X,aa),t(aa,_s),t(_s,si),t(aa,oi),t(X,li),t(X,sa),t(sa,vs),t(vs,ri),t(sa,ni),d(e,ol,i),d(e,Oe,i),t(Oe,ii),t(Oe,oa),t(oa,di),t(Oe,pi),d(e,ll,i),$(jt,e,i),d(e,rl,i),d(e,ne,i),t(ne,Se),t(Se,$s),$(qt,$s,null),t(ne,fi),t(ne,ys),t(ys,hi),d(e,nl,i),d(e,Le,i),t(Le,ci),t(Le,kt),t(kt,ui),t(Le,mi),d(e,il,i),d(e,H,i),t(H,gi),t(H,la),t(la,_i),t(H,vi),t(H,bs),t(bs,$i),t(H,yi),t(H,ws),t(ws,bi),t(H,wi),d(e,dl,i),$(At,e,i),d(e,pl,i),d(e,Fe,i),t(Fe,Ei),t(Fe,ra),t(ra,ji),t(Fe,qi),d(e,fl,i),d(e,Ne,i),t(Ne,ie),t(ie,ki),t(ie,Es),t(Es,Ai),t(ie,Ii),t(ie,js),t(js,Ci),t(ie,xi),t(Ne,Di),t(Ne,qs),t(qs,Ti),d(e,hl,i),$(It,e,i),d(e,cl,i),d(e,Be,i),t(Be,Pi),t(Be,ks),t(ks,Oi),t(Be,Si),d(e,ul,i),$(Ct,e,i),d(e,ml,i),d(e,de,i),t(de,Re),t(Re,As),$(xt,As,null),t(de,Li),t(de,Is),t(Is,Fi),d(e,gl,i),d(e,K,i),t(K,Ni),t(K,na),t(na,Bi),t(K,Ri),t(K,Cs),t(Cs,Gi),t(K,Mi),d(e,_l,i),$(Dt,e,i),d(e,vl,i),d(e,ia,i),t(ia,Ui),d(e,$l,i),d(e,O,i),t(O,da),t(da,xs),t(xs,Hi),t(da,Yi),t(O,zi),t(O,Ge),t(Ge,Ds),t(Ds,Vi),t(Ge,Wi),t(Ge,pa),t(pa,Ji),t(Ge,Xi),t(O,Ki),t(O,fa),t(fa,Ts),t(Ts,Qi),t(fa,Zi),t(O,ed),t(O,ha),t(ha,Ps),t(Ps,td),t(ha,ad),t(O,sd),t(O,ca),t(ca,Os),t(Os,od),t(ca,ld),t(O,rd),t(O,ua),t(ua,Ss),t(Ss,nd),t(ua,id),d(e,yl,i),$(Me,e,i),d(e,bl,i),$(Tt,e,i),d(e,wl,i),d(e,pe,i),t(pe,Ue),t(Ue,Ls),$(Pt,Ls,null),t(pe,dd),t(pe,Fs),t(Fs,pd),d(e,El,i),d(e,ma,i),t(ma,fd),d(e,jl,i),d(e,He,i),t(He,fe),t(fe,Ot),t(Ot,hd),t(Ot,ga),t(ga,cd),t(Ot,ud),t(fe,md),t(fe,he),t(he,St),t(St,gd),t(St,Ns),t(Ns,_d),t(St,vd),t(he,$d),t(he,Bs),t(Bs,yd),t(he,bd),t(he,Rs),t(Rs,wd),t(fe,Ed),t(fe,Gs),t(Gs,jd),t(He,qd),t(He,Lt),t(Lt,B),t(B,kd),t(B,_a),t(_a,Ad),t(B,Id),t(B,Ms),t(Ms,Cd),t(B,xd),t(B,Us),t(Us,Dd),t(B,Td),t(B,Hs),t(Hs,Pd),t(B,Od),t(Lt,Sd),t(Lt,T),t(T,Ld),t(T,Ys),t(Ys,Fd),t(T,Nd),t(T,zs),t(zs,Bd),t(T,Rd),t(T,va),t(va,Gd),t(T,Md),t(T,Vs),t(Vs,Ud),t(T,Hd),t(T,Ws),t(Ws,Yd),t(T,zd),t(T,Js),t(Js,Vd),t(T,Wd),d(e,ql,i),$(Ye,e,i),d(e,kl,i),$(Ft,e,i),d(e,Al,i),d(e,ce,i),t(ce,ze),t(ze,Xs),$(Nt,Xs,null),t(ce,Jd),t(ce,Ks),t(Ks,Xd),d(e,Il,i),d(e,D,i),t(D,Kd),t(D,$a),t($a,Qd),t(D,Zd),t(D,Qs),t(Qs,ep),t(D,tp),t(D,Zs),t(Zs,ap),t(D,sp),t(D,eo),t(eo,op),t(D,lp),t(D,to),t(to,rp),t(D,np),t(D,ao),t(ao,ip),t(D,dp),d(e,Cl,i),$(Ve,e,i),d(e,xl,i),d(e,ya,i),t(ya,pp),d(e,Dl,i),$(Bt,e,i),d(e,Tl,i),d(e,ue,i),t(ue,We),t(We,so),$(Rt,so,null),t(ue,fp),t(ue,oo),t(oo,hp),d(e,Pl,i),d(e,Je,i),t(Je,cp),t(Je,lo),t(lo,up),t(Je,mp),d(e,Ol,i),d(e,Xe,i),t(Xe,gp),t(Xe,ro),t(ro,_p),t(Xe,vp),d(e,Sl,i),$(Gt,e,i),d(e,Ll,i),d(e,Q,i),t(Q,$p),t(Q,no),t(no,yp),t(Q,bp),t(Q,io),t(io,wp),t(Q,Ep),d(e,Fl,i),d(e,me,i),t(me,Ke),t(Ke,po),$(Mt,po,null),t(me,jp),t(me,fo),t(fo,qp),d(e,Nl,i),d(e,Z,i),t(Z,kp),t(Z,ba),t(ba,Ap),t(Z,Ip),t(Z,wa),t(wa,Cp),t(Z,xp),d(e,Bl,i),d(e,Ea,i),t(Ea,Dp),d(e,Rl,i),$(Ut,e,i),Gl=!0},p(e,[i]){const Ht={};i&2&&(Ht.$$scope={dirty:i,ctx:e}),_e.$set(Ht);const ho={};i&2&&(ho.$$scope={dirty:i,ctx:e}),ye.$set(ho);const co={};i&2&&(co.$$scope={dirty:i,ctx:e}),we.$set(co);const uo={};i&2&&(uo.$$scope={dirty:i,ctx:e}),Te.$set(uo);const mo={};i&2&&(mo.$$scope={dirty:i,ctx:e}),Me.$set(mo);const Yt={};i&2&&(Yt.$$scope={dirty:i,ctx:e}),Ye.$set(Yt);const zt={};i&2&&(zt.$$scope={dirty:i,ctx:e}),Ve.$set(zt)},i(e){Gl||(y(m.$$.fragment,e),y(_e.$$.fragment,e),y(at.$$.fragment,e),y(st.$$.fragment,e),y(ot.$$.fragment,e),y(lt.$$.fragment,e),y(ye.$$.fragment,e),y(rt.$$.fragment,e),y(nt.$$.fragment,e),y(we.$$.fragment,e),y(it.$$.fragment,e),y(dt.$$.fragment,e),y(pt.$$.fragment,e),y(ft.$$.fragment,e),y(ht.$$.fragment,e),y(ct.$$.fragment,e),y(ut.$$.fragment,e),y(gt.$$.fragment,e),y(_t.$$.fragment,e),y(vt.$$.fragment,e),y($t.$$.fragment,e),y(Te.$$.fragment,e),y(wt.$$.fragment,e),y(jt.$$.fragment,e),y(qt.$$.fragment,e),y(At.$$.fragment,e),y(It.$$.fragment,e),y(Ct.$$.fragment,e),y(xt.$$.fragment,e),y(Dt.$$.fragment,e),y(Me.$$.fragment,e),y(Tt.$$.fragment,e),y(Pt.$$.fragment,e),y(Ye.$$.fragment,e),y(Ft.$$.fragment,e),y(Nt.$$.fragment,e),y(Ve.$$.fragment,e),y(Bt.$$.fragment,e),y(Rt.$$.fragment,e),y(Gt.$$.fragment,e),y(Mt.$$.fragment,e),y(Ut.$$.fragment,e),Gl=!0)},o(e){b(m.$$.fragment,e),b(_e.$$.fragment,e),b(at.$$.fragment,e),b(st.$$.fragment,e),b(ot.$$.fragment,e),b(lt.$$.fragment,e),b(ye.$$.fragment,e),b(rt.$$.fragment,e),b(nt.$$.fragment,e),b(we.$$.fragment,e),b(it.$$.fragment,e),b(dt.$$.fragment,e),b(pt.$$.fragment,e),b(ft.$$.fragment,e),b(ht.$$.fragment,e),b(ct.$$.fragment,e),b(ut.$$.fragment,e),b(gt.$$.fragment,e),b(_t.$$.fragment,e),b(vt.$$.fragment,e),b($t.$$.fragment,e),b(Te.$$.fragment,e),b(wt.$$.fragment,e),b(jt.$$.fragment,e),b(qt.$$.fragment,e),b(At.$$.fragment,e),b(It.$$.fragment,e),b(Ct.$$.fragment,e),b(xt.$$.fragment,e),b(Dt.$$.fragment,e),b(Me.$$.fragment,e),b(Tt.$$.fragment,e),b(Pt.$$.fragment,e),b(Ye.$$.fragment,e),b(Ft.$$.fragment,e),b(Nt.$$.fragment,e),b(Ve.$$.fragment,e),b(Bt.$$.fragment,e),b(Rt.$$.fragment,e),b(Gt.$$.fragment,e),b(Mt.$$.fragment,e),b(Ut.$$.fragment,e),Gl=!1},d(e){a(c),e&&a(q),e&&a(u),w(m),e&&a(k),e&&a(S),e&&a(_o),e&&a(ge),e&&a(vo),w(_e,e),e&&a($o),e&&a(te),w(at),e&&a(yo),e&&a(z),e&&a(bo),w(st,e),e&&a(wo),e&&a(M),e&&a(Eo),w(ot,e),e&&a(jo),e&&a($e),e&&a(qo),w(lt,e),e&&a(ko),w(ye,e),e&&a(Ao),e&&a(be),e&&a(Io),w(rt,e),e&&a(Co),e&&a(V),e&&a(xo),w(nt,e),e&&a(Do),w(we,e),e&&a(To),e&&a(ae),w(it),e&&a(Po),e&&a(je),e&&a(Oo),w(dt,e),e&&a(So),e&&a(W),e&&a(Lo),w(pt,e),e&&a(Fo),e&&a(se),w(ft),e&&a(No),e&&a(ke),e&&a(Bo),w(ht,e),e&&a(Ro),e&&a(J),e&&a(Go),w(ct,e),e&&a(Mo),e&&a(oe),w(ut),e&&a(Uo),e&&a(U),e&&a(Ho),e&&a(Ie),e&&a(Yo),w(gt,e),e&&a(zo),e&&a(le),w(_t),e&&a(Vo),e&&a(Qt),e&&a(Wo),w(vt,e),e&&a(Jo),e&&a(Zt),e&&a(Xo),w($t,e),e&&a(Ko),e&&a(xe),e&&a(Qo),e&&a(x),e&&a(Zo),e&&a(De),e&&a(el),w(Te,e),e&&a(tl),e&&a(re),w(wt),e&&a(al),e&&a(Et),e&&a(sl),e&&a(X),e&&a(ol),e&&a(Oe),e&&a(ll),w(jt,e),e&&a(rl),e&&a(ne),w(qt),e&&a(nl),e&&a(Le),e&&a(il),e&&a(H),e&&a(dl),w(At,e),e&&a(pl),e&&a(Fe),e&&a(fl),e&&a(Ne),e&&a(hl),w(It,e),e&&a(cl),e&&a(Be),e&&a(ul),w(Ct,e),e&&a(ml),e&&a(de),w(xt),e&&a(gl),e&&a(K),e&&a(_l),w(Dt,e),e&&a(vl),e&&a(ia),e&&a($l),e&&a(O),e&&a(yl),w(Me,e),e&&a(bl),w(Tt,e),e&&a(wl),e&&a(pe),w(Pt),e&&a(El),e&&a(ma),e&&a(jl),e&&a(He),e&&a(ql),w(Ye,e),e&&a(kl),w(Ft,e),e&&a(Al),e&&a(ce),w(Nt),e&&a(Il),e&&a(D),e&&a(Cl),w(Ve,e),e&&a(xl),e&&a(ya),e&&a(Dl),w(Bt,e),e&&a(Tl),e&&a(ue),w(Rt),e&&a(Pl),e&&a(Je),e&&a(Ol),e&&a(Xe),e&&a(Sl),w(Gt,e),e&&a(Ll),e&&a(Q),e&&a(Fl),e&&a(me),w(Mt),e&&a(Nl),e&&a(Z),e&&a(Bl),e&&a(Ea),e&&a(Rl),w(Ut,e)}}}const mc={local:"create-an-image-dataset",sections:[{local:"imagefolder",sections:[{local:"image-captioning",title:"Image captioning"},{local:"object-detection",title:"Object detection"},{local:"upload-dataset-to-the-hub",title:"Upload dataset to the Hub"}],title:"ImageFolder"},{local:"loading-script",sections:[{local:"create-a-dataset-builder-class",sections:[{local:"multiple-configurations",title:"Multiple configurations"}],title:"Create a dataset builder class"},{local:"add-dataset-metadata",title:"Add dataset metadata"},{local:"download-and-define-the-dataset-splits",title:"Download and define the dataset splits"},{local:"generate-the-dataset",title:"Generate the dataset"},{local:"generate-the-dataset-metadata-optional",title:"Generate the dataset metadata (optional)"},{local:"upload-the-dataset-to-the-hub",title:"Upload the dataset to the Hub"}],title:"Loading script"}],title:"Create an image dataset"};function gc(P){return rc(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bc extends ac{constructor(c){super();sc(this,c,gc,uc,oc,{})}}export{bc as default,mc as metadata};
