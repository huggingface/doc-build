import{S as Gv,i as Fv,s as Hv,e as l,k as h,w as v,t as s,M as Bv,c as r,d as t,m as c,a as n,x as w,h as o,b as f,G as a,g as d,y,q as $,o as j,B as E,v as Mv}from"../chunks/vendor-hf-doc-builder.js";import{T as pe}from"../chunks/Tip-hf-doc-builder.js";import{I as se}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as O}from"../chunks/CodeBlock-hf-doc-builder.js";function Vv(I){let p,k,u,g,b;return{c(){p=l("p"),k=s("You can control access to your dataset by requiring users to share their contact information first. Check out the "),u=l("a"),g=s("Gated datasets"),b=s(" guide for more information about how to enable this feature on the Hub."),this.h()},l(_){p=r(_,"P",{});var m=n(p);k=o(m,"You can control access to your dataset by requiring users to share their contact information first. Check out the "),u=r(m,"A",{href:!0,rel:!0});var x=n(u);g=o(x,"Gated datasets"),x.forEach(t),b=o(m," guide for more information about how to enable this feature on the Hub."),m.forEach(t),this.h()},h(){f(u,"href","https://huggingface.co/docs/hub/datasets-gated"),f(u,"rel","nofollow")},m(_,m){d(_,p,m),a(p,k),a(p,u),a(u,g),a(p,b)},d(_){_&&t(p)}}}function Yv(I){let p,k,u,g,b;return{c(){p=l("p"),k=s("It can be helpful to store your metadata as a "),u=l("code"),g=s("jsonl"),b=s(" file if the data columns contain a more complex format (like a list of floats) to avoid parsing errors or reading complex values as strings.")},l(_){p=r(_,"P",{});var m=n(p);k=o(m,"It can be helpful to store your metadata as a "),u=r(m,"CODE",{});var x=n(u);g=o(x,"jsonl"),x.forEach(t),b=o(m," file if the data columns contain a more complex format (like a list of floats) to avoid parsing errors or reading complex values as strings."),m.forEach(t)},m(_,m){d(_,p,m),a(p,k),a(p,u),a(u,g),a(p,b)},d(_){_&&t(p)}}}function Wv(I){let p,k,u,g,b;return{c(){p=l("p"),k=s("Note that if audio files are located not right next to a metadata file, "),u=l("code"),g=s("file_name"),b=s(" column should be a full relative path to an audio file, not just its filename.")},l(_){p=r(_,"P",{});var m=n(p);k=o(m,"Note that if audio files are located not right next to a metadata file, "),u=r(m,"CODE",{});var x=n(u);g=o(x,"file_name"),x.forEach(t),b=o(m," column should be a full relative path to an audio file, not just its filename."),m.forEach(t)},m(_,m){d(_,p,m),a(p,k),a(p,u),a(u,g),a(p,b)},d(_){_&&t(p)}}}function Kv(I){let p,k,u,g,b,_,m,x;return{c(){p=l("p"),k=s("If all audio files are contained in a single directory or if they are not on the same level of directory structure, "),u=l("code"),g=s("label"),b=s(" column won\u2019t be added automatically. If you need it, set "),_=l("code"),m=s("drop_labels=False"),x=s(" explicitly.")},l(A){p=r(A,"P",{});var q=n(p);k=o(q,"If all audio files are contained in a single directory or if they are not on the same level of directory structure, "),u=r(q,"CODE",{});var D=n(u);g=o(D,"label"),D.forEach(t),b=o(q," column won\u2019t be added automatically. If you need it, set "),_=r(q,"CODE",{});var T=n(_);m=o(T,"drop_labels=False"),T.forEach(t),x=o(q," explicitly."),q.forEach(t)},m(A,q){d(A,p,q),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x)},d(A){A&&t(p)}}}function Xv(I){let p,k,u,g,b,_,m,x,A,q,D;return{c(){p=l("p"),k=s("Some audio datasets, like those found in "),u=l("a"),g=s("Kaggle competitions"),b=s(", have separate metadata files for each split. Provided the metadata features are the same for each split, "),_=l("code"),m=s("audiofolder"),x=s(" can be used to load all splits at once. If the metadata features differ across each split, you should load them with separate "),A=l("code"),q=s("load_dataset()"),D=s(" calls."),this.h()},l(T){p=r(T,"P",{});var C=n(p);k=o(C,"Some audio datasets, like those found in "),u=r(C,"A",{href:!0,rel:!0});var U=n(u);g=o(U,"Kaggle competitions"),U.forEach(t),b=o(C,", have separate metadata files for each split. Provided the metadata features are the same for each split, "),_=r(C,"CODE",{});var G=n(_);m=o(G,"audiofolder"),G.forEach(t),x=o(C," can be used to load all splits at once. If the metadata features differ across each split, you should load them with separate "),A=r(C,"CODE",{});var F=n(A);q=o(F,"load_dataset()"),F.forEach(t),D=o(C," calls."),C.forEach(t),this.h()},h(){f(u,"href","https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/overview"),f(u,"rel","nofollow")},m(T,C){d(T,p,C),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x),a(p,A),a(A,q),a(p,D)},d(T){T&&t(p)}}}function Zv(I){let p,k,u,g,b;return{c(){p=l("p"),k=s("This guide shows how to process audio data stored in TAR archives - the most frequent case for audio datasets. Check out "),u=l("a"),g=s("minds14"),b=s(" dataset for an example of an audio script which uses ZIP archives."),this.h()},l(_){p=r(_,"P",{});var m=n(p);k=o(m,"This guide shows how to process audio data stored in TAR archives - the most frequent case for audio datasets. Check out "),u=r(m,"A",{href:!0,rel:!0});var x=n(u);g=o(x,"minds14"),x.forEach(t),b=o(m," dataset for an example of an audio script which uses ZIP archives."),m.forEach(t),this.h()},h(){f(u,"href","https://huggingface.co/datasets/PolyAI/minds14/blob/main/minds14.py"),f(u,"rel","nofollow")},m(_,m){d(_,p,m),a(p,k),a(p,u),a(u,g),a(p,b)},d(_){_&&t(p)}}}function Jv(I){let p,k,u,g,b;return{c(){p=l("p"),k=s("To help you get started, we created a loading script "),u=l("a"),g=s("template"),b=s(" you can copy and use as a starting point!"),this.h()},l(_){p=r(_,"P",{});var m=n(p);k=o(m,"To help you get started, we created a loading script "),u=r(m,"A",{href:!0,rel:!0});var x=n(u);g=o(x,"template"),x.forEach(t),b=o(m," you can copy and use as a starting point!"),m.forEach(t),this.h()},h(){f(u,"href","https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py"),f(u,"rel","nofollow")},m(_,m){d(_,p,m),a(p,k),a(p,u),a(u,g),a(p,b)},d(_){_&&t(p)}}}function Qv(I){let p,k,u,g,b,_,m,x,A,q,D;return{c(){p=l("p"),k=s("Typically, users need to specify a configuration to load in "),u=l("a"),g=s("load_dataset()"),b=s(", otherwise a "),_=l("code"),m=s("ValueError"),x=s(" is raised. You can avoid this by setting a default dataset configuration to load in "),A=l("code"),q=s("DEFAULT_CONFIG_NAME"),D=s("."),this.h()},l(T){p=r(T,"P",{});var C=n(p);k=o(C,"Typically, users need to specify a configuration to load in "),u=r(C,"A",{href:!0});var U=n(u);g=o(U,"load_dataset()"),U.forEach(t),b=o(C,", otherwise a "),_=r(C,"CODE",{});var G=n(_);m=o(G,"ValueError"),G.forEach(t),x=o(C," is raised. You can avoid this by setting a default dataset configuration to load in "),A=r(C,"CODE",{});var F=n(A);q=o(F,"DEFAULT_CONFIG_NAME"),F.forEach(t),D=o(C,"."),C.forEach(t),this.h()},h(){f(u,"href","/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset")},m(T,C){d(T,p,C),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x),a(p,A),a(A,q),a(p,D)},d(T){T&&t(p)}}}function ew(I){let p,k,u,g,b,_,m,x;return{c(){p=l("p"),k=s("You\u2019ll notice a lot of the dataset information is defined earlier in the loading script which can make it easier to read. There are also other "),u=l("code"),g=s("~Dataset.Features"),b=s(" you can input, so be sure to check out the full list and "),_=l("a"),m=s("features guide"),x=s(" for more details."),this.h()},l(A){p=r(A,"P",{});var q=n(p);k=o(q,"You\u2019ll notice a lot of the dataset information is defined earlier in the loading script which can make it easier to read. There are also other "),u=r(q,"CODE",{});var D=n(u);g=o(D,"~Dataset.Features"),D.forEach(t),b=o(q," you can input, so be sure to check out the full list and "),_=r(q,"A",{href:!0});var T=n(_);m=o(T,"features guide"),T.forEach(t),x=o(q," for more details."),q.forEach(t),this.h()},h(){f(_,"href","./about_dataset_features")},m(A,q){d(A,p,q),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x)},d(A){A&&t(p)}}}function aw(I){let p,k,u,g,b,_,m,x;return{c(){p=l("p"),k=s("This implementation does not extract downloaded archives. If you want to extract files after download, you need to additionally use "),u=l("a"),g=s("extract()"),b=s(", see the "),_=l("a"),m=s("(Advanced) Extract TAR archives"),x=s(" section."),this.h()},l(A){p=r(A,"P",{});var q=n(p);k=o(q,"This implementation does not extract downloaded archives. If you want to extract files after download, you need to additionally use "),u=r(q,"A",{href:!0});var D=n(u);g=o(D,"extract()"),D.forEach(t),b=o(q,", see the "),_=r(q,"A",{href:!0});var T=n(_);m=o(T,"(Advanced) Extract TAR archives"),T.forEach(t),x=o(q," section."),q.forEach(t),this.h()},h(){f(u,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.extract"),f(_,"href","#advanced-extract-tar-archives-locally")},m(A,q){d(A,p,q),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x)},d(A){A&&t(p)}}}function tw(I){let p,k,u,g,b,_,m,x;return{c(){p=l("p"),k=s("The reason you need to use a combination of "),u=l("a"),g=s("download()"),b=s(" and "),_=l("a"),m=s("iter_archive()"),x=s(" is because data in TAR archives can\u2019t be accessed directly from their paths. Instead, you\u2019ll need to download it first and then sequentially iterate over the files within the archive!"),this.h()},l(A){p=r(A,"P",{});var q=n(p);k=o(q,"The reason you need to use a combination of "),u=r(q,"A",{href:!0});var D=n(u);g=o(D,"download()"),D.forEach(t),b=o(q," and "),_=r(q,"A",{href:!0});var T=n(_);m=o(T,"iter_archive()"),T.forEach(t),x=o(q," is because data in TAR archives can\u2019t be accessed directly from their paths. Instead, you\u2019ll need to download it first and then sequentially iterate over the files within the archive!"),q.forEach(t),this.h()},h(){f(u,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download"),f(_,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive")},m(A,q){d(A,p,q),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x)},d(A){A&&t(p)}}}function sw(I){let p,k,u,g,b,_,m,x,A,q,D,T,C,U,G,F,za,he,X,Ae;return{c(){p=l("p"),k=s("You can use "),u=l("a"),g=s("download_and_extract()"),b=s(" to download and extract TAR archives too, but this method, as well as "),_=l("a"),m=s("extract()"),x=s(", would throw an error if you run "),A=l("code"),q=s("~Datasets.load_dataset"),D=s(" in streaming mode, i.e. with "),T=l("code"),C=s("streaming=True"),U=s(". This is the reason you need to use a combination of "),G=l("a"),F=s("download()"),za=s(" and "),he=l("a"),X=s("iter_archive()"),Ae=s(". Files in TAR archives can\u2019t be accessed directly by their paths. Instead, you have to sequentially iterate over the files within the archive to find a specific file."),this.h()},l(ee){p=r(ee,"P",{});var L=n(p);k=o(L,"You can use "),u=r(L,"A",{href:!0});var Te=n(u);g=o(Te,"download_and_extract()"),Te.forEach(t),b=o(L," to download and extract TAR archives too, but this method, as well as "),_=r(L,"A",{href:!0});var Yt=n(_);m=o(Yt,"extract()"),Yt.forEach(t),x=o(L,", would throw an error if you run "),A=r(L,"CODE",{});var Wt=n(A);q=o(Wt,"~Datasets.load_dataset"),Wt.forEach(t),D=o(L," in streaming mode, i.e. with "),T=r(L,"CODE",{});var Kt=n(T);C=o(Kt,"streaming=True"),Kt.forEach(t),U=o(L,". This is the reason you need to use a combination of "),G=r(L,"A",{href:!0});var Ye=n(G);F=o(Ye,"download()"),Ye.forEach(t),za=o(L," and "),he=r(L,"A",{href:!0});var fe=n(he);X=o(fe,"iter_archive()"),fe.forEach(t),Ae=o(L,". Files in TAR archives can\u2019t be accessed directly by their paths. Instead, you have to sequentially iterate over the files within the archive to find a specific file."),L.forEach(t),this.h()},h(){f(u,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract"),f(_,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.extract"),f(G,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download"),f(he,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive")},m(ee,L){d(ee,p,L),a(p,k),a(p,u),a(u,g),a(p,b),a(p,_),a(_,m),a(p,x),a(p,A),a(A,q),a(p,D),a(p,T),a(T,C),a(p,U),a(p,G),a(G,F),a(p,za),a(p,he),a(he,X),a(p,Ae)},d(ee){ee&&t(p)}}}function ow(I){let p,k,u,g,b,_,m,x,A,q,D,T,C,U,G,F,za,he,X,Ae,ee,L,Te,Yt,Wt,Kt,Ye,fe,Ki,Xs,Xi,Zi,Ji,Zs,Js,Qi,jr,We,Er,De,Ke,Qs,Na,ed,eo,ad,br,ue,td,Xt,sd,od,Zt,ld,rd,kr,Ua,qr,Xe,nd,Jt,id,dd,xr,Ga,Ar,Qt,pd,Tr,Fa,Dr,Ce,Ze,ao,Ha,hd,to,cd,Cr,Z,fd,so,ud,_d,oo,md,gd,lo,vd,wd,ro,yd,$d,Or,Je,jd,no,Ed,bd,Ir,Ba,Sr,Qe,kd,io,qd,xd,Pr,ea,Lr,aa,Ad,po,Td,Dd,Rr,Ma,zr,es,Cd,Nr,Va,Ur,oe,Od,ho,Id,Sd,as,Pd,Ld,co,Rd,zd,Gr,Ya,Fr,ta,Nd,fo,Ud,Gd,Hr,Wa,Br,sa,Mr,oa,Fd,uo,Hd,Bd,Vr,Ka,Yr,_e,Md,_o,Vd,Yd,mo,Wd,Kd,Wr,Xa,Kr,la,Xr,ra,Zr,Oe,na,go,Za,Xd,vo,Zd,Jr,ts,Jd,Qr,Ja,en,me,Qd,wo,ep,ap,yo,tp,sp,an,ss,op,tn,Qa,sn,ge,lp,et,rp,np,$o,ip,dp,on,ia,at,pp,os,hp,cp,fp,jo,up,ln,ls,_p,rn,tt,nn,rs,mp,dn,H,Eo,gp,vp,bo,wp,yp,ko,$p,jp,qo,Ep,bp,xo,kp,qp,Ao,xp,pn,da,Ap,st,Tp,Dp,hn,pa,cn,ha,fn,Ie,ca,To,ot,Cp,Do,Op,un,lt,ns,Ip,Sp,_n,ve,is,Co,Pp,Lp,Rp,ds,Oo,zp,Np,Up,fa,Io,Gp,Fp,So,Hp,Bp,mn,ua,Mp,ps,Vp,Yp,gn,rt,vn,Se,_a,Po,nt,Wp,Lo,Kp,wn,ma,Xp,it,Zp,Jp,yn,le,Qp,hs,eh,ah,Ro,th,sh,zo,oh,lh,$n,dt,jn,J,rh,No,nh,ih,cs,dh,ph,Uo,hh,ch,pt,fh,uh,En,ht,bn,ga,kn,va,_h,Go,mh,gh,qn,ct,xn,Pe,wa,Fo,ft,vh,Ho,wh,An,we,yh,fs,$h,jh,Bo,Eh,bh,Tn,ut,Dn,us,kh,Cn,Q,_s,Mo,qh,xh,Ah,ye,Vo,Th,Dh,ms,Ch,Oh,Yo,Ih,Sh,Ph,gs,Wo,Lh,Rh,zh,vs,Ko,Nh,Uh,Gh,ws,Xo,Fh,Hh,On,ya,In,_t,Sn,Le,$a,Zo,mt,Bh,Jo,Mh,Pn,ys,Vh,Ln,ja,gt,ce,Yh,$s,Wh,Kh,Qo,Xh,Zh,el,Jh,Qh,ec,Re,vt,ac,al,tc,sc,oc,tl,lc,rc,sl,nc,ic,wt,ae,dc,js,pc,hc,ol,cc,fc,ll,uc,_c,rl,mc,gc,vc,W,wc,nl,yc,$c,il,jc,Ec,dl,bc,kc,pl,qc,xc,Es,Ac,Tc,Rn,yt,zn,Ea,Nn,ze,ba,hl,$t,Dc,cl,Cc,Un,R,Oc,bs,Ic,Sc,fl,Pc,Lc,ul,Rc,zc,_l,Nc,Uc,ml,Gc,Fc,gl,Hc,Bc,vl,Mc,Vc,Gn,ks,Yc,Fn,jt,Hn,z,Wc,wl,Kc,Xc,qs,Zc,Jc,yl,Qc,ef,$l,af,tf,jl,sf,of,El,lf,rf,bl,nf,df,Bn,Et,Mn,ka,pf,kl,hf,cf,Vn,bt,Yn,Ne,qa,ql,kt,ff,xl,uf,Wn,$e,_f,xs,mf,gf,As,vf,wf,Kn,Ts,yf,Xn,qt,Zn,Ue,xa,Al,xt,$f,Tl,jf,Jn,Aa,Ef,At,bf,kf,Qn,Ge,Ta,Dl,Tt,qf,Cl,xf,ei,je,Ol,Fe,Af,Ds,Tf,Df,Il,Cf,Of,If,Dt,He,Sf,Cs,Pf,Lf,Sl,Rf,zf,Nf,Ct,Uf,Pl,K,Gf,Os,Ff,Hf,Ll,Bf,Mf,Is,Vf,Yf,Rl,Wf,Kf,zl,Xf,Zf,ai,Da,ti,Ot,Be,Jf,Ss,Qf,eu,Nl,au,tu,si,Ca,oi,It,St,te,su,Ps,ou,lu,Ul,ru,nu,Gl,iu,du,Fl,pu,hu,cu,N,fu,Hl,uu,_u,Bl,mu,gu,Ml,vu,wu,Vl,yu,$u,Yl,ju,Eu,Wl,bu,ku,Ls,qu,xu,li,Pt,ri,Me,Oa,Kl,Lt,Au,Xl,Tu,ni,B,Du,Zl,Cu,Ou,Jl,Iu,Su,Ql,Pu,Lu,er,Ru,zu,ar,Nu,Uu,ii,Ia,Rt,zt,Gu,tr,Fu,Hu,Bu,Nt,Mu,Ut,S,Vu,sr,Yu,Wu,Rs,Ku,Xu,or,Zu,Ju,lr,Qu,e_,rr,a_,t_,nr,s_,o_,ir,l_,r_,dr,n_,i_,pr,d_,p_,hr,h_,c_,f_,Gt,di,Sa,u_,cr,__,m_,pi,Ft,hi;return _=new se({}),U=new O({props:{code:`from datasets import load_dataset

dataset = load_dataset("<username>/my_dataset")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

dataset = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)`}}),We=new pe({props:{$$slots:{default:[Vv]},$$scope:{ctx:I}}}),Na=new se({}),Ua=new O({props:{code:`audio_dataset = Dataset.from_dict({"audio": ["path/to/audio_1", "path/to/audio_2", ..., "path/to/audio_n"]}).cast_column("audio", Audio())
audio_dataset[0]["audio"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>audio_dataset = Dataset.from_dict({<span class="hljs-string">&quot;audio&quot;</span>: [<span class="hljs-string">&quot;path/to/audio_1&quot;</span>, <span class="hljs-string">&quot;path/to/audio_2&quot;</span>, ..., <span class="hljs-string">&quot;path/to/audio_n&quot;</span>]}).cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio())
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>, ..., -<span class="hljs-number">0.00024414</span>,
         <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;path/to/audio_1&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`}}),Ga=new O({props:{code:'audio_dataset.push_to_hub("<username>/my_dataset")',highlighted:'audio_dataset.push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)'}}),Fa=new O({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u2514\u2500\u2500 train-00000-of-00001.parquet`,highlighted:`<span class="hljs-title">my_dataset</span>/
\u251C\u2500\u2500 <span class="hljs-type">README</span>.md
\u2514\u2500\u2500 <span class="hljs-class"><span class="hljs-keyword">data</span>/</span>
    \u2514\u2500\u2500 train-<span class="hljs-number">00000</span>-<span class="hljs-keyword">of</span>-<span class="hljs-number">00001</span>.parquet`}}),Ha=new se({}),Ba=new O({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 metadata.csv
\u2514\u2500\u2500 data/`,highlighted:`<span class="hljs-title">my_dataset</span>/
\u251C\u2500\u2500 <span class="hljs-type">README</span>.md
\u251C\u2500\u2500 metadata.csv
\u2514\u2500\u2500 <span class="hljs-class"><span class="hljs-keyword">data</span>/</span>`}}),ea=new pe({props:{$$slots:{default:[Yv]},$$scope:{ctx:I}}}),Ma=new O({props:{code:`file_name,transcription
data/first_audio_file.mp3,znowu si\u0119 duch z cia\u0142em zro\u015Bnie w m\u0142odocianej wstaniesz wiosnie i mo\u017Cesz skutkiem tych lek\xF3w umiera\u0107 wstawa\u0107 wiek wiek\xF3w dalej tam by\u0142y przestrogi jak sieka\u0107 g\u0142ow\u0119 jak nogi
data/second_audio_file.mp3,ju\u017C u \u017Awierzy\u0144ca podwoj\xF3w kr\xF3l zasiada przy nim ksi\u0105\u017C\u0119ta i panowie rada a gdzie wznios\u0142y kr\u0105\u017Cy\u0142 ganek rycerze obok kochanek kr\xF3l skin\u0105\u0142 palcem zacz\u0119to igrzysko
data/third_audio_file.mp3,pewnie k\u0119dy\u015B w ob\u0142\u0119dzie ubite min\u0119\u0142y szlaki zaczekajmy dzie\u0144 jaki po\u015Blemy szuka\u0107 wsz\u0119dzie dzi\u015B jutro pewnie b\u0119dzie pos\u0142ali wsz\u0119dzie s\u0142ugi czekali dzie\u0144 i drugi gdy nic nie doczekali z p\u0142aczem chc\u0105 jecha\u0107 dali`,highlighted:`file_name,transcription
data/first_audio_file<span class="hljs-selector-class">.mp3</span>,znowu si\u0119 duch z cia\u0142<span class="hljs-selector-tag">em</span> zro\u015Bnie w m\u0142odocianej wstaniesz wiosnie <span class="hljs-selector-tag">i</span> mo\u017Cesz skutkiem tych lek\xF3w umiera\u0107 wstawa\u0107 wiek wiek\xF3w dalej tam by\u0142y przestrogi jak sieka\u0107 g\u0142ow\u0119 jak nogi
data/second_audio_file<span class="hljs-selector-class">.mp3</span>,ju\u017C u \u017Awierzy\u0144ca podwoj\xF3w kr\xF3l zasiada przy nim ksi\u0105\u017C\u0119ta <span class="hljs-selector-tag">i</span> panowie rada <span class="hljs-selector-tag">a</span> gdzie wznios\u0142y kr\u0105\u017Cy\u0142 ganek rycerze obok kochanek kr\xF3l skin\u0105\u0142 palcem zacz\u0119<span class="hljs-selector-tag">to</span> igrzysko
data/third_audio_file<span class="hljs-selector-class">.mp3</span>,pewnie k\u0119dy\u015B w ob\u0142\u0119dzie ubite min\u0119\u0142y szlaki zaczekajmy dzie\u0144 jaki po\u015Blemy szuka\u0107 wsz\u0119dzie dzi\u015B jutro pewnie <span class="hljs-selector-tag">b</span>\u0119dzie pos\u0142ali wsz\u0119dzie s\u0142ugi czekali dzie\u0144 <span class="hljs-selector-tag">i</span> drugi gdy nic nie doczekali z <span class="hljs-selector-tag">p</span>\u0142aczem chc\u0105 jecha\u0107 dali`}}),Va=new O({props:{code:`metadata.csv
data/first_audio_file.mp3
data/second_audio_file.mp3
data/third_audio_file.mp3
`,highlighted:`<span class="hljs-title">metadata</span>.csv
<span class="hljs-class"><span class="hljs-keyword">data</span>/first_audio_file.mp3</span>
<span class="hljs-class"><span class="hljs-keyword">data</span>/second_audio_file.mp3</span>
<span class="hljs-class"><span class="hljs-keyword">data</span>/third_audio_file.mp3</span>
`}}),Ya=new O({props:{code:`from datasets import load_dataset
dataset = load_dataset("audiofolder", data_dir="/path/to/data")
dataset["train"][0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;audiofolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/data&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>:
    {<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/path/to/extracted/audio/first_audio_file.mp3&#x27;</span>,
    <span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.00088501</span>,  <span class="hljs-number">0.0012207</span> ,  <span class="hljs-number">0.00131226</span>, ..., -<span class="hljs-number">0.00045776</span>, -<span class="hljs-number">0.00054932</span>, -<span class="hljs-number">0.00054932</span>], dtype=float32),
    <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>},
 <span class="hljs-string">&#x27;transcription&#x27;</span>: <span class="hljs-string">&#x27;znowu si\u0119 duch z cia\u0142em zro\u015Bnie w m\u0142odocianej wstaniesz wiosnie i mo\u017Cesz skutkiem tych lek\xF3w umiera\u0107 wstawa\u0107 wiek wiek\xF3w dalej tam by\u0142y przestrogi jak sieka\u0107 g\u0142ow\u0119 jak nogi&#x27;</span>
}`}}),Wa=new O({props:{code:`data/train/first_train_audio_file.mp3
data/train/second_train_audio_file.mp3

data/test/first_test_audio_file.mp3
data/test/second_test_audio_file.mp3
`,highlighted:`data<span class="hljs-regexp">/train/</span>first_train_audio_file.mp3
data<span class="hljs-regexp">/train/</span>second_train_audio_file.mp3

data<span class="hljs-regexp">/test/</span>first_test_audio_file.mp3
data<span class="hljs-regexp">/test/</span>second_test_audio_file.mp3
`}}),sa=new pe({props:{warning:!0,$$slots:{default:[Wv]},$$scope:{ctx:I}}}),Ka=new O({props:{code:`data/train/electronic/01.mp3
data/train/punk/01.mp3

data/test/electronic/09.mp3
data/test/punk/09.mp3`,highlighted:`data<span class="hljs-regexp">/train/</span>electronic/<span class="hljs-number">01</span>.mp3
data<span class="hljs-regexp">/train/</span>punk/<span class="hljs-number">01</span>.mp3

data<span class="hljs-regexp">/test/</span>electronic/<span class="hljs-number">09</span>.mp3
data<span class="hljs-regexp">/test/</span>punk/<span class="hljs-number">09</span>.mp3`}}),Xa=new O({props:{code:`from datasets import load_dataset
dataset = load_dataset("audiofolder", data_dir="/path/to/data")
dataset["train"][0]
dataset["train"][-1]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;audiofolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/data&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>:
    {<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/path/to/electronic/01.mp3&#x27;</span>,
     <span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">3.9714024e-07</span>,  <span class="hljs-number">7.3031038e-07</span>,  <span class="hljs-number">7.5640685e-07</span>, ...,
         -<span class="hljs-number">1.1963668e-01</span>, -<span class="hljs-number">1.1681189e-01</span>, -<span class="hljs-number">1.1244172e-01</span>], dtype=float32),
     <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">44100</span>},
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>  <span class="hljs-comment"># &quot;electronic&quot;</span>
}
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][-<span class="hljs-number">1</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>:
    {<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/path/to/punk/01.mp3&#x27;</span>,
     <span class="hljs-string">&#x27;array&#x27;</span>: array([<span class="hljs-number">0.15237972</span>, <span class="hljs-number">0.13222949</span>, <span class="hljs-number">0.10627693</span>, ..., <span class="hljs-number">0.41940814</span>, <span class="hljs-number">0.37578005</span>,
         <span class="hljs-number">0.33717662</span>], dtype=float32),
     <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">44100</span>},
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>  <span class="hljs-comment"># &quot;punk&quot;</span>
}`}}),la=new pe({props:{warning:!0,$$slots:{default:[Kv]},$$scope:{ctx:I}}}),ra=new pe({props:{$$slots:{default:[Xv]},$$scope:{ctx:I}}}),Za=new se({}),Ja=new O({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 my_dataset.py
\u2514\u2500\u2500 data/`,highlighted:`<span class="hljs-title">my_dataset</span>/
\u251C\u2500\u2500 <span class="hljs-type">README</span>.md
\u251C\u2500\u2500 my_dataset.py
\u2514\u2500\u2500 <span class="hljs-class"><span class="hljs-keyword">data</span>/</span>`}}),Qa=new O({props:{code:`from datasets import load_dataset
dataset = load_dataset("path/to/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;path/to/my_dataset&quot;</span>)`}}),tt=new O({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 my_dataset.py
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.tar.gz
    \u251C\u2500\u2500 test.tar.gz
    \u2514\u2500\u2500 metadata.csv`,highlighted:`my_dataset/
\u251C\u2500\u2500 README<span class="hljs-selector-class">.md</span>
\u251C\u2500\u2500 my_dataset<span class="hljs-selector-class">.py</span>
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train<span class="hljs-selector-class">.tar</span><span class="hljs-selector-class">.gz</span>
    \u251C\u2500\u2500 test<span class="hljs-selector-class">.tar</span><span class="hljs-selector-class">.gz</span>
    \u2514\u2500\u2500 metadata.csv`}}),pa=new pe({props:{warning:"True",$$slots:{default:[Zv]},$$scope:{ctx:I}}}),ha=new pe({props:{$$slots:{default:[Jv]},$$scope:{ctx:I}}}),ot=new se({}),rt=new O({props:{code:`class VivosDataset(datasets.GeneratorBasedBuilder):
    """VIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for
    Vietnamese Automatic Speech Recognition task."""

    def _info(self):

    def _split_generators(self, dl_manager):

    def _generate_examples(self, prompts_path, path_to_clips, audio_files):
`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">VivosDataset</span>(datasets.GeneratorBasedBuilder):
    <span class="hljs-string">&quot;&quot;&quot;VIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for
    Vietnamese Automatic Speech Recognition task.&quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager</span>):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, prompts_path, path_to_clips, audio_files</span>):
`}}),nt=new se({}),dt=new O({props:{code:`class LibriVoxIndonesiaConfig(datasets.BuilderConfig):
    """BuilderConfig for LibriVoxIndonesia."""

    def __init__(self, name, version, **kwargs):
        self.language = kwargs.pop("language", None)
        self.release_date = kwargs.pop("release_date", None)
        self.num_clips = kwargs.pop("num_clips", None)
        self.num_speakers = kwargs.pop("num_speakers", None)
        self.validated_hr = kwargs.pop("validated_hr", None)
        self.total_hr = kwargs.pop("total_hr", None)
        self.size_bytes = kwargs.pop("size_bytes", None)
        self.size_human = size_str(self.size_bytes)
        description = (
            f"LibriVox-Indonesia speech to text dataset in {self.language} released on {self.release_date}. "
            f"The dataset comprises {self.validated_hr} hours of transcribed speech data"
        )
        super(LibriVoxIndonesiaConfig, self).__init__(
            name=name,
            version=datasets.Version(version),
            description=description,
            **kwargs,
        )`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">LibriVoxIndonesiaConfig</span>(datasets.BuilderConfig):
    <span class="hljs-string">&quot;&quot;&quot;BuilderConfig for LibriVoxIndonesia.&quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, version, **kwargs</span>):
        self.language = kwargs.pop(<span class="hljs-string">&quot;language&quot;</span>, <span class="hljs-literal">None</span>)
        self.release_date = kwargs.pop(<span class="hljs-string">&quot;release_date&quot;</span>, <span class="hljs-literal">None</span>)
        self.num_clips = kwargs.pop(<span class="hljs-string">&quot;num_clips&quot;</span>, <span class="hljs-literal">None</span>)
        self.num_speakers = kwargs.pop(<span class="hljs-string">&quot;num_speakers&quot;</span>, <span class="hljs-literal">None</span>)
        self.validated_hr = kwargs.pop(<span class="hljs-string">&quot;validated_hr&quot;</span>, <span class="hljs-literal">None</span>)
        self.total_hr = kwargs.pop(<span class="hljs-string">&quot;total_hr&quot;</span>, <span class="hljs-literal">None</span>)
        self.size_bytes = kwargs.pop(<span class="hljs-string">&quot;size_bytes&quot;</span>, <span class="hljs-literal">None</span>)
        self.size_human = size_str(self.size_bytes)
        description = (
            <span class="hljs-string">f&quot;LibriVox-Indonesia speech to text dataset in <span class="hljs-subst">{self.language}</span> released on <span class="hljs-subst">{self.release_date}</span>. &quot;</span>
            <span class="hljs-string">f&quot;The dataset comprises <span class="hljs-subst">{self.validated_hr}</span> hours of transcribed speech data&quot;</span>
        )
        <span class="hljs-built_in">super</span>(LibriVoxIndonesiaConfig, self).__init__(
            name=name,
            version=datasets.Version(version),
            description=description,
            **kwargs,
        )`}}),ht=new O({props:{code:`class LibriVoxIndonesiaConfig(datasets.GeneratorBasedBuilder):
    DEFAULT_CONFIG_NAME = "all"

    BUILDER_CONFIGS = [
        LibriVoxIndonesiaConfig(
            name=lang,
            version=STATS["version"],
            language=LANGUAGES[lang],
            release_date=STATS["date"],
            num_clips=lang_stats["clips"],
            num_speakers=lang_stats["users"],
            total_hr=float(lang_stats["totalHrs"]) if lang_stats["totalHrs"] else None,
            size_bytes=int(lang_stats["size"]) if lang_stats["size"] else None,
        )
        for lang, lang_stats in STATS["locales"].items()
    ]`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">LibriVoxIndonesiaConfig</span>(datasets.GeneratorBasedBuilder):
    DEFAULT_CONFIG_NAME = <span class="hljs-string">&quot;all&quot;</span>

    BUILDER_CONFIGS = [
        LibriVoxIndonesiaConfig(
            name=lang,
            version=STATS[<span class="hljs-string">&quot;version&quot;</span>],
            language=LANGUAGES[lang],
            release_date=STATS[<span class="hljs-string">&quot;date&quot;</span>],
            num_clips=lang_stats[<span class="hljs-string">&quot;clips&quot;</span>],
            num_speakers=lang_stats[<span class="hljs-string">&quot;users&quot;</span>],
            total_hr=<span class="hljs-built_in">float</span>(lang_stats[<span class="hljs-string">&quot;totalHrs&quot;</span>]) <span class="hljs-keyword">if</span> lang_stats[<span class="hljs-string">&quot;totalHrs&quot;</span>] <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,
            size_bytes=<span class="hljs-built_in">int</span>(lang_stats[<span class="hljs-string">&quot;size&quot;</span>]) <span class="hljs-keyword">if</span> lang_stats[<span class="hljs-string">&quot;size&quot;</span>] <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,
        )
        <span class="hljs-keyword">for</span> lang, lang_stats <span class="hljs-keyword">in</span> STATS[<span class="hljs-string">&quot;locales&quot;</span>].items()
    ]`}}),ga=new pe({props:{$$slots:{default:[Qv]},$$scope:{ctx:I}}}),ct=new O({props:{code:`from datasets import load_dataset
dataset = load_dataset("indonesian-nlp/librivox-indonesia", "bal", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;indonesian-nlp/librivox-indonesia&quot;</span>, <span class="hljs-string">&quot;bal&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),ft=new se({}),ut=new O({props:{code:`from datasets import load_dataset_builder
ds_builder = load_dataset_builder("vivos")
ds_builder.info`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder = load_dataset_builder(<span class="hljs-string">&quot;vivos&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder.info`}}),ya=new pe({props:{$$slots:{default:[ew]},$$scope:{ctx:I}}}),_t=new O({props:{code:`def _info(self):
    return datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                "speaker_id": datasets.Value("string"),
                "path": datasets.Value("string"),
                "audio": datasets.Audio(sampling_rate=16_000),
                "sentence": datasets.Value("string"),
            }
        ),
        supervised_keys=None,
        homepage=_HOMEPAGE,
        license=_LICENSE,
        citation=_CITATION,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">return</span> datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                <span class="hljs-string">&quot;speaker_id&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;path&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;audio&quot;</span>: datasets.Audio(sampling_rate=<span class="hljs-number">16_000</span>),
                <span class="hljs-string">&quot;sentence&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
            }
        ),
        supervised_keys=<span class="hljs-literal">None</span>,
        homepage=_HOMEPAGE,
        license=_LICENSE,
        citation=_CITATION,
    )`}}),mt=new se({}),yt=new O({props:{code:`def _split_generators(self, dl_manager):
    """Returns SplitGenerators."""
    prompts_paths = dl_manager.download(_PROMPTS_URLS)
    archive = dl_manager.download(_DATA_URL)
    train_dir = "vivos/train"
    test_dir = "vivos/test"

    return [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                "prompts_path": prompts_paths["train"],
                "path_to_clips": train_dir + "/waves",
                "audio_files": dl_manager.iter_archive(archive),
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                "prompts_path": prompts_paths["test"],
                "path_to_clips": test_dir + "/waves",
                "audio_files": dl_manager.iter_archive(archive),
            },
        ),
    ]`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager</span>):
    <span class="hljs-string">&quot;&quot;&quot;Returns SplitGenerators.&quot;&quot;&quot;</span>
    prompts_paths = dl_manager.download(_PROMPTS_URLS)
    archive = dl_manager.download(_DATA_URL)
    train_dir = <span class="hljs-string">&quot;vivos/train&quot;</span>
    test_dir = <span class="hljs-string">&quot;vivos/test&quot;</span>

    <span class="hljs-keyword">return</span> [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                <span class="hljs-string">&quot;prompts_path&quot;</span>: prompts_paths[<span class="hljs-string">&quot;train&quot;</span>],
                <span class="hljs-string">&quot;path_to_clips&quot;</span>: train_dir + <span class="hljs-string">&quot;/waves&quot;</span>,
                <span class="hljs-string">&quot;audio_files&quot;</span>: dl_manager.iter_archive(archive),
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                <span class="hljs-string">&quot;prompts_path&quot;</span>: prompts_paths[<span class="hljs-string">&quot;test&quot;</span>],
                <span class="hljs-string">&quot;path_to_clips&quot;</span>: test_dir + <span class="hljs-string">&quot;/waves&quot;</span>,
                <span class="hljs-string">&quot;audio_files&quot;</span>: dl_manager.iter_archive(archive),
            },
        ),
    ]`}}),Ea=new pe({props:{warning:!0,$$slots:{default:[aw]},$$scope:{ctx:I}}}),$t=new se({}),jt=new O({props:{code:`examples = {}
with open(prompts_path, encoding="utf-8") as f:
    for row in f:
        data = row.strip().split(" ", 1)
        speaker_id = data[0].split("_")[0]
        audio_path = "/".join([path_to_clips, speaker_id, data[0] + ".wav"])
        examples[audio_path] = {
            "speaker_id": speaker_id,
            "path": audio_path,
            "sentence": data[1],
        }`,highlighted:`examples = {}
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(prompts_path, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> f:
        data = row.strip().split(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-number">1</span>)
        speaker_id = data[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>]
        audio_path = <span class="hljs-string">&quot;/&quot;</span>.join([path_to_clips, speaker_id, data[<span class="hljs-number">0</span>] + <span class="hljs-string">&quot;.wav&quot;</span>])
        examples[audio_path] = {
            <span class="hljs-string">&quot;speaker_id&quot;</span>: speaker_id,
            <span class="hljs-string">&quot;path&quot;</span>: audio_path,
            <span class="hljs-string">&quot;sentence&quot;</span>: data[<span class="hljs-number">1</span>],
        }`}}),Et=new O({props:{code:`inside_clips_dir = False
id_ = 0
for path, f in audio_files:
    if path.startswith(path_to_clips):
        inside_clips_dir = True
        if path in examples:
            audio = {"path": path, "bytes": f.read()}
            yield id_, {**examples[path], "audio": audio}
            id_ += 1
    elif inside_clips_dir:
        break`,highlighted:`inside_clips_dir = <span class="hljs-literal">False</span>
id_ = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> path, f <span class="hljs-keyword">in</span> audio_files:
    <span class="hljs-keyword">if</span> path.startswith(path_to_clips):
        inside_clips_dir = <span class="hljs-literal">True</span>
        <span class="hljs-keyword">if</span> path <span class="hljs-keyword">in</span> examples:
            audio = {<span class="hljs-string">&quot;path&quot;</span>: path, <span class="hljs-string">&quot;bytes&quot;</span>: f.read()}
            <span class="hljs-keyword">yield</span> id_, {**examples[path], <span class="hljs-string">&quot;audio&quot;</span>: audio}
            id_ += <span class="hljs-number">1</span>
    <span class="hljs-keyword">elif</span> inside_clips_dir:
        <span class="hljs-keyword">break</span>`}}),bt=new O({props:{code:`def _generate_examples(self, prompts_path, path_to_clips, audio_files):
    """Yields examples as (key, example) tuples."""
    examples = {}
    with open(prompts_path, encoding="utf-8") as f:
        for row in f:
            data = row.strip().split(" ", 1)
            speaker_id = data[0].split("_")[0]
            audio_path = "/".join([path_to_clips, speaker_id, data[0] + ".wav"])
            examples[audio_path] = {
                "speaker_id": speaker_id,
                "path": audio_path,
                "sentence": data[1],
            }
    inside_clips_dir = False
    id_ = 0
    for path, f in audio_files:
        if path.startswith(path_to_clips):
            inside_clips_dir = True
            if path in examples:
                audio = {"path": path, "bytes": f.read()}
                yield id_, {**examples[path], "audio": audio}
                id_ += 1
        elif inside_clips_dir:
            break`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, prompts_path, path_to_clips, audio_files</span>):
    <span class="hljs-string">&quot;&quot;&quot;Yields examples as (key, example) tuples.&quot;&quot;&quot;</span>
    examples = {}
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(prompts_path, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> f:
            data = row.strip().split(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-number">1</span>)
            speaker_id = data[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>]
            audio_path = <span class="hljs-string">&quot;/&quot;</span>.join([path_to_clips, speaker_id, data[<span class="hljs-number">0</span>] + <span class="hljs-string">&quot;.wav&quot;</span>])
            examples[audio_path] = {
                <span class="hljs-string">&quot;speaker_id&quot;</span>: speaker_id,
                <span class="hljs-string">&quot;path&quot;</span>: audio_path,
                <span class="hljs-string">&quot;sentence&quot;</span>: data[<span class="hljs-number">1</span>],
            }
    inside_clips_dir = <span class="hljs-literal">False</span>
    id_ = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> path, f <span class="hljs-keyword">in</span> audio_files:
        <span class="hljs-keyword">if</span> path.startswith(path_to_clips):
            inside_clips_dir = <span class="hljs-literal">True</span>
            <span class="hljs-keyword">if</span> path <span class="hljs-keyword">in</span> examples:
                audio = {<span class="hljs-string">&quot;path&quot;</span>: path, <span class="hljs-string">&quot;bytes&quot;</span>: f.read()}
                <span class="hljs-keyword">yield</span> id_, {**examples[path], <span class="hljs-string">&quot;audio&quot;</span>: audio}
                id_ += <span class="hljs-number">1</span>
        <span class="hljs-keyword">elif</span> inside_clips_dir:
            <span class="hljs-keyword">break</span>`}}),kt=new se({}),qt=new O({props:{code:`from datasets import load_dataset
load_dataset("<username>/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)`}}),xt=new se({}),Tt=new se({}),Ct=new O({props:{code:"local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None",highlighted:'local_extracted_archive = dl_manager.extract(audio_path) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> dl_manager.is_streaming <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>'}}),Da=new pe({props:{$$slots:{default:[tw]},$$scope:{ctx:I}}}),Ca=new pe({props:{$$slots:{default:[sw]},$$scope:{ctx:I}}}),Pt=new O({props:{code:`def _split_generators(self, dl_manager):
    """Returns SplitGenerators."""
    dl_manager.download_config.ignore_url_params = True

    audio_path = dl_manager.download(_AUDIO_URL)
    local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None
    path_to_clips = "librivox-indonesia"

    return [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                "local_extracted_archive": local_extracted_archive,
                "audio_files": dl_manager.iter_archive(audio_path),
                "metadata_path": dl_manager.download_and_extract(_METADATA_URL + "/metadata_train.csv.gz"),
                "path_to_clips": path_to_clips,
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                "local_extracted_archive": local_extracted_archive,
                "audio_files": dl_manager.iter_archive(audio_path),
                "metadata_path": dl_manager.download_and_extract(_METADATA_URL + "/metadata_test.csv.gz"),
                "path_to_clips": path_to_clips,
            },
        ),
    ]`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager</span>):
    <span class="hljs-string">&quot;&quot;&quot;Returns SplitGenerators.&quot;&quot;&quot;</span>
    dl_manager.download_config.ignore_url_params = <span class="hljs-literal">True</span>

    audio_path = dl_manager.download(_AUDIO_URL)
    local_extracted_archive = dl_manager.extract(audio_path) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> dl_manager.is_streaming <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>
    path_to_clips = <span class="hljs-string">&quot;librivox-indonesia&quot;</span>

    <span class="hljs-keyword">return</span> [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                <span class="hljs-string">&quot;local_extracted_archive&quot;</span>: local_extracted_archive,
                <span class="hljs-string">&quot;audio_files&quot;</span>: dl_manager.iter_archive(audio_path),
                <span class="hljs-string">&quot;metadata_path&quot;</span>: dl_manager.download_and_extract(_METADATA_URL + <span class="hljs-string">&quot;/metadata_train.csv.gz&quot;</span>),
                <span class="hljs-string">&quot;path_to_clips&quot;</span>: path_to_clips,
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                <span class="hljs-string">&quot;local_extracted_archive&quot;</span>: local_extracted_archive,
                <span class="hljs-string">&quot;audio_files&quot;</span>: dl_manager.iter_archive(audio_path),
                <span class="hljs-string">&quot;metadata_path&quot;</span>: dl_manager.download_and_extract(_METADATA_URL + <span class="hljs-string">&quot;/metadata_test.csv.gz&quot;</span>),
                <span class="hljs-string">&quot;path_to_clips&quot;</span>: path_to_clips,
            },
        ),
    ]`}}),Lt=new se({}),Nt=new O({props:{code:`with open(metadata_path, "r", encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        if self.config.name == "all" or self.config.name == row["language"]:
            row["path"] = os.path.join(path_to_clips, row["path"])
            # if data is incomplete, fill with empty values
            for field in data_fields:
                if field not in row:
                    row[field] = ""
            metadata[row["path"]] = row`,highlighted:`<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(metadata_path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    reader = csv.DictReader(f)
    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:
        <span class="hljs-keyword">if</span> self.config.name == <span class="hljs-string">&quot;all&quot;</span> <span class="hljs-keyword">or</span> self.config.name == row[<span class="hljs-string">&quot;language&quot;</span>]:
            row[<span class="hljs-string">&quot;path&quot;</span>] = os.path.join(path_to_clips, row[<span class="hljs-string">&quot;path&quot;</span>])
            <span class="hljs-comment"># if data is incomplete, fill with empty values</span>
            <span class="hljs-keyword">for</span> field <span class="hljs-keyword">in</span> data_fields:
                <span class="hljs-keyword">if</span> field <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> row:
                    row[field] = <span class="hljs-string">&quot;&quot;</span>
            metadata[row[<span class="hljs-string">&quot;path&quot;</span>]] = row`}}),Gt=new O({props:{code:`for path, f in audio_files:
    if path in metadata:
        result = dict(metadata[path])
        # set the audio feature and the path to the extracted file
        path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path
        result["audio"] = {"path": path, "bytes": f.read()}
        result["path"] = path
        yield id_, result
        id_ += 1`,highlighted:`<span class="hljs-keyword">for</span> path, f <span class="hljs-keyword">in</span> audio_files:
    <span class="hljs-keyword">if</span> path <span class="hljs-keyword">in</span> metadata:
        result = <span class="hljs-built_in">dict</span>(metadata[path])
        <span class="hljs-comment"># set the audio feature and the path to the extracted file</span>
        path = os.path.join(local_extracted_archive, path) <span class="hljs-keyword">if</span> local_extracted_archive <span class="hljs-keyword">else</span> path
        result[<span class="hljs-string">&quot;audio&quot;</span>] = {<span class="hljs-string">&quot;path&quot;</span>: path, <span class="hljs-string">&quot;bytes&quot;</span>: f.read()}
        result[<span class="hljs-string">&quot;path&quot;</span>] = path
        <span class="hljs-keyword">yield</span> id_, result
        id_ += <span class="hljs-number">1</span>`}}),Ft=new O({props:{code:`def _generate_examples(
        self,
        local_extracted_archive,
        audio_files,
        metadata_path,
        path_to_clips,
    ):
        """Yields examples."""
        data_fields = list(self._info().features.keys())
        metadata = {}
        with open(metadata_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if self.config.name == "all" or self.config.name == row["language"]:
                    row["path"] = os.path.join(path_to_clips, row["path"])
                    # if data is incomplete, fill with empty values
                    for field in data_fields:
                        if field not in row:
                            row[field] = ""
                    metadata[row["path"]] = row
        id_ = 0
        for path, f in audio_files:
            if path in metadata:
                result = dict(metadata[path])
                # set the audio feature and the path to the extracted file
                path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path
                result["audio"] = {"path": path, "bytes": f.read()}
                result["path"] = path
                yield id_, result
                id_ += 1`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">
        self,
        local_extracted_archive,
        audio_files,
        metadata_path,
        path_to_clips,
    </span>):
        <span class="hljs-string">&quot;&quot;&quot;Yields examples.&quot;&quot;&quot;</span>
        data_fields = <span class="hljs-built_in">list</span>(self._info().features.keys())
        metadata = {}
        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(metadata_path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
            reader = csv.DictReader(f)
            <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:
                <span class="hljs-keyword">if</span> self.config.name == <span class="hljs-string">&quot;all&quot;</span> <span class="hljs-keyword">or</span> self.config.name == row[<span class="hljs-string">&quot;language&quot;</span>]:
                    row[<span class="hljs-string">&quot;path&quot;</span>] = os.path.join(path_to_clips, row[<span class="hljs-string">&quot;path&quot;</span>])
                    <span class="hljs-comment"># if data is incomplete, fill with empty values</span>
                    <span class="hljs-keyword">for</span> field <span class="hljs-keyword">in</span> data_fields:
                        <span class="hljs-keyword">if</span> field <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> row:
                            row[field] = <span class="hljs-string">&quot;&quot;</span>
                    metadata[row[<span class="hljs-string">&quot;path&quot;</span>]] = row
        id_ = <span class="hljs-number">0</span>
        <span class="hljs-keyword">for</span> path, f <span class="hljs-keyword">in</span> audio_files:
            <span class="hljs-keyword">if</span> path <span class="hljs-keyword">in</span> metadata:
                result = <span class="hljs-built_in">dict</span>(metadata[path])
                <span class="hljs-comment"># set the audio feature and the path to the extracted file</span>
                path = os.path.join(local_extracted_archive, path) <span class="hljs-keyword">if</span> local_extracted_archive <span class="hljs-keyword">else</span> path
                result[<span class="hljs-string">&quot;audio&quot;</span>] = {<span class="hljs-string">&quot;path&quot;</span>: path, <span class="hljs-string">&quot;bytes&quot;</span>: f.read()}
                result[<span class="hljs-string">&quot;path&quot;</span>] = path
                <span class="hljs-keyword">yield</span> id_, result
                id_ += <span class="hljs-number">1</span>`}}),{c(){p=l("meta"),k=h(),u=l("h1"),g=l("a"),b=l("span"),v(_.$$.fragment),m=h(),x=l("span"),A=s("Create an audio dataset"),q=h(),D=l("p"),T=s("You can share a dataset with your team or with anyone in the community by creating a dataset repository on the Hugging Face Hub:"),C=h(),v(U.$$.fragment),G=h(),F=l("p"),za=s("There are several methods for creating and sharing an audio dataset:"),he=h(),X=l("ol"),Ae=l("li"),ee=l("p"),L=s("Create an audio dataset from local files in python with "),Te=l("a"),Yt=s("Dataset.push_to_hub()"),Wt=s(". This is an easy way that requires only a few steps in python."),Kt=h(),Ye=l("li"),fe=l("p"),Ki=s("Create an audio dataset repository with the "),Xs=l("code"),Xi=s("AudioFolder"),Zi=s(" builder. This is a no-code solution for quickly creating small dataset to experiment with."),Ji=h(),Zs=l("li"),Js=l("p"),Qi=s("Create an audio dataset by writing a loading script. This method is for advanced users and requires more effort and coding, but you have greater flexibility over how a dataset is defined, downloaded, and generated."),jr=h(),v(We.$$.fragment),Er=h(),De=l("h2"),Ke=l("a"),Qs=l("span"),v(Na.$$.fragment),ed=h(),eo=l("span"),ad=s("Local files"),br=h(),ue=l("p"),td=s("You can load your own dataset using the paths to your audio files. Use the "),Xt=l("a"),sd=s("cast_column()"),od=s(" function to take a column of audio file paths, and cast it to the "),Zt=l("a"),ld=s("Audio"),rd=s(" feature:"),kr=h(),v(Ua.$$.fragment),qr=h(),Xe=l("p"),nd=s("Then upload the dataset to the Hugging Face Hub using "),Jt=l("a"),id=s("Dataset.push_to_hub()"),dd=s(":"),xr=h(),v(Ga.$$.fragment),Ar=h(),Qt=l("p"),pd=s("This will create a dataset repository containing your audio dataset:"),Tr=h(),v(Fa.$$.fragment),Dr=h(),Ce=l("h2"),Ze=l("a"),ao=l("span"),v(Ha.$$.fragment),hd=h(),to=l("span"),cd=s("AudioFolder"),Cr=h(),Z=l("p"),fd=s("The "),so=l("code"),ud=s("AudioFolder"),_d=s(` is a dataset builder designed to quickly load an audio dataset without requiring you to write any code.
Any additional information about your dataset - such as transcription, speaker accent, or speaker intent - is automatically loaded by `),oo=l("code"),md=s("AudioFolder"),gd=s(" as long as you include this information in a metadata file ("),lo=l("code"),vd=s("metadata.csv"),wd=s("/"),ro=l("code"),yd=s("metadata.jsonl"),$d=s(")."),Or=h(),Je=l("p"),jd=s("Create a dataset repository on the Hugging Face Hub and upload your dataset directory following the "),no=l("code"),Ed=s("AudioFolder"),bd=s(" structure:"),Ir=h(),v(Ba.$$.fragment),Sr=h(),Qe=l("p"),kd=s("The "),io=l("code"),qd=s("data"),xd=s(" folder can be any name you want."),Pr=h(),v(ea.$$.fragment),Lr=h(),aa=l("p"),Ad=s("The metadata file should include a "),po=l("code"),Td=s("file_name"),Dd=s(" column to link an audio file to it\u2019s metadata:"),Rr=h(),v(Ma.$$.fragment),zr=h(),es=l("p"),Cd=s("Then you can store your dataset in a directory structure like this:"),Nr=h(),v(Va.$$.fragment),Ur=h(),oe=l("p"),Od=s("Users can now load your dataset and the associated metadata by specifying "),ho=l("code"),Id=s("audiofolder"),Sd=s(" in "),as=l("a"),Pd=s("load_dataset()"),Ld=s(" and the dataset directory in "),co=l("code"),Rd=s("data_dir"),zd=s(":"),Gr=h(),v(Ya.$$.fragment),Fr=h(),ta=l("p"),Nd=s("You can also use "),fo=l("code"),Ud=s("audiofolder"),Gd=s(" to load datasets involving multiple splits. To do so, your dataset directory might have the following structure:"),Hr=h(),v(Wa.$$.fragment),Br=h(),v(sa.$$.fragment),Mr=h(),oa=l("p"),Fd=s("For audio datasets that don\u2019t have any associated metadata, "),uo=l("code"),Hd=s("AudioFolder"),Bd=s(" automatically infers the class labels of the dataset based on the directory name. It might be useful for audio classification tasks. Your dataset directory might look like:"),Vr=h(),v(Ka.$$.fragment),Yr=h(),_e=l("p"),Md=s("Load the dataset with "),_o=l("code"),Vd=s("AudioFolder"),Yd=s(", and it will create a "),mo=l("code"),Wd=s("label"),Kd=s(" column from the directory name (language id):"),Wr=h(),v(Xa.$$.fragment),Kr=h(),v(la.$$.fragment),Xr=h(),v(ra.$$.fragment),Zr=h(),Oe=l("h2"),na=l("a"),go=l("span"),v(Za.$$.fragment),Xd=h(),vo=l("span"),Zd=s("Loading script"),Jr=h(),ts=l("p"),Jd=s(`Write a dataset loading script to manually create a dataset.
It defines a dataset\u2019s splits and configurations, and handles downloading and generating the dataset examples.
The script should have the same name as your dataset folder or repository:`),Qr=h(),v(Ja.$$.fragment),en=h(),me=l("p"),Qd=s("The "),wo=l("code"),ep=s("data"),ap=s(" folder can be any name you want, it doesn\u2019t have to be "),yo=l("code"),tp=s("data"),sp=s(". This folder is optional, unless you\u2019re hosting your dataset on the Hub."),an=h(),ss=l("p"),op=s("This directory structure allows your dataset to be loaded in one line:"),tn=h(),v(Qa.$$.fragment),sn=h(),ge=l("p"),lp=s("This guide will show you how to create a dataset loading script for audio datasets, which is a bit different from "),et=l("a"),rp=s("creating a loading script for text datasets"),np=s(`.
Audio datasets are commonly stored in `),$o=l("code"),ip=s("tar.gz"),dp=s(" archives which requires a particular approach to support streaming mode. While streaming is not required, we highly encourage enabling streaming support in your audio dataset because:"),on=h(),ia=l("ol"),at=l("li"),pp=s("Users without a lot of disk space can use your dataset without waiting for the entire dataset to be downloaded. Learn more about streaming in the "),os=l("a"),hp=s("Stream"),cp=s(" guide!"),fp=h(),jo=l("li"),up=s("Users can preview a dataset in the dataset viewer."),ln=h(),ls=l("p"),_p=s("Here is an example using TAR archives:"),rn=h(),v(tt.$$.fragment),nn=h(),rs=l("p"),mp=s("In addition to learning how to create a streamable dataset, you\u2019ll also learn how to:"),dn=h(),H=l("ul"),Eo=l("li"),gp=s("Create a dataset builder class."),vp=h(),bo=l("li"),wp=s("Create dataset configurations."),yp=h(),ko=l("li"),$p=s("Add dataset metadata."),jp=h(),qo=l("li"),Ep=s("Download and define the dataset splits."),bp=h(),xo=l("li"),kp=s("Generate the dataset."),qp=h(),Ao=l("li"),xp=s("Upload the dataset to the Hub."),pn=h(),da=l("p"),Ap=s("The best way to learn is to open up an existing audio dataset loading script, like "),st=l("a"),Tp=s("Vivos"),Dp=s(", and follow along!"),hn=h(),v(pa.$$.fragment),cn=h(),v(ha.$$.fragment),fn=h(),Ie=l("h3"),ca=l("a"),To=l("span"),v(ot.$$.fragment),Cp=h(),Do=l("span"),Op=s("Create a dataset builder class"),un=h(),lt=l("p"),ns=l("a"),Ip=s("GeneratorBasedBuilder"),Sp=s(" is the base class for datasets generated from a dictionary generator. Within this class, there are three methods to help create your dataset:"),_n=h(),ve=l("ul"),is=l("li"),Co=l("code"),Pp=s("_info"),Lp=s(" stores information about your dataset like its description, license, and features."),Rp=h(),ds=l("li"),Oo=l("code"),zp=s("_split_generators"),Np=s(" downloads the dataset and defines its splits."),Up=h(),fa=l("li"),Io=l("code"),Gp=s("_generate_examples"),Fp=s(" generates the dataset\u2019s samples containing the audio data and other features specified in "),So=l("code"),Hp=s("info"),Bp=s(" for each split."),mn=h(),ua=l("p"),Mp=s("Start by creating your dataset class as a subclass of "),ps=l("a"),Vp=s("GeneratorBasedBuilder"),Yp=s(" and add the three methods. Don\u2019t worry about filling in each of these methods yet, you\u2019ll develop those over the next few sections:"),gn=h(),v(rt.$$.fragment),vn=h(),Se=l("h4"),_a=l("a"),Po=l("span"),v(nt.$$.fragment),Wp=h(),Lo=l("span"),Kp=s("Multiple configurations"),wn=h(),ma=l("p"),Xp=s("In some cases, a dataset may have more than one configuration. For example, "),it=l("a"),Zp=s("LibriVox Indonesia"),Jp=s(" dataset has several configurations corresponding to different languages."),yn=h(),le=l("p"),Qp=s("To create different configurations, use the "),hs=l("a"),eh=s("BuilderConfig"),ah=s(" class to create a subclass of your dataset. The only required parameter is the "),Ro=l("code"),th=s("name"),sh=s(" of the configuration, which must be passed to the configuration\u2019s superclass "),zo=l("code"),oh=s("__init__()"),lh=s(". Otherwise, you can specify any custom parameters you want in your configuration class."),$n=h(),v(dt.$$.fragment),jn=h(),J=l("p"),rh=s("Define your configurations in the "),No=l("code"),nh=s("BUILDER_CONFIGS"),ih=s(" class variable inside "),cs=l("a"),dh=s("GeneratorBasedBuilder"),ph=s(". In this example, the author imports the languages from a separate "),Uo=l("code"),hh=s("release_stats.py"),ch=h(),pt=l("a"),fh=s("file"),uh=s(" from their repository, and then loops through each language to create a configuration:"),En=h(),v(ht.$$.fragment),bn=h(),v(ga.$$.fragment),kn=h(),va=l("p"),_h=s("Now if users want to load the Balinese ("),Go=l("code"),mh=s("bal"),gh=s(") configuration, they can use the configuration name:"),qn=h(),v(ct.$$.fragment),xn=h(),Pe=l("h3"),wa=l("a"),Fo=l("span"),v(ft.$$.fragment),vh=h(),Ho=l("span"),wh=s("Add dataset metadata"),An=h(),we=l("p"),yh=s("Adding information about your dataset helps users to learn more about it. This information is stored in the "),fs=l("a"),$h=s("DatasetInfo"),jh=s(" class which is returned by the "),Bo=l("code"),Eh=s("info"),bh=s(" method. Users can access this information by:"),Tn=h(),v(ut.$$.fragment),Dn=h(),us=l("p"),kh=s("There is a lot of information you can include about your dataset, but some important ones are:"),Cn=h(),Q=l("ol"),_s=l("li"),Mo=l("code"),qh=s("description"),xh=s(" provides a concise description of the dataset."),Ah=h(),ye=l("li"),Vo=l("code"),Th=s("features"),Dh=s(" specify the dataset column types. Since you\u2019re creating an audio loading script, you\u2019ll need to include the "),ms=l("a"),Ch=s("Audio"),Oh=s(" feature and the "),Yo=l("code"),Ih=s("sampling_rate"),Sh=s(" of the dataset."),Ph=h(),gs=l("li"),Wo=l("code"),Lh=s("homepage"),Rh=s(" provides a link to the dataset homepage."),zh=h(),vs=l("li"),Ko=l("code"),Nh=s("license"),Uh=s(" specify the permissions for using a dataset as defined by the license type."),Gh=h(),ws=l("li"),Xo=l("code"),Fh=s("citation"),Hh=s(" is a BibTeX citation of the dataset."),On=h(),v(ya.$$.fragment),In=h(),v(_t.$$.fragment),Sn=h(),Le=l("h3"),$a=l("a"),Zo=l("span"),v(mt.$$.fragment),Bh=h(),Jo=l("span"),Mh=s("Download and define the dataset splits"),Pn=h(),ys=l("p"),Vh=s("Now that you\u2019ve added some information about your dataset, the next step is to download the dataset and define the splits."),Ln=h(),ja=l("ol"),gt=l("li"),ce=l("p"),Yh=s("Use the "),$s=l("a"),Wh=s("download()"),Kh=s(" method to download metadata file at "),Qo=l("code"),Xh=s("_PROMPTS_URLS"),Zh=s(" and audio TAR archive at "),el=l("code"),Jh=s("_DATA_URL"),Qh=s(". This method returns the path to the local file/archive. In streaming mode, it returns a URL to stream the data from. This method accepts:"),ec=h(),Re=l("ul"),vt=l("li"),ac=s("a relative path to a file inside a Hub dataset repository (for example, in the "),al=l("code"),tc=s("data/"),sc=s(" folder)"),oc=h(),tl=l("li"),lc=s("a URL to a file hosted somewhere else"),rc=h(),sl=l("li"),nc=s("a (nested) list or dictionary of file names or URLs"),ic=h(),wt=l("li"),ae=l("p"),dc=s("After you\u2019ve downloaded the dataset, use the "),js=l("a"),pc=s("SplitGenerator"),hc=s(" to organize the audio files and sentence prompts in each split. Name each split with a standard name like: "),ol=l("code"),cc=s("Split.TRAIN"),fc=s(", "),ll=l("code"),uc=s("Split.TEST"),_c=s(", and "),rl=l("code"),mc=s("SPLIT.Validation"),gc=s("."),vc=h(),W=l("p"),wc=s("In the "),nl=l("code"),yc=s("gen_kwargs"),$c=s(" parameter, specify the file path to the "),il=l("code"),jc=s("prompts_path"),Ec=s(" and "),dl=l("code"),bc=s("path_to_clips"),kc=s(". For "),pl=l("code"),qc=s("audio_files"),xc=s(", you\u2019ll need to use "),Es=l("a"),Ac=s("iter_archive()"),Tc=s(" to iterate over the audio files in the TAR archive. This enables streaming for your dataset. All of these file paths are passed onto the next step where you\u2019ll actually generate the dataset."),Rn=h(),v(yt.$$.fragment),zn=h(),v(Ea.$$.fragment),Nn=h(),ze=l("h3"),ba=l("a"),hl=l("span"),v($t.$$.fragment),Dc=h(),cl=l("span"),Cc=s("Generate the dataset"),Un=h(),R=l("p"),Oc=s("The last method in the "),bs=l("a"),Ic=s("GeneratorBasedBuilder"),Sc=s(" class actually generates the samples in the dataset. It yields a dataset according to the structure specified in "),fl=l("code"),Pc=s("features"),Lc=s(" from the "),ul=l("code"),Rc=s("info"),zc=s(" method. As you can see, "),_l=l("code"),Nc=s("generate_examples"),Uc=s(" accepts the "),ml=l("code"),Gc=s("prompts_path"),Fc=s(", "),gl=l("code"),Hc=s("path_to_clips"),Bc=s(", and "),vl=l("code"),Mc=s("audio_files"),Vc=s(" from the previous method as arguments."),Gn=h(),ks=l("p"),Yc=s("Files inside TAR archives are accessed and yielded sequentially. This means you need to have the metadata associated with the audio files in the TAR file in hand first so you can yield it with its corresponding audio file."),Fn=h(),v(jt.$$.fragment),Hn=h(),z=l("p"),Wc=s("Finally, iterate over files in "),wl=l("code"),Kc=s("audio_files"),Xc=s(" and yield them along with their corresponding metadata. "),qs=l("a"),Zc=s("iter_archive()"),Jc=s(" yields a tuple of ("),yl=l("code"),Qc=s("path"),ef=s(", "),$l=l("code"),af=s("f"),tf=s(") where "),jl=l("code"),sf=s("path"),of=s(" is a "),El=l("strong"),lf=s("relative"),rf=s(" path to a file inside TAR archive and "),bl=l("code"),nf=s("f"),df=s(" is a file object itself."),Bn=h(),v(Et.$$.fragment),Mn=h(),ka=l("p"),pf=s("Put these two steps together, and the whole "),kl=l("code"),hf=s("_generate_examples"),cf=s(" method looks like:"),Vn=h(),v(bt.$$.fragment),Yn=h(),Ne=l("h3"),qa=l("a"),ql=l("span"),v(kt.$$.fragment),ff=h(),xl=l("span"),uf=s("Upload the dataset to the Hub"),Wn=h(),$e=l("p"),_f=s("Once your script is ready, "),xs=l("a"),mf=s("create a dataset card"),gf=s(" and "),As=l("a"),vf=s("upload it to the Hub"),wf=s("."),Kn=h(),Ts=l("p"),yf=s("Congratulations, you can now load your dataset from the Hub! \u{1F973}"),Xn=h(),v(qt.$$.fragment),Zn=h(),Ue=l("h3"),xa=l("a"),Al=l("span"),v(xt.$$.fragment),$f=h(),Tl=l("span"),jf=s("(Advanced) Extract TAR archives locally"),Jn=h(),Aa=l("p"),Ef=s(`In the example above downloaded archives are not extracted and therefore examples do not contain information about where they are stored locally.
To explain how to do the extraction in a way that it also supports streaming, we will briefly go through the `),At=l("a"),bf=s("LibriVox Indonesia"),kf=s(" loading script."),Qn=h(),Ge=l("h4"),Ta=l("a"),Dl=l("span"),v(Tt.$$.fragment),qf=h(),Cl=l("span"),xf=s("Download and define the dataset splits"),ei=h(),je=l("ol"),Ol=l("li"),Fe=l("p"),Af=s("Use the "),Ds=l("a"),Tf=s("download()"),Df=s(" method to download the audio data at "),Il=l("code"),Cf=s("_AUDIO_URL"),Of=s("."),If=h(),Dt=l("li"),He=l("p"),Sf=s("To extract audio TAR archive locally, use the "),Cs=l("a"),Pf=s("extract()"),Lf=s(". You can use this method only in non-streaming mode (when "),Sl=l("code"),Rf=s("dl_manager.is_streaming=False"),zf=s("). This returns a local path to the extracted archive directory:"),Nf=h(),v(Ct.$$.fragment),Uf=h(),Pl=l("li"),K=l("p"),Gf=s("Use the "),Os=l("a"),Ff=s("iter_archive()"),Hf=s(" method to iterate over the archive at "),Ll=l("code"),Bf=s("audio_path"),Mf=s(" after it\u2019s downloaded, just like in the Vivos example above. "),Is=l("a"),Vf=s("iter_archive()"),Yf=s(" doesn\u2019t provide any information about the full paths of files from the archive, even if it has been extracted. As a result, you need to pass the "),Rl=l("code"),Wf=s("local_extracted_archive"),Kf=s(" path to the next step in "),zl=l("code"),Xf=s("gen_kwargs"),Zf=s(", in order to preserve information about where the archive was extracted to. This is required to construct the correct paths to the local files when you generate the examples."),ai=h(),v(Da.$$.fragment),ti=h(),Ot=l("ol"),Be=l("li"),Jf=s("Use the "),Ss=l("a"),Qf=s("download_and_extract()"),eu=s(" method to download the metadata file specified in "),Nl=l("code"),au=s("_METADATA_URL"),tu=s(". This method returns a path to a local file in non-streaming mode. In streaming mode, it opens the file at the URL remotely and returns this URL."),si=h(),v(Ca.$$.fragment),oi=h(),It=l("ol"),St=l("li"),te=l("p"),su=s("Now use the "),Ps=l("a"),ou=s("SplitGenerator"),lu=s(" to organize the audio files and metadata in each split. Name each split with a standard name like: "),Ul=l("code"),ru=s("Split.TRAIN"),nu=s(", "),Gl=l("code"),iu=s("Split.TEST"),du=s(", and "),Fl=l("code"),pu=s("SPLIT.Validation"),hu=s("."),cu=h(),N=l("p"),fu=s("In the "),Hl=l("code"),uu=s("gen_kwargs"),_u=s(" parameter, specify the file paths to "),Bl=l("code"),mu=s("local_extracted_archive"),gu=s(", "),Ml=l("code"),vu=s("audio_files"),wu=s(", "),Vl=l("code"),yu=s("metadata_path"),$u=s(", and "),Yl=l("code"),ju=s("path_to_clips"),Eu=s(". Remember, for "),Wl=l("code"),bu=s("audio_files"),ku=s(", you need to use "),Ls=l("a"),qu=s("iter_archive()"),xu=s(" to iterate over the audio files in the TAR archives. This enables streaming for your dataset! All of these file paths are passed onto the next step where the dataset samples are generated."),li=h(),v(Pt.$$.fragment),ri=h(),Me=l("h4"),Oa=l("a"),Kl=l("span"),v(Lt.$$.fragment),Au=h(),Xl=l("span"),Tu=s("Generate the dataset"),ni=h(),B=l("p"),Du=s("Here "),Zl=l("code"),Cu=s("_generate_examples"),Ou=s(" accepts "),Jl=l("code"),Iu=s("local_extracted_archive"),Su=s(", "),Ql=l("code"),Pu=s("audio_files"),Lu=s(", "),er=l("code"),Ru=s("metadata_path"),zu=s(", and "),ar=l("code"),Nu=s("path_to_clips"),Uu=s(" from the previous method as arguments."),ii=h(),Ia=l("ol"),Rt=l("li"),zt=l("p"),Gu=s("TAR files are accessed and yielded sequentially. This means you need to have the metadata in "),tr=l("code"),Fu=s("metadata_path"),Hu=s(" associated with the audio files in the TAR file in hand first so that you can yield it with its corresponding audio file further:"),Bu=h(),v(Nt.$$.fragment),Mu=h(),Ut=l("li"),S=l("p"),Vu=s("Now you can yield the files in "),sr=l("code"),Yu=s("audio_files"),Wu=s(" archive. When you use "),Rs=l("a"),Ku=s("iter_archive()"),Xu=s(", it yielded a tuple of ("),or=l("code"),Zu=s("path"),Ju=s(", "),lr=l("code"),Qu=s("f"),e_=s(") where "),rr=l("code"),a_=s("path"),t_=s(" is a "),nr=l("strong"),s_=s("relative path"),o_=s(" to a file inside the archive, and "),ir=l("code"),l_=s("f"),r_=s(" is the file object itself. To get the "),dr=l("strong"),n_=s("full path"),i_=s(" to the locally extracted file, join the path of the directory ("),pr=l("code"),d_=s("local_extracted_path"),p_=s(") where the archive is extracted to and the relative audio file path ("),hr=l("code"),h_=s("path"),c_=s("):"),f_=h(),v(Gt.$$.fragment),di=h(),Sa=l("p"),u_=s("Put both of these steps together, and the whole "),cr=l("code"),__=s("_generate_examples"),m_=s(" method should look like:"),pi=h(),v(Ft.$$.fragment),this.h()},l(e){const i=Bv('[data-svelte="svelte-1phssyn"]',document.head);p=r(i,"META",{name:!0,content:!0}),i.forEach(t),k=c(e),u=r(e,"H1",{class:!0});var Ht=n(u);g=r(Ht,"A",{id:!0,class:!0,href:!0});var fr=n(g);b=r(fr,"SPAN",{});var ur=n(b);w(_.$$.fragment,ur),ur.forEach(t),fr.forEach(t),m=c(Ht),x=r(Ht,"SPAN",{});var _r=n(x);A=o(_r,"Create an audio dataset"),_r.forEach(t),Ht.forEach(t),q=c(e),D=r(e,"P",{});var mr=n(D);T=o(mr,"You can share a dataset with your team or with anyone in the community by creating a dataset repository on the Hugging Face Hub:"),mr.forEach(t),C=c(e),w(U.$$.fragment,e),G=c(e),F=r(e,"P",{});var gr=n(F);za=o(gr,"There are several methods for creating and sharing an audio dataset:"),gr.forEach(t),he=c(e),X=r(e,"OL",{});var Ve=n(X);Ae=r(Ve,"LI",{});var vr=n(Ae);ee=r(vr,"P",{});var Bt=n(ee);L=o(Bt,"Create an audio dataset from local files in python with "),Te=r(Bt,"A",{href:!0});var wr=n(Te);Yt=o(wr,"Dataset.push_to_hub()"),wr.forEach(t),Wt=o(Bt,". This is an easy way that requires only a few steps in python."),Bt.forEach(t),vr.forEach(t),Kt=c(Ve),Ye=r(Ve,"LI",{});var yr=n(Ye);fe=r(yr,"P",{});var Mt=n(fe);Ki=o(Mt,"Create an audio dataset repository with the "),Xs=r(Mt,"CODE",{});var b_=n(Xs);Xi=o(b_,"AudioFolder"),b_.forEach(t),Zi=o(Mt," builder. This is a no-code solution for quickly creating small dataset to experiment with."),Mt.forEach(t),yr.forEach(t),Ji=c(Ve),Zs=r(Ve,"LI",{});var k_=n(Zs);Js=r(k_,"P",{});var q_=n(Js);Qi=o(q_,"Create an audio dataset by writing a loading script. This method is for advanced users and requires more effort and coding, but you have greater flexibility over how a dataset is defined, downloaded, and generated."),q_.forEach(t),k_.forEach(t),Ve.forEach(t),jr=c(e),w(We.$$.fragment,e),Er=c(e),De=r(e,"H2",{class:!0});var ci=n(De);Ke=r(ci,"A",{id:!0,class:!0,href:!0});var x_=n(Ke);Qs=r(x_,"SPAN",{});var A_=n(Qs);w(Na.$$.fragment,A_),A_.forEach(t),x_.forEach(t),ed=c(ci),eo=r(ci,"SPAN",{});var T_=n(eo);ad=o(T_,"Local files"),T_.forEach(t),ci.forEach(t),br=c(e),ue=r(e,"P",{});var zs=n(ue);td=o(zs,"You can load your own dataset using the paths to your audio files. Use the "),Xt=r(zs,"A",{href:!0});var D_=n(Xt);sd=o(D_,"cast_column()"),D_.forEach(t),od=o(zs," function to take a column of audio file paths, and cast it to the "),Zt=r(zs,"A",{href:!0});var C_=n(Zt);ld=o(C_,"Audio"),C_.forEach(t),rd=o(zs," feature:"),zs.forEach(t),kr=c(e),w(Ua.$$.fragment,e),qr=c(e),Xe=r(e,"P",{});var fi=n(Xe);nd=o(fi,"Then upload the dataset to the Hugging Face Hub using "),Jt=r(fi,"A",{href:!0});var O_=n(Jt);id=o(O_,"Dataset.push_to_hub()"),O_.forEach(t),dd=o(fi,":"),fi.forEach(t),xr=c(e),w(Ga.$$.fragment,e),Ar=c(e),Qt=r(e,"P",{});var I_=n(Qt);pd=o(I_,"This will create a dataset repository containing your audio dataset:"),I_.forEach(t),Tr=c(e),w(Fa.$$.fragment,e),Dr=c(e),Ce=r(e,"H2",{class:!0});var ui=n(Ce);Ze=r(ui,"A",{id:!0,class:!0,href:!0});var S_=n(Ze);ao=r(S_,"SPAN",{});var P_=n(ao);w(Ha.$$.fragment,P_),P_.forEach(t),S_.forEach(t),hd=c(ui),to=r(ui,"SPAN",{});var L_=n(to);cd=o(L_,"AudioFolder"),L_.forEach(t),ui.forEach(t),Cr=c(e),Z=r(e,"P",{});var Ee=n(Z);fd=o(Ee,"The "),so=r(Ee,"CODE",{});var R_=n(so);ud=o(R_,"AudioFolder"),R_.forEach(t),_d=o(Ee,` is a dataset builder designed to quickly load an audio dataset without requiring you to write any code.
Any additional information about your dataset - such as transcription, speaker accent, or speaker intent - is automatically loaded by `),oo=r(Ee,"CODE",{});var z_=n(oo);md=o(z_,"AudioFolder"),z_.forEach(t),gd=o(Ee," as long as you include this information in a metadata file ("),lo=r(Ee,"CODE",{});var N_=n(lo);vd=o(N_,"metadata.csv"),N_.forEach(t),wd=o(Ee,"/"),ro=r(Ee,"CODE",{});var U_=n(ro);yd=o(U_,"metadata.jsonl"),U_.forEach(t),$d=o(Ee,")."),Ee.forEach(t),Or=c(e),Je=r(e,"P",{});var _i=n(Je);jd=o(_i,"Create a dataset repository on the Hugging Face Hub and upload your dataset directory following the "),no=r(_i,"CODE",{});var G_=n(no);Ed=o(G_,"AudioFolder"),G_.forEach(t),bd=o(_i," structure:"),_i.forEach(t),Ir=c(e),w(Ba.$$.fragment,e),Sr=c(e),Qe=r(e,"P",{});var mi=n(Qe);kd=o(mi,"The "),io=r(mi,"CODE",{});var F_=n(io);qd=o(F_,"data"),F_.forEach(t),xd=o(mi," folder can be any name you want."),mi.forEach(t),Pr=c(e),w(ea.$$.fragment,e),Lr=c(e),aa=r(e,"P",{});var gi=n(aa);Ad=o(gi,"The metadata file should include a "),po=r(gi,"CODE",{});var H_=n(po);Td=o(H_,"file_name"),H_.forEach(t),Dd=o(gi," column to link an audio file to it\u2019s metadata:"),gi.forEach(t),Rr=c(e),w(Ma.$$.fragment,e),zr=c(e),es=r(e,"P",{});var B_=n(es);Cd=o(B_,"Then you can store your dataset in a directory structure like this:"),B_.forEach(t),Nr=c(e),w(Va.$$.fragment,e),Ur=c(e),oe=r(e,"P",{});var Pa=n(oe);Od=o(Pa,"Users can now load your dataset and the associated metadata by specifying "),ho=r(Pa,"CODE",{});var M_=n(ho);Id=o(M_,"audiofolder"),M_.forEach(t),Sd=o(Pa," in "),as=r(Pa,"A",{href:!0});var V_=n(as);Pd=o(V_,"load_dataset()"),V_.forEach(t),Ld=o(Pa," and the dataset directory in "),co=r(Pa,"CODE",{});var Y_=n(co);Rd=o(Y_,"data_dir"),Y_.forEach(t),zd=o(Pa,":"),Pa.forEach(t),Gr=c(e),w(Ya.$$.fragment,e),Fr=c(e),ta=r(e,"P",{});var vi=n(ta);Nd=o(vi,"You can also use "),fo=r(vi,"CODE",{});var W_=n(fo);Ud=o(W_,"audiofolder"),W_.forEach(t),Gd=o(vi," to load datasets involving multiple splits. To do so, your dataset directory might have the following structure:"),vi.forEach(t),Hr=c(e),w(Wa.$$.fragment,e),Br=c(e),w(sa.$$.fragment,e),Mr=c(e),oa=r(e,"P",{});var wi=n(oa);Fd=o(wi,"For audio datasets that don\u2019t have any associated metadata, "),uo=r(wi,"CODE",{});var K_=n(uo);Hd=o(K_,"AudioFolder"),K_.forEach(t),Bd=o(wi," automatically infers the class labels of the dataset based on the directory name. It might be useful for audio classification tasks. Your dataset directory might look like:"),wi.forEach(t),Vr=c(e),w(Ka.$$.fragment,e),Yr=c(e),_e=r(e,"P",{});var Ns=n(_e);Md=o(Ns,"Load the dataset with "),_o=r(Ns,"CODE",{});var X_=n(_o);Vd=o(X_,"AudioFolder"),X_.forEach(t),Yd=o(Ns,", and it will create a "),mo=r(Ns,"CODE",{});var Z_=n(mo);Wd=o(Z_,"label"),Z_.forEach(t),Kd=o(Ns," column from the directory name (language id):"),Ns.forEach(t),Wr=c(e),w(Xa.$$.fragment,e),Kr=c(e),w(la.$$.fragment,e),Xr=c(e),w(ra.$$.fragment,e),Zr=c(e),Oe=r(e,"H2",{class:!0});var yi=n(Oe);na=r(yi,"A",{id:!0,class:!0,href:!0});var J_=n(na);go=r(J_,"SPAN",{});var Q_=n(go);w(Za.$$.fragment,Q_),Q_.forEach(t),J_.forEach(t),Xd=c(yi),vo=r(yi,"SPAN",{});var em=n(vo);Zd=o(em,"Loading script"),em.forEach(t),yi.forEach(t),Jr=c(e),ts=r(e,"P",{});var am=n(ts);Jd=o(am,`Write a dataset loading script to manually create a dataset.
It defines a dataset\u2019s splits and configurations, and handles downloading and generating the dataset examples.
The script should have the same name as your dataset folder or repository:`),am.forEach(t),Qr=c(e),w(Ja.$$.fragment,e),en=c(e),me=r(e,"P",{});var Us=n(me);Qd=o(Us,"The "),wo=r(Us,"CODE",{});var tm=n(wo);ep=o(tm,"data"),tm.forEach(t),ap=o(Us," folder can be any name you want, it doesn\u2019t have to be "),yo=r(Us,"CODE",{});var sm=n(yo);tp=o(sm,"data"),sm.forEach(t),sp=o(Us,". This folder is optional, unless you\u2019re hosting your dataset on the Hub."),Us.forEach(t),an=c(e),ss=r(e,"P",{});var om=n(ss);op=o(om,"This directory structure allows your dataset to be loaded in one line:"),om.forEach(t),tn=c(e),w(Qa.$$.fragment,e),sn=c(e),ge=r(e,"P",{});var Gs=n(ge);lp=o(Gs,"This guide will show you how to create a dataset loading script for audio datasets, which is a bit different from "),et=r(Gs,"A",{class:!0,href:!0});var lm=n(et);rp=o(lm,"creating a loading script for text datasets"),lm.forEach(t),np=o(Gs,`.
Audio datasets are commonly stored in `),$o=r(Gs,"CODE",{});var rm=n($o);ip=o(rm,"tar.gz"),rm.forEach(t),dp=o(Gs," archives which requires a particular approach to support streaming mode. While streaming is not required, we highly encourage enabling streaming support in your audio dataset because:"),Gs.forEach(t),on=c(e),ia=r(e,"OL",{});var $i=n(ia);at=r($i,"LI",{});var ji=n(at);pp=o(ji,"Users without a lot of disk space can use your dataset without waiting for the entire dataset to be downloaded. Learn more about streaming in the "),os=r(ji,"A",{href:!0});var nm=n(os);hp=o(nm,"Stream"),nm.forEach(t),cp=o(ji," guide!"),ji.forEach(t),fp=c($i),jo=r($i,"LI",{});var im=n(jo);up=o(im,"Users can preview a dataset in the dataset viewer."),im.forEach(t),$i.forEach(t),ln=c(e),ls=r(e,"P",{});var dm=n(ls);_p=o(dm,"Here is an example using TAR archives:"),dm.forEach(t),rn=c(e),w(tt.$$.fragment,e),nn=c(e),rs=r(e,"P",{});var pm=n(rs);mp=o(pm,"In addition to learning how to create a streamable dataset, you\u2019ll also learn how to:"),pm.forEach(t),dn=c(e),H=r(e,"UL",{});var re=n(H);Eo=r(re,"LI",{});var hm=n(Eo);gp=o(hm,"Create a dataset builder class."),hm.forEach(t),vp=c(re),bo=r(re,"LI",{});var cm=n(bo);wp=o(cm,"Create dataset configurations."),cm.forEach(t),yp=c(re),ko=r(re,"LI",{});var fm=n(ko);$p=o(fm,"Add dataset metadata."),fm.forEach(t),jp=c(re),qo=r(re,"LI",{});var um=n(qo);Ep=o(um,"Download and define the dataset splits."),um.forEach(t),bp=c(re),xo=r(re,"LI",{});var _m=n(xo);kp=o(_m,"Generate the dataset."),_m.forEach(t),qp=c(re),Ao=r(re,"LI",{});var mm=n(Ao);xp=o(mm,"Upload the dataset to the Hub."),mm.forEach(t),re.forEach(t),pn=c(e),da=r(e,"P",{});var Ei=n(da);Ap=o(Ei,"The best way to learn is to open up an existing audio dataset loading script, like "),st=r(Ei,"A",{href:!0,rel:!0});var gm=n(st);Tp=o(gm,"Vivos"),gm.forEach(t),Dp=o(Ei,", and follow along!"),Ei.forEach(t),hn=c(e),w(pa.$$.fragment,e),cn=c(e),w(ha.$$.fragment,e),fn=c(e),Ie=r(e,"H3",{class:!0});var bi=n(Ie);ca=r(bi,"A",{id:!0,class:!0,href:!0});var vm=n(ca);To=r(vm,"SPAN",{});var wm=n(To);w(ot.$$.fragment,wm),wm.forEach(t),vm.forEach(t),Cp=c(bi),Do=r(bi,"SPAN",{});var ym=n(Do);Op=o(ym,"Create a dataset builder class"),ym.forEach(t),bi.forEach(t),un=c(e),lt=r(e,"P",{});var g_=n(lt);ns=r(g_,"A",{href:!0});var $m=n(ns);Ip=o($m,"GeneratorBasedBuilder"),$m.forEach(t),Sp=o(g_," is the base class for datasets generated from a dictionary generator. Within this class, there are three methods to help create your dataset:"),g_.forEach(t),_n=c(e),ve=r(e,"UL",{});var Fs=n(ve);is=r(Fs,"LI",{});var v_=n(is);Co=r(v_,"CODE",{});var jm=n(Co);Pp=o(jm,"_info"),jm.forEach(t),Lp=o(v_," stores information about your dataset like its description, license, and features."),v_.forEach(t),Rp=c(Fs),ds=r(Fs,"LI",{});var w_=n(ds);Oo=r(w_,"CODE",{});var Em=n(Oo);zp=o(Em,"_split_generators"),Em.forEach(t),Np=o(w_," downloads the dataset and defines its splits."),w_.forEach(t),Up=c(Fs),fa=r(Fs,"LI",{});var $r=n(fa);Io=r($r,"CODE",{});var bm=n(Io);Gp=o(bm,"_generate_examples"),bm.forEach(t),Fp=o($r," generates the dataset\u2019s samples containing the audio data and other features specified in "),So=r($r,"CODE",{});var km=n(So);Hp=o(km,"info"),km.forEach(t),Bp=o($r," for each split."),$r.forEach(t),Fs.forEach(t),mn=c(e),ua=r(e,"P",{});var ki=n(ua);Mp=o(ki,"Start by creating your dataset class as a subclass of "),ps=r(ki,"A",{href:!0});var qm=n(ps);Vp=o(qm,"GeneratorBasedBuilder"),qm.forEach(t),Yp=o(ki," and add the three methods. Don\u2019t worry about filling in each of these methods yet, you\u2019ll develop those over the next few sections:"),ki.forEach(t),gn=c(e),w(rt.$$.fragment,e),vn=c(e),Se=r(e,"H4",{class:!0});var qi=n(Se);_a=r(qi,"A",{id:!0,class:!0,href:!0});var xm=n(_a);Po=r(xm,"SPAN",{});var Am=n(Po);w(nt.$$.fragment,Am),Am.forEach(t),xm.forEach(t),Wp=c(qi),Lo=r(qi,"SPAN",{});var Tm=n(Lo);Kp=o(Tm,"Multiple configurations"),Tm.forEach(t),qi.forEach(t),wn=c(e),ma=r(e,"P",{});var xi=n(ma);Xp=o(xi,"In some cases, a dataset may have more than one configuration. For example, "),it=r(xi,"A",{href:!0,rel:!0});var Dm=n(it);Zp=o(Dm,"LibriVox Indonesia"),Dm.forEach(t),Jp=o(xi," dataset has several configurations corresponding to different languages."),xi.forEach(t),yn=c(e),le=r(e,"P",{});var La=n(le);Qp=o(La,"To create different configurations, use the "),hs=r(La,"A",{href:!0});var Cm=n(hs);eh=o(Cm,"BuilderConfig"),Cm.forEach(t),ah=o(La," class to create a subclass of your dataset. The only required parameter is the "),Ro=r(La,"CODE",{});var Om=n(Ro);th=o(Om,"name"),Om.forEach(t),sh=o(La," of the configuration, which must be passed to the configuration\u2019s superclass "),zo=r(La,"CODE",{});var Im=n(zo);oh=o(Im,"__init__()"),Im.forEach(t),lh=o(La,". Otherwise, you can specify any custom parameters you want in your configuration class."),La.forEach(t),$n=c(e),w(dt.$$.fragment,e),jn=c(e),J=r(e,"P",{});var be=n(J);rh=o(be,"Define your configurations in the "),No=r(be,"CODE",{});var Sm=n(No);nh=o(Sm,"BUILDER_CONFIGS"),Sm.forEach(t),ih=o(be," class variable inside "),cs=r(be,"A",{href:!0});var Pm=n(cs);dh=o(Pm,"GeneratorBasedBuilder"),Pm.forEach(t),ph=o(be,". In this example, the author imports the languages from a separate "),Uo=r(be,"CODE",{});var Lm=n(Uo);hh=o(Lm,"release_stats.py"),Lm.forEach(t),ch=c(be),pt=r(be,"A",{href:!0,rel:!0});var Rm=n(pt);fh=o(Rm,"file"),Rm.forEach(t),uh=o(be," from their repository, and then loops through each language to create a configuration:"),be.forEach(t),En=c(e),w(ht.$$.fragment,e),bn=c(e),w(ga.$$.fragment,e),kn=c(e),va=r(e,"P",{});var Ai=n(va);_h=o(Ai,"Now if users want to load the Balinese ("),Go=r(Ai,"CODE",{});var zm=n(Go);mh=o(zm,"bal"),zm.forEach(t),gh=o(Ai,") configuration, they can use the configuration name:"),Ai.forEach(t),qn=c(e),w(ct.$$.fragment,e),xn=c(e),Pe=r(e,"H3",{class:!0});var Ti=n(Pe);wa=r(Ti,"A",{id:!0,class:!0,href:!0});var Nm=n(wa);Fo=r(Nm,"SPAN",{});var Um=n(Fo);w(ft.$$.fragment,Um),Um.forEach(t),Nm.forEach(t),vh=c(Ti),Ho=r(Ti,"SPAN",{});var Gm=n(Ho);wh=o(Gm,"Add dataset metadata"),Gm.forEach(t),Ti.forEach(t),An=c(e),we=r(e,"P",{});var Hs=n(we);yh=o(Hs,"Adding information about your dataset helps users to learn more about it. This information is stored in the "),fs=r(Hs,"A",{href:!0});var Fm=n(fs);$h=o(Fm,"DatasetInfo"),Fm.forEach(t),jh=o(Hs," class which is returned by the "),Bo=r(Hs,"CODE",{});var Hm=n(Bo);Eh=o(Hm,"info"),Hm.forEach(t),bh=o(Hs," method. Users can access this information by:"),Hs.forEach(t),Tn=c(e),w(ut.$$.fragment,e),Dn=c(e),us=r(e,"P",{});var Bm=n(us);kh=o(Bm,"There is a lot of information you can include about your dataset, but some important ones are:"),Bm.forEach(t),Cn=c(e),Q=r(e,"OL",{});var ke=n(Q);_s=r(ke,"LI",{});var y_=n(_s);Mo=r(y_,"CODE",{});var Mm=n(Mo);qh=o(Mm,"description"),Mm.forEach(t),xh=o(y_," provides a concise description of the dataset."),y_.forEach(t),Ah=c(ke),ye=r(ke,"LI",{});var Vt=n(ye);Vo=r(Vt,"CODE",{});var Vm=n(Vo);Th=o(Vm,"features"),Vm.forEach(t),Dh=o(Vt," specify the dataset column types. Since you\u2019re creating an audio loading script, you\u2019ll need to include the "),ms=r(Vt,"A",{href:!0});var Ym=n(ms);Ch=o(Ym,"Audio"),Ym.forEach(t),Oh=o(Vt," feature and the "),Yo=r(Vt,"CODE",{});var Wm=n(Yo);Ih=o(Wm,"sampling_rate"),Wm.forEach(t),Sh=o(Vt," of the dataset."),Vt.forEach(t),Ph=c(ke),gs=r(ke,"LI",{});var $_=n(gs);Wo=r($_,"CODE",{});var Km=n(Wo);Lh=o(Km,"homepage"),Km.forEach(t),Rh=o($_," provides a link to the dataset homepage."),$_.forEach(t),zh=c(ke),vs=r(ke,"LI",{});var j_=n(vs);Ko=r(j_,"CODE",{});var Xm=n(Ko);Nh=o(Xm,"license"),Xm.forEach(t),Uh=o(j_," specify the permissions for using a dataset as defined by the license type."),j_.forEach(t),Gh=c(ke),ws=r(ke,"LI",{});var E_=n(ws);Xo=r(E_,"CODE",{});var Zm=n(Xo);Fh=o(Zm,"citation"),Zm.forEach(t),Hh=o(E_," is a BibTeX citation of the dataset."),E_.forEach(t),ke.forEach(t),On=c(e),w(ya.$$.fragment,e),In=c(e),w(_t.$$.fragment,e),Sn=c(e),Le=r(e,"H3",{class:!0});var Di=n(Le);$a=r(Di,"A",{id:!0,class:!0,href:!0});var Jm=n($a);Zo=r(Jm,"SPAN",{});var Qm=n(Zo);w(mt.$$.fragment,Qm),Qm.forEach(t),Jm.forEach(t),Bh=c(Di),Jo=r(Di,"SPAN",{});var eg=n(Jo);Mh=o(eg,"Download and define the dataset splits"),eg.forEach(t),Di.forEach(t),Pn=c(e),ys=r(e,"P",{});var ag=n(ys);Vh=o(ag,"Now that you\u2019ve added some information about your dataset, the next step is to download the dataset and define the splits."),ag.forEach(t),Ln=c(e),ja=r(e,"OL",{});var Ci=n(ja);gt=r(Ci,"LI",{});var Oi=n(gt);ce=r(Oi,"P",{});var Ra=n(ce);Yh=o(Ra,"Use the "),$s=r(Ra,"A",{href:!0});var tg=n($s);Wh=o(tg,"download()"),tg.forEach(t),Kh=o(Ra," method to download metadata file at "),Qo=r(Ra,"CODE",{});var sg=n(Qo);Xh=o(sg,"_PROMPTS_URLS"),sg.forEach(t),Zh=o(Ra," and audio TAR archive at "),el=r(Ra,"CODE",{});var og=n(el);Jh=o(og,"_DATA_URL"),og.forEach(t),Qh=o(Ra,". This method returns the path to the local file/archive. In streaming mode, it returns a URL to stream the data from. This method accepts:"),Ra.forEach(t),ec=c(Oi),Re=r(Oi,"UL",{});var Bs=n(Re);vt=r(Bs,"LI",{});var Ii=n(vt);ac=o(Ii,"a relative path to a file inside a Hub dataset repository (for example, in the "),al=r(Ii,"CODE",{});var lg=n(al);tc=o(lg,"data/"),lg.forEach(t),sc=o(Ii," folder)"),Ii.forEach(t),oc=c(Bs),tl=r(Bs,"LI",{});var rg=n(tl);lc=o(rg,"a URL to a file hosted somewhere else"),rg.forEach(t),rc=c(Bs),sl=r(Bs,"LI",{});var ng=n(sl);nc=o(ng,"a (nested) list or dictionary of file names or URLs"),ng.forEach(t),Bs.forEach(t),Oi.forEach(t),ic=c(Ci),wt=r(Ci,"LI",{});var Si=n(wt);ae=r(Si,"P",{});var qe=n(ae);dc=o(qe,"After you\u2019ve downloaded the dataset, use the "),js=r(qe,"A",{href:!0});var ig=n(js);pc=o(ig,"SplitGenerator"),ig.forEach(t),hc=o(qe," to organize the audio files and sentence prompts in each split. Name each split with a standard name like: "),ol=r(qe,"CODE",{});var dg=n(ol);cc=o(dg,"Split.TRAIN"),dg.forEach(t),fc=o(qe,", "),ll=r(qe,"CODE",{});var pg=n(ll);uc=o(pg,"Split.TEST"),pg.forEach(t),_c=o(qe,", and "),rl=r(qe,"CODE",{});var hg=n(rl);mc=o(hg,"SPLIT.Validation"),hg.forEach(t),gc=o(qe,"."),qe.forEach(t),vc=c(Si),W=r(Si,"P",{});var ne=n(W);wc=o(ne,"In the "),nl=r(ne,"CODE",{});var cg=n(nl);yc=o(cg,"gen_kwargs"),cg.forEach(t),$c=o(ne," parameter, specify the file path to the "),il=r(ne,"CODE",{});var fg=n(il);jc=o(fg,"prompts_path"),fg.forEach(t),Ec=o(ne," and "),dl=r(ne,"CODE",{});var ug=n(dl);bc=o(ug,"path_to_clips"),ug.forEach(t),kc=o(ne,". For "),pl=r(ne,"CODE",{});var _g=n(pl);qc=o(_g,"audio_files"),_g.forEach(t),xc=o(ne,", you\u2019ll need to use "),Es=r(ne,"A",{href:!0});var mg=n(Es);Ac=o(mg,"iter_archive()"),mg.forEach(t),Tc=o(ne," to iterate over the audio files in the TAR archive. This enables streaming for your dataset. All of these file paths are passed onto the next step where you\u2019ll actually generate the dataset."),ne.forEach(t),Si.forEach(t),Ci.forEach(t),Rn=c(e),w(yt.$$.fragment,e),zn=c(e),w(Ea.$$.fragment,e),Nn=c(e),ze=r(e,"H3",{class:!0});var Pi=n(ze);ba=r(Pi,"A",{id:!0,class:!0,href:!0});var gg=n(ba);hl=r(gg,"SPAN",{});var vg=n(hl);w($t.$$.fragment,vg),vg.forEach(t),gg.forEach(t),Dc=c(Pi),cl=r(Pi,"SPAN",{});var wg=n(cl);Cc=o(wg,"Generate the dataset"),wg.forEach(t),Pi.forEach(t),Un=c(e),R=r(e,"P",{});var M=n(R);Oc=o(M,"The last method in the "),bs=r(M,"A",{href:!0});var yg=n(bs);Ic=o(yg,"GeneratorBasedBuilder"),yg.forEach(t),Sc=o(M," class actually generates the samples in the dataset. It yields a dataset according to the structure specified in "),fl=r(M,"CODE",{});var $g=n(fl);Pc=o($g,"features"),$g.forEach(t),Lc=o(M," from the "),ul=r(M,"CODE",{});var jg=n(ul);Rc=o(jg,"info"),jg.forEach(t),zc=o(M," method. As you can see, "),_l=r(M,"CODE",{});var Eg=n(_l);Nc=o(Eg,"generate_examples"),Eg.forEach(t),Uc=o(M," accepts the "),ml=r(M,"CODE",{});var bg=n(ml);Gc=o(bg,"prompts_path"),bg.forEach(t),Fc=o(M,", "),gl=r(M,"CODE",{});var kg=n(gl);Hc=o(kg,"path_to_clips"),kg.forEach(t),Bc=o(M,", and "),vl=r(M,"CODE",{});var qg=n(vl);Mc=o(qg,"audio_files"),qg.forEach(t),Vc=o(M," from the previous method as arguments."),M.forEach(t),Gn=c(e),ks=r(e,"P",{});var xg=n(ks);Yc=o(xg,"Files inside TAR archives are accessed and yielded sequentially. This means you need to have the metadata associated with the audio files in the TAR file in hand first so you can yield it with its corresponding audio file."),xg.forEach(t),Fn=c(e),w(jt.$$.fragment,e),Hn=c(e),z=r(e,"P",{});var V=n(z);Wc=o(V,"Finally, iterate over files in "),wl=r(V,"CODE",{});var Ag=n(wl);Kc=o(Ag,"audio_files"),Ag.forEach(t),Xc=o(V," and yield them along with their corresponding metadata. "),qs=r(V,"A",{href:!0});var Tg=n(qs);Zc=o(Tg,"iter_archive()"),Tg.forEach(t),Jc=o(V," yields a tuple of ("),yl=r(V,"CODE",{});var Dg=n(yl);Qc=o(Dg,"path"),Dg.forEach(t),ef=o(V,", "),$l=r(V,"CODE",{});var Cg=n($l);af=o(Cg,"f"),Cg.forEach(t),tf=o(V,") where "),jl=r(V,"CODE",{});var Og=n(jl);sf=o(Og,"path"),Og.forEach(t),of=o(V," is a "),El=r(V,"STRONG",{});var Ig=n(El);lf=o(Ig,"relative"),Ig.forEach(t),rf=o(V," path to a file inside TAR archive and "),bl=r(V,"CODE",{});var Sg=n(bl);nf=o(Sg,"f"),Sg.forEach(t),df=o(V," is a file object itself."),V.forEach(t),Bn=c(e),w(Et.$$.fragment,e),Mn=c(e),ka=r(e,"P",{});var Li=n(ka);pf=o(Li,"Put these two steps together, and the whole "),kl=r(Li,"CODE",{});var Pg=n(kl);hf=o(Pg,"_generate_examples"),Pg.forEach(t),cf=o(Li," method looks like:"),Li.forEach(t),Vn=c(e),w(bt.$$.fragment,e),Yn=c(e),Ne=r(e,"H3",{class:!0});var Ri=n(Ne);qa=r(Ri,"A",{id:!0,class:!0,href:!0});var Lg=n(qa);ql=r(Lg,"SPAN",{});var Rg=n(ql);w(kt.$$.fragment,Rg),Rg.forEach(t),Lg.forEach(t),ff=c(Ri),xl=r(Ri,"SPAN",{});var zg=n(xl);uf=o(zg,"Upload the dataset to the Hub"),zg.forEach(t),Ri.forEach(t),Wn=c(e),$e=r(e,"P",{});var Ms=n($e);_f=o(Ms,"Once your script is ready, "),xs=r(Ms,"A",{href:!0});var Ng=n(xs);mf=o(Ng,"create a dataset card"),Ng.forEach(t),gf=o(Ms," and "),As=r(Ms,"A",{href:!0});var Ug=n(As);vf=o(Ug,"upload it to the Hub"),Ug.forEach(t),wf=o(Ms,"."),Ms.forEach(t),Kn=c(e),Ts=r(e,"P",{});var Gg=n(Ts);yf=o(Gg,"Congratulations, you can now load your dataset from the Hub! \u{1F973}"),Gg.forEach(t),Xn=c(e),w(qt.$$.fragment,e),Zn=c(e),Ue=r(e,"H3",{class:!0});var zi=n(Ue);xa=r(zi,"A",{id:!0,class:!0,href:!0});var Fg=n(xa);Al=r(Fg,"SPAN",{});var Hg=n(Al);w(xt.$$.fragment,Hg),Hg.forEach(t),Fg.forEach(t),$f=c(zi),Tl=r(zi,"SPAN",{});var Bg=n(Tl);jf=o(Bg,"(Advanced) Extract TAR archives locally"),Bg.forEach(t),zi.forEach(t),Jn=c(e),Aa=r(e,"P",{});var Ni=n(Aa);Ef=o(Ni,`In the example above downloaded archives are not extracted and therefore examples do not contain information about where they are stored locally.
To explain how to do the extraction in a way that it also supports streaming, we will briefly go through the `),At=r(Ni,"A",{href:!0,rel:!0});var Mg=n(At);bf=o(Mg,"LibriVox Indonesia"),Mg.forEach(t),kf=o(Ni," loading script."),Ni.forEach(t),Qn=c(e),Ge=r(e,"H4",{class:!0});var Ui=n(Ge);Ta=r(Ui,"A",{id:!0,class:!0,href:!0});var Vg=n(Ta);Dl=r(Vg,"SPAN",{});var Yg=n(Dl);w(Tt.$$.fragment,Yg),Yg.forEach(t),Vg.forEach(t),qf=c(Ui),Cl=r(Ui,"SPAN",{});var Wg=n(Cl);xf=o(Wg,"Download and define the dataset splits"),Wg.forEach(t),Ui.forEach(t),ei=c(e),je=r(e,"OL",{});var Vs=n(je);Ol=r(Vs,"LI",{});var Kg=n(Ol);Fe=r(Kg,"P",{});var Ys=n(Fe);Af=o(Ys,"Use the "),Ds=r(Ys,"A",{href:!0});var Xg=n(Ds);Tf=o(Xg,"download()"),Xg.forEach(t),Df=o(Ys," method to download the audio data at "),Il=r(Ys,"CODE",{});var Zg=n(Il);Cf=o(Zg,"_AUDIO_URL"),Zg.forEach(t),Of=o(Ys,"."),Ys.forEach(t),Kg.forEach(t),If=c(Vs),Dt=r(Vs,"LI",{});var Gi=n(Dt);He=r(Gi,"P",{});var Ws=n(He);Sf=o(Ws,"To extract audio TAR archive locally, use the "),Cs=r(Ws,"A",{href:!0});var Jg=n(Cs);Pf=o(Jg,"extract()"),Jg.forEach(t),Lf=o(Ws,". You can use this method only in non-streaming mode (when "),Sl=r(Ws,"CODE",{});var Qg=n(Sl);Rf=o(Qg,"dl_manager.is_streaming=False"),Qg.forEach(t),zf=o(Ws,"). This returns a local path to the extracted archive directory:"),Ws.forEach(t),Nf=c(Gi),w(Ct.$$.fragment,Gi),Gi.forEach(t),Uf=c(Vs),Pl=r(Vs,"LI",{});var ev=n(Pl);K=r(ev,"P",{});var ie=n(K);Gf=o(ie,"Use the "),Os=r(ie,"A",{href:!0});var av=n(Os);Ff=o(av,"iter_archive()"),av.forEach(t),Hf=o(ie," method to iterate over the archive at "),Ll=r(ie,"CODE",{});var tv=n(Ll);Bf=o(tv,"audio_path"),tv.forEach(t),Mf=o(ie," after it\u2019s downloaded, just like in the Vivos example above. "),Is=r(ie,"A",{href:!0});var sv=n(Is);Vf=o(sv,"iter_archive()"),sv.forEach(t),Yf=o(ie," doesn\u2019t provide any information about the full paths of files from the archive, even if it has been extracted. As a result, you need to pass the "),Rl=r(ie,"CODE",{});var ov=n(Rl);Wf=o(ov,"local_extracted_archive"),ov.forEach(t),Kf=o(ie," path to the next step in "),zl=r(ie,"CODE",{});var lv=n(zl);Xf=o(lv,"gen_kwargs"),lv.forEach(t),Zf=o(ie,", in order to preserve information about where the archive was extracted to. This is required to construct the correct paths to the local files when you generate the examples."),ie.forEach(t),ev.forEach(t),Vs.forEach(t),ai=c(e),w(Da.$$.fragment,e),ti=c(e),Ot=r(e,"OL",{start:!0});var rv=n(Ot);Be=r(rv,"LI",{});var Ks=n(Be);Jf=o(Ks,"Use the "),Ss=r(Ks,"A",{href:!0});var nv=n(Ss);Qf=o(nv,"download_and_extract()"),nv.forEach(t),eu=o(Ks," method to download the metadata file specified in "),Nl=r(Ks,"CODE",{});var iv=n(Nl);au=o(iv,"_METADATA_URL"),iv.forEach(t),tu=o(Ks,". This method returns a path to a local file in non-streaming mode. In streaming mode, it opens the file at the URL remotely and returns this URL."),Ks.forEach(t),rv.forEach(t),si=c(e),w(Ca.$$.fragment,e),oi=c(e),It=r(e,"OL",{start:!0});var dv=n(It);St=r(dv,"LI",{});var Fi=n(St);te=r(Fi,"P",{});var xe=n(te);su=o(xe,"Now use the "),Ps=r(xe,"A",{href:!0});var pv=n(Ps);ou=o(pv,"SplitGenerator"),pv.forEach(t),lu=o(xe," to organize the audio files and metadata in each split. Name each split with a standard name like: "),Ul=r(xe,"CODE",{});var hv=n(Ul);ru=o(hv,"Split.TRAIN"),hv.forEach(t),nu=o(xe,", "),Gl=r(xe,"CODE",{});var cv=n(Gl);iu=o(cv,"Split.TEST"),cv.forEach(t),du=o(xe,", and "),Fl=r(xe,"CODE",{});var fv=n(Fl);pu=o(fv,"SPLIT.Validation"),fv.forEach(t),hu=o(xe,"."),xe.forEach(t),cu=c(Fi),N=r(Fi,"P",{});var Y=n(N);fu=o(Y,"In the "),Hl=r(Y,"CODE",{});var uv=n(Hl);uu=o(uv,"gen_kwargs"),uv.forEach(t),_u=o(Y," parameter, specify the file paths to "),Bl=r(Y,"CODE",{});var _v=n(Bl);mu=o(_v,"local_extracted_archive"),_v.forEach(t),gu=o(Y,", "),Ml=r(Y,"CODE",{});var mv=n(Ml);vu=o(mv,"audio_files"),mv.forEach(t),wu=o(Y,", "),Vl=r(Y,"CODE",{});var gv=n(Vl);yu=o(gv,"metadata_path"),gv.forEach(t),$u=o(Y,", and "),Yl=r(Y,"CODE",{});var vv=n(Yl);ju=o(vv,"path_to_clips"),vv.forEach(t),Eu=o(Y,". Remember, for "),Wl=r(Y,"CODE",{});var wv=n(Wl);bu=o(wv,"audio_files"),wv.forEach(t),ku=o(Y,", you need to use "),Ls=r(Y,"A",{href:!0});var yv=n(Ls);qu=o(yv,"iter_archive()"),yv.forEach(t),xu=o(Y," to iterate over the audio files in the TAR archives. This enables streaming for your dataset! All of these file paths are passed onto the next step where the dataset samples are generated."),Y.forEach(t),Fi.forEach(t),dv.forEach(t),li=c(e),w(Pt.$$.fragment,e),ri=c(e),Me=r(e,"H4",{class:!0});var Hi=n(Me);Oa=r(Hi,"A",{id:!0,class:!0,href:!0});var $v=n(Oa);Kl=r($v,"SPAN",{});var jv=n(Kl);w(Lt.$$.fragment,jv),jv.forEach(t),$v.forEach(t),Au=c(Hi),Xl=r(Hi,"SPAN",{});var Ev=n(Xl);Tu=o(Ev,"Generate the dataset"),Ev.forEach(t),Hi.forEach(t),ni=c(e),B=r(e,"P",{});var de=n(B);Du=o(de,"Here "),Zl=r(de,"CODE",{});var bv=n(Zl);Cu=o(bv,"_generate_examples"),bv.forEach(t),Ou=o(de," accepts "),Jl=r(de,"CODE",{});var kv=n(Jl);Iu=o(kv,"local_extracted_archive"),kv.forEach(t),Su=o(de,", "),Ql=r(de,"CODE",{});var qv=n(Ql);Pu=o(qv,"audio_files"),qv.forEach(t),Lu=o(de,", "),er=r(de,"CODE",{});var xv=n(er);Ru=o(xv,"metadata_path"),xv.forEach(t),zu=o(de,", and "),ar=r(de,"CODE",{});var Av=n(ar);Nu=o(Av,"path_to_clips"),Av.forEach(t),Uu=o(de," from the previous method as arguments."),de.forEach(t),ii=c(e),Ia=r(e,"OL",{});var Bi=n(Ia);Rt=r(Bi,"LI",{});var Mi=n(Rt);zt=r(Mi,"P",{});var Vi=n(zt);Gu=o(Vi,"TAR files are accessed and yielded sequentially. This means you need to have the metadata in "),tr=r(Vi,"CODE",{});var Tv=n(tr);Fu=o(Tv,"metadata_path"),Tv.forEach(t),Hu=o(Vi," associated with the audio files in the TAR file in hand first so that you can yield it with its corresponding audio file further:"),Vi.forEach(t),Bu=c(Mi),w(Nt.$$.fragment,Mi),Mi.forEach(t),Mu=c(Bi),Ut=r(Bi,"LI",{});var Yi=n(Ut);S=r(Yi,"P",{});var P=n(S);Vu=o(P,"Now you can yield the files in "),sr=r(P,"CODE",{});var Dv=n(sr);Yu=o(Dv,"audio_files"),Dv.forEach(t),Wu=o(P," archive. When you use "),Rs=r(P,"A",{href:!0});var Cv=n(Rs);Ku=o(Cv,"iter_archive()"),Cv.forEach(t),Xu=o(P,", it yielded a tuple of ("),or=r(P,"CODE",{});var Ov=n(or);Zu=o(Ov,"path"),Ov.forEach(t),Ju=o(P,", "),lr=r(P,"CODE",{});var Iv=n(lr);Qu=o(Iv,"f"),Iv.forEach(t),e_=o(P,") where "),rr=r(P,"CODE",{});var Sv=n(rr);a_=o(Sv,"path"),Sv.forEach(t),t_=o(P," is a "),nr=r(P,"STRONG",{});var Pv=n(nr);s_=o(Pv,"relative path"),Pv.forEach(t),o_=o(P," to a file inside the archive, and "),ir=r(P,"CODE",{});var Lv=n(ir);l_=o(Lv,"f"),Lv.forEach(t),r_=o(P," is the file object itself. To get the "),dr=r(P,"STRONG",{});var Rv=n(dr);n_=o(Rv,"full path"),Rv.forEach(t),i_=o(P," to the locally extracted file, join the path of the directory ("),pr=r(P,"CODE",{});var zv=n(pr);d_=o(zv,"local_extracted_path"),zv.forEach(t),p_=o(P,") where the archive is extracted to and the relative audio file path ("),hr=r(P,"CODE",{});var Nv=n(hr);h_=o(Nv,"path"),Nv.forEach(t),c_=o(P,"):"),P.forEach(t),f_=c(Yi),w(Gt.$$.fragment,Yi),Yi.forEach(t),Bi.forEach(t),di=c(e),Sa=r(e,"P",{});var Wi=n(Sa);u_=o(Wi,"Put both of these steps together, and the whole "),cr=r(Wi,"CODE",{});var Uv=n(cr);__=o(Uv,"_generate_examples"),Uv.forEach(t),m_=o(Wi," method should look like:"),Wi.forEach(t),pi=c(e),w(Ft.$$.fragment,e),this.h()},h(){f(p,"name","hf:doc:metadata"),f(p,"content",JSON.stringify(lw)),f(g,"id","create-an-audio-dataset"),f(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(g,"href","#create-an-audio-dataset"),f(u,"class","relative group"),f(Te,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.push_to_hub"),f(Ke,"id","local-files"),f(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ke,"href","#local-files"),f(De,"class","relative group"),f(Xt,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.cast_column"),f(Zt,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Audio"),f(Jt,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.push_to_hub"),f(Ze,"id","audiofolder"),f(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ze,"href","#audiofolder"),f(Ce,"class","relative group"),f(as,"href","/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset"),f(na,"id","loading-script"),f(na,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(na,"href","#loading-script"),f(Oe,"class","relative group"),f(et,"class","underline decoration-green-400 decoration-2 font-semibold"),f(et,"href","./dataset_script"),f(os,"href","./stream"),f(st,"href","https://huggingface.co/datasets/vivos/blob/main/vivos.py"),f(st,"rel","nofollow"),f(ca,"id","create-a-dataset-builder-class"),f(ca,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ca,"href","#create-a-dataset-builder-class"),f(Ie,"class","relative group"),f(ns,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),f(ps,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),f(_a,"id","multiple-configurations"),f(_a,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(_a,"href","#multiple-configurations"),f(Se,"class","relative group"),f(it,"href","https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia"),f(it,"rel","nofollow"),f(hs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.BuilderConfig"),f(cs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),f(pt,"href","https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/release_stats.py"),f(pt,"rel","nofollow"),f(wa,"id","add-dataset-metadata"),f(wa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(wa,"href","#add-dataset-metadata"),f(Pe,"class","relative group"),f(fs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetInfo"),f(ms,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Audio"),f($a,"id","download-and-define-the-dataset-splits"),f($a,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f($a,"href","#download-and-define-the-dataset-splits"),f(Le,"class","relative group"),f($s,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download"),f(js,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.SplitGenerator"),f(Es,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),f(ba,"id","generate-the-dataset"),f(ba,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ba,"href","#generate-the-dataset"),f(ze,"class","relative group"),f(bs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder"),f(qs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),f(qa,"id","upload-the-dataset-to-the-hub"),f(qa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(qa,"href","#upload-the-dataset-to-the-hub"),f(Ne,"class","relative group"),f(xs,"href","./dataset_card"),f(As,"href","./share"),f(xa,"id","advanced-extract-tar-archives-locally"),f(xa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(xa,"href","#advanced-extract-tar-archives-locally"),f(Ue,"class","relative group"),f(At,"href","https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/librivox-indonesia.py"),f(At,"rel","nofollow"),f(Ta,"id","download-and-define-the-dataset-splits"),f(Ta,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ta,"href","#download-and-define-the-dataset-splits"),f(Ge,"class","relative group"),f(Ds,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download"),f(Cs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.extract"),f(Os,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),f(Is,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),f(Ss,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract"),f(Ot,"start","4"),f(Ps,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.SplitGenerator"),f(Ls,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive"),f(It,"start","5"),f(Oa,"id","generate-the-dataset"),f(Oa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Oa,"href","#generate-the-dataset"),f(Me,"class","relative group"),f(Rs,"href","/docs/datasets/main/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive")},m(e,i){a(document.head,p),d(e,k,i),d(e,u,i),a(u,g),a(g,b),y(_,b,null),a(u,m),a(u,x),a(x,A),d(e,q,i),d(e,D,i),a(D,T),d(e,C,i),y(U,e,i),d(e,G,i),d(e,F,i),a(F,za),d(e,he,i),d(e,X,i),a(X,Ae),a(Ae,ee),a(ee,L),a(ee,Te),a(Te,Yt),a(ee,Wt),a(X,Kt),a(X,Ye),a(Ye,fe),a(fe,Ki),a(fe,Xs),a(Xs,Xi),a(fe,Zi),a(X,Ji),a(X,Zs),a(Zs,Js),a(Js,Qi),d(e,jr,i),y(We,e,i),d(e,Er,i),d(e,De,i),a(De,Ke),a(Ke,Qs),y(Na,Qs,null),a(De,ed),a(De,eo),a(eo,ad),d(e,br,i),d(e,ue,i),a(ue,td),a(ue,Xt),a(Xt,sd),a(ue,od),a(ue,Zt),a(Zt,ld),a(ue,rd),d(e,kr,i),y(Ua,e,i),d(e,qr,i),d(e,Xe,i),a(Xe,nd),a(Xe,Jt),a(Jt,id),a(Xe,dd),d(e,xr,i),y(Ga,e,i),d(e,Ar,i),d(e,Qt,i),a(Qt,pd),d(e,Tr,i),y(Fa,e,i),d(e,Dr,i),d(e,Ce,i),a(Ce,Ze),a(Ze,ao),y(Ha,ao,null),a(Ce,hd),a(Ce,to),a(to,cd),d(e,Cr,i),d(e,Z,i),a(Z,fd),a(Z,so),a(so,ud),a(Z,_d),a(Z,oo),a(oo,md),a(Z,gd),a(Z,lo),a(lo,vd),a(Z,wd),a(Z,ro),a(ro,yd),a(Z,$d),d(e,Or,i),d(e,Je,i),a(Je,jd),a(Je,no),a(no,Ed),a(Je,bd),d(e,Ir,i),y(Ba,e,i),d(e,Sr,i),d(e,Qe,i),a(Qe,kd),a(Qe,io),a(io,qd),a(Qe,xd),d(e,Pr,i),y(ea,e,i),d(e,Lr,i),d(e,aa,i),a(aa,Ad),a(aa,po),a(po,Td),a(aa,Dd),d(e,Rr,i),y(Ma,e,i),d(e,zr,i),d(e,es,i),a(es,Cd),d(e,Nr,i),y(Va,e,i),d(e,Ur,i),d(e,oe,i),a(oe,Od),a(oe,ho),a(ho,Id),a(oe,Sd),a(oe,as),a(as,Pd),a(oe,Ld),a(oe,co),a(co,Rd),a(oe,zd),d(e,Gr,i),y(Ya,e,i),d(e,Fr,i),d(e,ta,i),a(ta,Nd),a(ta,fo),a(fo,Ud),a(ta,Gd),d(e,Hr,i),y(Wa,e,i),d(e,Br,i),y(sa,e,i),d(e,Mr,i),d(e,oa,i),a(oa,Fd),a(oa,uo),a(uo,Hd),a(oa,Bd),d(e,Vr,i),y(Ka,e,i),d(e,Yr,i),d(e,_e,i),a(_e,Md),a(_e,_o),a(_o,Vd),a(_e,Yd),a(_e,mo),a(mo,Wd),a(_e,Kd),d(e,Wr,i),y(Xa,e,i),d(e,Kr,i),y(la,e,i),d(e,Xr,i),y(ra,e,i),d(e,Zr,i),d(e,Oe,i),a(Oe,na),a(na,go),y(Za,go,null),a(Oe,Xd),a(Oe,vo),a(vo,Zd),d(e,Jr,i),d(e,ts,i),a(ts,Jd),d(e,Qr,i),y(Ja,e,i),d(e,en,i),d(e,me,i),a(me,Qd),a(me,wo),a(wo,ep),a(me,ap),a(me,yo),a(yo,tp),a(me,sp),d(e,an,i),d(e,ss,i),a(ss,op),d(e,tn,i),y(Qa,e,i),d(e,sn,i),d(e,ge,i),a(ge,lp),a(ge,et),a(et,rp),a(ge,np),a(ge,$o),a($o,ip),a(ge,dp),d(e,on,i),d(e,ia,i),a(ia,at),a(at,pp),a(at,os),a(os,hp),a(at,cp),a(ia,fp),a(ia,jo),a(jo,up),d(e,ln,i),d(e,ls,i),a(ls,_p),d(e,rn,i),y(tt,e,i),d(e,nn,i),d(e,rs,i),a(rs,mp),d(e,dn,i),d(e,H,i),a(H,Eo),a(Eo,gp),a(H,vp),a(H,bo),a(bo,wp),a(H,yp),a(H,ko),a(ko,$p),a(H,jp),a(H,qo),a(qo,Ep),a(H,bp),a(H,xo),a(xo,kp),a(H,qp),a(H,Ao),a(Ao,xp),d(e,pn,i),d(e,da,i),a(da,Ap),a(da,st),a(st,Tp),a(da,Dp),d(e,hn,i),y(pa,e,i),d(e,cn,i),y(ha,e,i),d(e,fn,i),d(e,Ie,i),a(Ie,ca),a(ca,To),y(ot,To,null),a(Ie,Cp),a(Ie,Do),a(Do,Op),d(e,un,i),d(e,lt,i),a(lt,ns),a(ns,Ip),a(lt,Sp),d(e,_n,i),d(e,ve,i),a(ve,is),a(is,Co),a(Co,Pp),a(is,Lp),a(ve,Rp),a(ve,ds),a(ds,Oo),a(Oo,zp),a(ds,Np),a(ve,Up),a(ve,fa),a(fa,Io),a(Io,Gp),a(fa,Fp),a(fa,So),a(So,Hp),a(fa,Bp),d(e,mn,i),d(e,ua,i),a(ua,Mp),a(ua,ps),a(ps,Vp),a(ua,Yp),d(e,gn,i),y(rt,e,i),d(e,vn,i),d(e,Se,i),a(Se,_a),a(_a,Po),y(nt,Po,null),a(Se,Wp),a(Se,Lo),a(Lo,Kp),d(e,wn,i),d(e,ma,i),a(ma,Xp),a(ma,it),a(it,Zp),a(ma,Jp),d(e,yn,i),d(e,le,i),a(le,Qp),a(le,hs),a(hs,eh),a(le,ah),a(le,Ro),a(Ro,th),a(le,sh),a(le,zo),a(zo,oh),a(le,lh),d(e,$n,i),y(dt,e,i),d(e,jn,i),d(e,J,i),a(J,rh),a(J,No),a(No,nh),a(J,ih),a(J,cs),a(cs,dh),a(J,ph),a(J,Uo),a(Uo,hh),a(J,ch),a(J,pt),a(pt,fh),a(J,uh),d(e,En,i),y(ht,e,i),d(e,bn,i),y(ga,e,i),d(e,kn,i),d(e,va,i),a(va,_h),a(va,Go),a(Go,mh),a(va,gh),d(e,qn,i),y(ct,e,i),d(e,xn,i),d(e,Pe,i),a(Pe,wa),a(wa,Fo),y(ft,Fo,null),a(Pe,vh),a(Pe,Ho),a(Ho,wh),d(e,An,i),d(e,we,i),a(we,yh),a(we,fs),a(fs,$h),a(we,jh),a(we,Bo),a(Bo,Eh),a(we,bh),d(e,Tn,i),y(ut,e,i),d(e,Dn,i),d(e,us,i),a(us,kh),d(e,Cn,i),d(e,Q,i),a(Q,_s),a(_s,Mo),a(Mo,qh),a(_s,xh),a(Q,Ah),a(Q,ye),a(ye,Vo),a(Vo,Th),a(ye,Dh),a(ye,ms),a(ms,Ch),a(ye,Oh),a(ye,Yo),a(Yo,Ih),a(ye,Sh),a(Q,Ph),a(Q,gs),a(gs,Wo),a(Wo,Lh),a(gs,Rh),a(Q,zh),a(Q,vs),a(vs,Ko),a(Ko,Nh),a(vs,Uh),a(Q,Gh),a(Q,ws),a(ws,Xo),a(Xo,Fh),a(ws,Hh),d(e,On,i),y(ya,e,i),d(e,In,i),y(_t,e,i),d(e,Sn,i),d(e,Le,i),a(Le,$a),a($a,Zo),y(mt,Zo,null),a(Le,Bh),a(Le,Jo),a(Jo,Mh),d(e,Pn,i),d(e,ys,i),a(ys,Vh),d(e,Ln,i),d(e,ja,i),a(ja,gt),a(gt,ce),a(ce,Yh),a(ce,$s),a($s,Wh),a(ce,Kh),a(ce,Qo),a(Qo,Xh),a(ce,Zh),a(ce,el),a(el,Jh),a(ce,Qh),a(gt,ec),a(gt,Re),a(Re,vt),a(vt,ac),a(vt,al),a(al,tc),a(vt,sc),a(Re,oc),a(Re,tl),a(tl,lc),a(Re,rc),a(Re,sl),a(sl,nc),a(ja,ic),a(ja,wt),a(wt,ae),a(ae,dc),a(ae,js),a(js,pc),a(ae,hc),a(ae,ol),a(ol,cc),a(ae,fc),a(ae,ll),a(ll,uc),a(ae,_c),a(ae,rl),a(rl,mc),a(ae,gc),a(wt,vc),a(wt,W),a(W,wc),a(W,nl),a(nl,yc),a(W,$c),a(W,il),a(il,jc),a(W,Ec),a(W,dl),a(dl,bc),a(W,kc),a(W,pl),a(pl,qc),a(W,xc),a(W,Es),a(Es,Ac),a(W,Tc),d(e,Rn,i),y(yt,e,i),d(e,zn,i),y(Ea,e,i),d(e,Nn,i),d(e,ze,i),a(ze,ba),a(ba,hl),y($t,hl,null),a(ze,Dc),a(ze,cl),a(cl,Cc),d(e,Un,i),d(e,R,i),a(R,Oc),a(R,bs),a(bs,Ic),a(R,Sc),a(R,fl),a(fl,Pc),a(R,Lc),a(R,ul),a(ul,Rc),a(R,zc),a(R,_l),a(_l,Nc),a(R,Uc),a(R,ml),a(ml,Gc),a(R,Fc),a(R,gl),a(gl,Hc),a(R,Bc),a(R,vl),a(vl,Mc),a(R,Vc),d(e,Gn,i),d(e,ks,i),a(ks,Yc),d(e,Fn,i),y(jt,e,i),d(e,Hn,i),d(e,z,i),a(z,Wc),a(z,wl),a(wl,Kc),a(z,Xc),a(z,qs),a(qs,Zc),a(z,Jc),a(z,yl),a(yl,Qc),a(z,ef),a(z,$l),a($l,af),a(z,tf),a(z,jl),a(jl,sf),a(z,of),a(z,El),a(El,lf),a(z,rf),a(z,bl),a(bl,nf),a(z,df),d(e,Bn,i),y(Et,e,i),d(e,Mn,i),d(e,ka,i),a(ka,pf),a(ka,kl),a(kl,hf),a(ka,cf),d(e,Vn,i),y(bt,e,i),d(e,Yn,i),d(e,Ne,i),a(Ne,qa),a(qa,ql),y(kt,ql,null),a(Ne,ff),a(Ne,xl),a(xl,uf),d(e,Wn,i),d(e,$e,i),a($e,_f),a($e,xs),a(xs,mf),a($e,gf),a($e,As),a(As,vf),a($e,wf),d(e,Kn,i),d(e,Ts,i),a(Ts,yf),d(e,Xn,i),y(qt,e,i),d(e,Zn,i),d(e,Ue,i),a(Ue,xa),a(xa,Al),y(xt,Al,null),a(Ue,$f),a(Ue,Tl),a(Tl,jf),d(e,Jn,i),d(e,Aa,i),a(Aa,Ef),a(Aa,At),a(At,bf),a(Aa,kf),d(e,Qn,i),d(e,Ge,i),a(Ge,Ta),a(Ta,Dl),y(Tt,Dl,null),a(Ge,qf),a(Ge,Cl),a(Cl,xf),d(e,ei,i),d(e,je,i),a(je,Ol),a(Ol,Fe),a(Fe,Af),a(Fe,Ds),a(Ds,Tf),a(Fe,Df),a(Fe,Il),a(Il,Cf),a(Fe,Of),a(je,If),a(je,Dt),a(Dt,He),a(He,Sf),a(He,Cs),a(Cs,Pf),a(He,Lf),a(He,Sl),a(Sl,Rf),a(He,zf),a(Dt,Nf),y(Ct,Dt,null),a(je,Uf),a(je,Pl),a(Pl,K),a(K,Gf),a(K,Os),a(Os,Ff),a(K,Hf),a(K,Ll),a(Ll,Bf),a(K,Mf),a(K,Is),a(Is,Vf),a(K,Yf),a(K,Rl),a(Rl,Wf),a(K,Kf),a(K,zl),a(zl,Xf),a(K,Zf),d(e,ai,i),y(Da,e,i),d(e,ti,i),d(e,Ot,i),a(Ot,Be),a(Be,Jf),a(Be,Ss),a(Ss,Qf),a(Be,eu),a(Be,Nl),a(Nl,au),a(Be,tu),d(e,si,i),y(Ca,e,i),d(e,oi,i),d(e,It,i),a(It,St),a(St,te),a(te,su),a(te,Ps),a(Ps,ou),a(te,lu),a(te,Ul),a(Ul,ru),a(te,nu),a(te,Gl),a(Gl,iu),a(te,du),a(te,Fl),a(Fl,pu),a(te,hu),a(St,cu),a(St,N),a(N,fu),a(N,Hl),a(Hl,uu),a(N,_u),a(N,Bl),a(Bl,mu),a(N,gu),a(N,Ml),a(Ml,vu),a(N,wu),a(N,Vl),a(Vl,yu),a(N,$u),a(N,Yl),a(Yl,ju),a(N,Eu),a(N,Wl),a(Wl,bu),a(N,ku),a(N,Ls),a(Ls,qu),a(N,xu),d(e,li,i),y(Pt,e,i),d(e,ri,i),d(e,Me,i),a(Me,Oa),a(Oa,Kl),y(Lt,Kl,null),a(Me,Au),a(Me,Xl),a(Xl,Tu),d(e,ni,i),d(e,B,i),a(B,Du),a(B,Zl),a(Zl,Cu),a(B,Ou),a(B,Jl),a(Jl,Iu),a(B,Su),a(B,Ql),a(Ql,Pu),a(B,Lu),a(B,er),a(er,Ru),a(B,zu),a(B,ar),a(ar,Nu),a(B,Uu),d(e,ii,i),d(e,Ia,i),a(Ia,Rt),a(Rt,zt),a(zt,Gu),a(zt,tr),a(tr,Fu),a(zt,Hu),a(Rt,Bu),y(Nt,Rt,null),a(Ia,Mu),a(Ia,Ut),a(Ut,S),a(S,Vu),a(S,sr),a(sr,Yu),a(S,Wu),a(S,Rs),a(Rs,Ku),a(S,Xu),a(S,or),a(or,Zu),a(S,Ju),a(S,lr),a(lr,Qu),a(S,e_),a(S,rr),a(rr,a_),a(S,t_),a(S,nr),a(nr,s_),a(S,o_),a(S,ir),a(ir,l_),a(S,r_),a(S,dr),a(dr,n_),a(S,i_),a(S,pr),a(pr,d_),a(S,p_),a(S,hr),a(hr,h_),a(S,c_),a(Ut,f_),y(Gt,Ut,null),d(e,di,i),d(e,Sa,i),a(Sa,u_),a(Sa,cr),a(cr,__),a(Sa,m_),d(e,pi,i),y(Ft,e,i),hi=!0},p(e,[i]){const Ht={};i&2&&(Ht.$$scope={dirty:i,ctx:e}),We.$set(Ht);const fr={};i&2&&(fr.$$scope={dirty:i,ctx:e}),ea.$set(fr);const ur={};i&2&&(ur.$$scope={dirty:i,ctx:e}),sa.$set(ur);const _r={};i&2&&(_r.$$scope={dirty:i,ctx:e}),la.$set(_r);const mr={};i&2&&(mr.$$scope={dirty:i,ctx:e}),ra.$set(mr);const gr={};i&2&&(gr.$$scope={dirty:i,ctx:e}),pa.$set(gr);const Ve={};i&2&&(Ve.$$scope={dirty:i,ctx:e}),ha.$set(Ve);const vr={};i&2&&(vr.$$scope={dirty:i,ctx:e}),ga.$set(vr);const Bt={};i&2&&(Bt.$$scope={dirty:i,ctx:e}),ya.$set(Bt);const wr={};i&2&&(wr.$$scope={dirty:i,ctx:e}),Ea.$set(wr);const yr={};i&2&&(yr.$$scope={dirty:i,ctx:e}),Da.$set(yr);const Mt={};i&2&&(Mt.$$scope={dirty:i,ctx:e}),Ca.$set(Mt)},i(e){hi||($(_.$$.fragment,e),$(U.$$.fragment,e),$(We.$$.fragment,e),$(Na.$$.fragment,e),$(Ua.$$.fragment,e),$(Ga.$$.fragment,e),$(Fa.$$.fragment,e),$(Ha.$$.fragment,e),$(Ba.$$.fragment,e),$(ea.$$.fragment,e),$(Ma.$$.fragment,e),$(Va.$$.fragment,e),$(Ya.$$.fragment,e),$(Wa.$$.fragment,e),$(sa.$$.fragment,e),$(Ka.$$.fragment,e),$(Xa.$$.fragment,e),$(la.$$.fragment,e),$(ra.$$.fragment,e),$(Za.$$.fragment,e),$(Ja.$$.fragment,e),$(Qa.$$.fragment,e),$(tt.$$.fragment,e),$(pa.$$.fragment,e),$(ha.$$.fragment,e),$(ot.$$.fragment,e),$(rt.$$.fragment,e),$(nt.$$.fragment,e),$(dt.$$.fragment,e),$(ht.$$.fragment,e),$(ga.$$.fragment,e),$(ct.$$.fragment,e),$(ft.$$.fragment,e),$(ut.$$.fragment,e),$(ya.$$.fragment,e),$(_t.$$.fragment,e),$(mt.$$.fragment,e),$(yt.$$.fragment,e),$(Ea.$$.fragment,e),$($t.$$.fragment,e),$(jt.$$.fragment,e),$(Et.$$.fragment,e),$(bt.$$.fragment,e),$(kt.$$.fragment,e),$(qt.$$.fragment,e),$(xt.$$.fragment,e),$(Tt.$$.fragment,e),$(Ct.$$.fragment,e),$(Da.$$.fragment,e),$(Ca.$$.fragment,e),$(Pt.$$.fragment,e),$(Lt.$$.fragment,e),$(Nt.$$.fragment,e),$(Gt.$$.fragment,e),$(Ft.$$.fragment,e),hi=!0)},o(e){j(_.$$.fragment,e),j(U.$$.fragment,e),j(We.$$.fragment,e),j(Na.$$.fragment,e),j(Ua.$$.fragment,e),j(Ga.$$.fragment,e),j(Fa.$$.fragment,e),j(Ha.$$.fragment,e),j(Ba.$$.fragment,e),j(ea.$$.fragment,e),j(Ma.$$.fragment,e),j(Va.$$.fragment,e),j(Ya.$$.fragment,e),j(Wa.$$.fragment,e),j(sa.$$.fragment,e),j(Ka.$$.fragment,e),j(Xa.$$.fragment,e),j(la.$$.fragment,e),j(ra.$$.fragment,e),j(Za.$$.fragment,e),j(Ja.$$.fragment,e),j(Qa.$$.fragment,e),j(tt.$$.fragment,e),j(pa.$$.fragment,e),j(ha.$$.fragment,e),j(ot.$$.fragment,e),j(rt.$$.fragment,e),j(nt.$$.fragment,e),j(dt.$$.fragment,e),j(ht.$$.fragment,e),j(ga.$$.fragment,e),j(ct.$$.fragment,e),j(ft.$$.fragment,e),j(ut.$$.fragment,e),j(ya.$$.fragment,e),j(_t.$$.fragment,e),j(mt.$$.fragment,e),j(yt.$$.fragment,e),j(Ea.$$.fragment,e),j($t.$$.fragment,e),j(jt.$$.fragment,e),j(Et.$$.fragment,e),j(bt.$$.fragment,e),j(kt.$$.fragment,e),j(qt.$$.fragment,e),j(xt.$$.fragment,e),j(Tt.$$.fragment,e),j(Ct.$$.fragment,e),j(Da.$$.fragment,e),j(Ca.$$.fragment,e),j(Pt.$$.fragment,e),j(Lt.$$.fragment,e),j(Nt.$$.fragment,e),j(Gt.$$.fragment,e),j(Ft.$$.fragment,e),hi=!1},d(e){t(p),e&&t(k),e&&t(u),E(_),e&&t(q),e&&t(D),e&&t(C),E(U,e),e&&t(G),e&&t(F),e&&t(he),e&&t(X),e&&t(jr),E(We,e),e&&t(Er),e&&t(De),E(Na),e&&t(br),e&&t(ue),e&&t(kr),E(Ua,e),e&&t(qr),e&&t(Xe),e&&t(xr),E(Ga,e),e&&t(Ar),e&&t(Qt),e&&t(Tr),E(Fa,e),e&&t(Dr),e&&t(Ce),E(Ha),e&&t(Cr),e&&t(Z),e&&t(Or),e&&t(Je),e&&t(Ir),E(Ba,e),e&&t(Sr),e&&t(Qe),e&&t(Pr),E(ea,e),e&&t(Lr),e&&t(aa),e&&t(Rr),E(Ma,e),e&&t(zr),e&&t(es),e&&t(Nr),E(Va,e),e&&t(Ur),e&&t(oe),e&&t(Gr),E(Ya,e),e&&t(Fr),e&&t(ta),e&&t(Hr),E(Wa,e),e&&t(Br),E(sa,e),e&&t(Mr),e&&t(oa),e&&t(Vr),E(Ka,e),e&&t(Yr),e&&t(_e),e&&t(Wr),E(Xa,e),e&&t(Kr),E(la,e),e&&t(Xr),E(ra,e),e&&t(Zr),e&&t(Oe),E(Za),e&&t(Jr),e&&t(ts),e&&t(Qr),E(Ja,e),e&&t(en),e&&t(me),e&&t(an),e&&t(ss),e&&t(tn),E(Qa,e),e&&t(sn),e&&t(ge),e&&t(on),e&&t(ia),e&&t(ln),e&&t(ls),e&&t(rn),E(tt,e),e&&t(nn),e&&t(rs),e&&t(dn),e&&t(H),e&&t(pn),e&&t(da),e&&t(hn),E(pa,e),e&&t(cn),E(ha,e),e&&t(fn),e&&t(Ie),E(ot),e&&t(un),e&&t(lt),e&&t(_n),e&&t(ve),e&&t(mn),e&&t(ua),e&&t(gn),E(rt,e),e&&t(vn),e&&t(Se),E(nt),e&&t(wn),e&&t(ma),e&&t(yn),e&&t(le),e&&t($n),E(dt,e),e&&t(jn),e&&t(J),e&&t(En),E(ht,e),e&&t(bn),E(ga,e),e&&t(kn),e&&t(va),e&&t(qn),E(ct,e),e&&t(xn),e&&t(Pe),E(ft),e&&t(An),e&&t(we),e&&t(Tn),E(ut,e),e&&t(Dn),e&&t(us),e&&t(Cn),e&&t(Q),e&&t(On),E(ya,e),e&&t(In),E(_t,e),e&&t(Sn),e&&t(Le),E(mt),e&&t(Pn),e&&t(ys),e&&t(Ln),e&&t(ja),e&&t(Rn),E(yt,e),e&&t(zn),E(Ea,e),e&&t(Nn),e&&t(ze),E($t),e&&t(Un),e&&t(R),e&&t(Gn),e&&t(ks),e&&t(Fn),E(jt,e),e&&t(Hn),e&&t(z),e&&t(Bn),E(Et,e),e&&t(Mn),e&&t(ka),e&&t(Vn),E(bt,e),e&&t(Yn),e&&t(Ne),E(kt),e&&t(Wn),e&&t($e),e&&t(Kn),e&&t(Ts),e&&t(Xn),E(qt,e),e&&t(Zn),e&&t(Ue),E(xt),e&&t(Jn),e&&t(Aa),e&&t(Qn),e&&t(Ge),E(Tt),e&&t(ei),e&&t(je),E(Ct),e&&t(ai),E(Da,e),e&&t(ti),e&&t(Ot),e&&t(si),E(Ca,e),e&&t(oi),e&&t(It),e&&t(li),E(Pt,e),e&&t(ri),e&&t(Me),E(Lt),e&&t(ni),e&&t(B),e&&t(ii),e&&t(Ia),E(Nt),E(Gt),e&&t(di),e&&t(Sa),e&&t(pi),E(Ft,e)}}}const lw={local:"create-an-audio-dataset",sections:[{local:"local-files",title:"Local files"},{local:"audiofolder",title:"AudioFolder"},{local:"loading-script",sections:[{local:"create-a-dataset-builder-class",sections:[{local:"multiple-configurations",title:"Multiple configurations"}],title:"Create a dataset builder class"},{local:"add-dataset-metadata",title:"Add dataset metadata"},{local:"download-and-define-the-dataset-splits",title:"Download and define the dataset splits"},{local:"generate-the-dataset",title:"Generate the dataset"},{local:"upload-the-dataset-to-the-hub",title:"Upload the dataset to the Hub"},{local:"advanced-extract-tar-archives-locally",sections:[{local:"download-and-define-the-dataset-splits",title:"Download and define the dataset splits"},{local:"generate-the-dataset",title:"Generate the dataset"}],title:"(Advanced) Extract TAR archives locally"}],title:"Loading script"}],title:"Create an audio dataset"};function rw(I){return Mv(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class hw extends Gv{constructor(p){super();Fv(this,p,rw,ow,Hv,{})}}export{hw as default,lw as metadata};
