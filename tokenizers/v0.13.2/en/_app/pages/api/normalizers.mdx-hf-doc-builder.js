import{S as cn,i as pn,s as fn,e as a,k as m,w as v,t as h,M as hn,c as o,d as r,m as c,a as n,x as z,h as d,b as s,G as t,g as f,y as g,q as w,o as _,B as k,v as dn,L as un}from"../../chunks/vendor-hf-doc-builder.js";import{D as P}from"../../chunks/Docstring-hf-doc-builder.js";import{I as D}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{T as $n,M as ro}from"../../chunks/TokenizersLanguageContent-hf-doc-builder.js";function vn(C){let i,$,l,u,b,E,A,F,y,T,q,K,N,x,I,Ye,be,B,ce,ar,Ee,Vt,or,Ht,jr,H,ye,Ut,nr,Mt,Gr,U,pe,sr,Se,Ot,lr,Wt,Jr,M,Pe,jt,ir,Gt,Qr,O,fe,mr,Ae,Jt,cr,Qt,Xr,W,xe,Xt,pr,Yt,Yr,j,he,fr,De,Zt,hr,ea,Zr,G,Fe,ra,dr,ta,et,J,de,ur,Ie,aa,$r,oa,rt,Q,Ce,na,vr,sa,tt,X,ue,zr,Te,la,gr,ia,at,Y,qe,ma,wr,ca,ot,Z,$e,_r,Be,pa,kr,fa,nt,S,Ke,ha,Nr,da,ua,br,$a,va,L,Le,za,Re,ga,Er,wa,_a,ka,ve,Na,yr,ba,Ea,Sr,ya,Sa,R,Ve,Pa,Pr,Aa,xa,ze,Da,Ze,Fa,Ia,Ar,Ca,st,ee,ge,xr,He,Ta,Dr,qa,lt,re,Ue,Ba,Fr,Ka,it,te,we,Ir,Me,La,Cr,Ra,mt,ae,Oe,Va,Tr,Ha,ct,oe,_e,qr,We,Ua,Br,Ma,pt,ne,je,Oa,Kr,Wa,ft,se,ke,Lr,Ge,ja,Rr,Ga,ht,le,Je,Ja,Vr,Qa,dt,ie,Ne,Hr,Qe,Xa,Ur,Ya,ut,me,Xe,Za,Mr,eo,$t;return u=new D({}),T=new P({props:{name:"class tokenizers.normalizers.BertNormalizer",anchor:"tokenizers.normalizers.BertNormalizer",parameters:[{name:"clean_text",val:" = True"},{name:"handle_chinese_chars",val:" = True"},{name:"strip_accents",val:" = None"},{name:"lowercase",val:" = True"}],parametersDescription:[{anchor:"tokenizers.normalizers.BertNormalizer.clean_text",description:`<strong>clean_text</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether to clean the text, by removing any control characters
and replacing all whitespaces by the classic one.`,name:"clean_text"},{anchor:"tokenizers.normalizers.BertNormalizer.handle_chinese_chars",description:`<strong>handle_chinese_chars</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether to handle chinese chars by putting spaces around them.`,name:"handle_chinese_chars"},{anchor:"tokenizers.normalizers.BertNormalizer.strip_accents",description:`<strong>strip_accents</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to strip all accents. If this option is not specified (ie == None),
then it will be determined by the value for <em>lowercase</em> (as in the original Bert).`,name:"strip_accents"},{anchor:"tokenizers.normalizers.BertNormalizer.lowercase",description:`<strong>lowercase</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether to lowercase.`,name:"lowercase"}]}}),Ee=new D({}),ye=new P({props:{name:"class tokenizers.normalizers.Lowercase",anchor:"tokenizers.normalizers.Lowercase",parameters:[]}}),Se=new D({}),Pe=new P({props:{name:"class tokenizers.normalizers.NFC",anchor:"tokenizers.normalizers.NFC",parameters:[]}}),Ae=new D({}),xe=new P({props:{name:"class tokenizers.normalizers.NFD",anchor:"tokenizers.normalizers.NFD",parameters:[]}}),De=new D({}),Fe=new P({props:{name:"class tokenizers.normalizers.NFKC",anchor:"tokenizers.normalizers.NFKC",parameters:[]}}),Ie=new D({}),Ce=new P({props:{name:"class tokenizers.normalizers.NFKD",anchor:"tokenizers.normalizers.NFKD",parameters:[]}}),Te=new D({}),qe=new P({props:{name:"class tokenizers.normalizers.Nmt",anchor:"tokenizers.normalizers.Nmt",parameters:[]}}),Be=new D({}),Ke=new P({props:{name:"class tokenizers.normalizers.Normalizer",anchor:"tokenizers.normalizers.Normalizer",parameters:""}}),Le=new P({props:{name:"normalize",anchor:"tokenizers.normalizers.Normalizer.normalize",parameters:[{name:"normalized",val:""}],parametersDescription:[{anchor:"tokenizers.normalizers.Normalizer.normalize.normalized",description:`<strong>normalized</strong> (<code>NormalizedString</code>) &#x2014;
The normalized string on which to apply this
<a href="/docs/tokenizers/v0.13.2/en/api/normalizers#tokenizers.normalizers.Normalizer">Normalizer</a>`,name:"normalized"}]}}),Ve=new P({props:{name:"normalize_str",anchor:"tokenizers.normalizers.Normalizer.normalize_str",parameters:[{name:"sequence",val:""}],parametersDescription:[{anchor:"tokenizers.normalizers.Normalizer.normalize_str.sequence",description:`<strong>sequence</strong> (<code>str</code>) &#x2014;
A string to normalize`,name:"sequence"}],returnDescription:`
<p>A string after normalization</p>
`,returnType:`
<p><code>str</code></p>
`}}),He=new D({}),Ue=new P({props:{name:"class tokenizers.normalizers.Precompiled",anchor:"tokenizers.normalizers.Precompiled",parameters:[{name:"precompiled_charsmap",val:""}]}}),Me=new D({}),Oe=new P({props:{name:"class tokenizers.normalizers.Replace",anchor:"tokenizers.normalizers.Replace",parameters:[{name:"pattern",val:""},{name:"content",val:""}]}}),We=new D({}),je=new P({props:{name:"class tokenizers.normalizers.Sequence",anchor:"tokenizers.normalizers.Sequence",parameters:"",parametersDescription:[{anchor:"tokenizers.normalizers.Sequence.normalizers",description:`<strong>normalizers</strong> (<code>List[Normalizer]</code>) &#x2014;
A list of Normalizer to be run as a sequence`,name:"normalizers"}]}}),Ge=new D({}),Je=new P({props:{name:"class tokenizers.normalizers.Strip",anchor:"tokenizers.normalizers.Strip",parameters:[{name:"left",val:" = True"},{name:"right",val:" = True"}]}}),Qe=new D({}),Xe=new P({props:{name:"class tokenizers.normalizers.StripAccents",anchor:"tokenizers.normalizers.StripAccents",parameters:[]}}),{c(){i=a("h2"),$=a("a"),l=a("span"),v(u.$$.fragment),b=m(),E=a("span"),A=h("BertNormalizer"),F=m(),y=a("div"),v(T.$$.fragment),q=m(),K=a("p"),N=h("BertNormalizer"),x=m(),I=a("p"),Ye=h(`Takes care of normalizing raw text before giving it to a Bert model.
This includes cleaning the text, handling accents, chinese chars and lowercasing`),be=m(),B=a("h2"),ce=a("a"),ar=a("span"),v(Ee.$$.fragment),Vt=m(),or=a("span"),Ht=h("Lowercase"),jr=m(),H=a("div"),v(ye.$$.fragment),Ut=m(),nr=a("p"),Mt=h("Lowercase Normalizer"),Gr=m(),U=a("h2"),pe=a("a"),sr=a("span"),v(Se.$$.fragment),Ot=m(),lr=a("span"),Wt=h("NFC"),Jr=m(),M=a("div"),v(Pe.$$.fragment),jt=m(),ir=a("p"),Gt=h("NFC Unicode Normalizer"),Qr=m(),O=a("h2"),fe=a("a"),mr=a("span"),v(Ae.$$.fragment),Jt=m(),cr=a("span"),Qt=h("NFD"),Xr=m(),W=a("div"),v(xe.$$.fragment),Xt=m(),pr=a("p"),Yt=h("NFD Unicode Normalizer"),Yr=m(),j=a("h2"),he=a("a"),fr=a("span"),v(De.$$.fragment),Zt=m(),hr=a("span"),ea=h("NFKC"),Zr=m(),G=a("div"),v(Fe.$$.fragment),ra=m(),dr=a("p"),ta=h("NFKC Unicode Normalizer"),et=m(),J=a("h2"),de=a("a"),ur=a("span"),v(Ie.$$.fragment),aa=m(),$r=a("span"),oa=h("NFKD"),rt=m(),Q=a("div"),v(Ce.$$.fragment),na=m(),vr=a("p"),sa=h("NFKD Unicode Normalizer"),tt=m(),X=a("h2"),ue=a("a"),zr=a("span"),v(Te.$$.fragment),la=m(),gr=a("span"),ia=h("Nmt"),at=m(),Y=a("div"),v(qe.$$.fragment),ma=m(),wr=a("p"),ca=h("Nmt normalizer"),ot=m(),Z=a("h2"),$e=a("a"),_r=a("span"),v(Be.$$.fragment),pa=m(),kr=a("span"),fa=h("Normalizer"),nt=m(),S=a("div"),v(Ke.$$.fragment),ha=m(),Nr=a("p"),da=h("Base class for all normalizers"),ua=m(),br=a("p"),$a=h(`This class is not supposed to be instantiated directly. Instead, any implementation of a
Normalizer will return an instance of this class when instantiated.`),va=m(),L=a("div"),v(Le.$$.fragment),za=m(),Re=a("p"),ga=h("Normalize a "),Er=a("code"),wa=h("NormalizedString"),_a=h(" in-place"),ka=m(),ve=a("p"),Na=h("This method allows to modify a "),yr=a("code"),ba=h("NormalizedString"),Ea=h(` to
keep track of the alignment information. If you just want to see the result
of the normalization on a raw string, you can use
`),Sr=a("code"),ya=h("normalize_str()"),Sa=m(),R=a("div"),v(Ve.$$.fragment),Pa=m(),Pr=a("p"),Aa=h("Normalize the given string"),xa=m(),ze=a("p"),Da=h(`This method provides a way to visualize the effect of a
`),Ze=a("a"),Fa=h("Normalizer"),Ia=h(` but it does not keep track of the alignment
information. If you need to get/convert offsets, you can use
`),Ar=a("code"),Ca=h("normalize()"),st=m(),ee=a("h2"),ge=a("a"),xr=a("span"),v(He.$$.fragment),Ta=m(),Dr=a("span"),qa=h("Precompiled"),lt=m(),re=a("div"),v(Ue.$$.fragment),Ba=m(),Fr=a("p"),Ka=h(`Precompiled normalizer
Don\u2019t use manually it is used for compatiblity for SentencePiece.`),it=m(),te=a("h2"),we=a("a"),Ir=a("span"),v(Me.$$.fragment),La=m(),Cr=a("span"),Ra=h("Replace"),mt=m(),ae=a("div"),v(Oe.$$.fragment),Va=m(),Tr=a("p"),Ha=h("Replace normalizer"),ct=m(),oe=a("h2"),_e=a("a"),qr=a("span"),v(We.$$.fragment),Ua=m(),Br=a("span"),Ma=h("Sequence"),pt=m(),ne=a("div"),v(je.$$.fragment),Oa=m(),Kr=a("p"),Wa=h(`Allows concatenating multiple other Normalizer as a Sequence.
All the normalizers run in sequence in the given order`),ft=m(),se=a("h2"),ke=a("a"),Lr=a("span"),v(Ge.$$.fragment),ja=m(),Rr=a("span"),Ga=h("Strip"),ht=m(),le=a("div"),v(Je.$$.fragment),Ja=m(),Vr=a("p"),Qa=h("Strip normalizer"),dt=m(),ie=a("h2"),Ne=a("a"),Hr=a("span"),v(Qe.$$.fragment),Xa=m(),Ur=a("span"),Ya=h("StripAccents"),ut=m(),me=a("div"),v(Xe.$$.fragment),Za=m(),Mr=a("p"),eo=h("StripAccents normalizer"),this.h()},l(e){i=o(e,"H2",{class:!0});var p=n(i);$=o(p,"A",{id:!0,class:!0,href:!0});var to=n($);l=o(to,"SPAN",{});var ao=n(l);z(u.$$.fragment,ao),ao.forEach(r),to.forEach(r),b=c(p),E=o(p,"SPAN",{});var oo=n(E);A=d(oo,"BertNormalizer"),oo.forEach(r),p.forEach(r),F=c(e),y=o(e,"DIV",{class:!0});var er=n(y);z(T.$$.fragment,er),q=c(er),K=o(er,"P",{});var no=n(K);N=d(no,"BertNormalizer"),no.forEach(r),x=c(er),I=o(er,"P",{});var so=n(I);Ye=d(so,`Takes care of normalizing raw text before giving it to a Bert model.
This includes cleaning the text, handling accents, chinese chars and lowercasing`),so.forEach(r),er.forEach(r),be=c(e),B=o(e,"H2",{class:!0});var vt=n(B);ce=o(vt,"A",{id:!0,class:!0,href:!0});var lo=n(ce);ar=o(lo,"SPAN",{});var io=n(ar);z(Ee.$$.fragment,io),io.forEach(r),lo.forEach(r),Vt=c(vt),or=o(vt,"SPAN",{});var mo=n(or);Ht=d(mo,"Lowercase"),mo.forEach(r),vt.forEach(r),jr=c(e),H=o(e,"DIV",{class:!0});var zt=n(H);z(ye.$$.fragment,zt),Ut=c(zt),nr=o(zt,"P",{});var co=n(nr);Mt=d(co,"Lowercase Normalizer"),co.forEach(r),zt.forEach(r),Gr=c(e),U=o(e,"H2",{class:!0});var gt=n(U);pe=o(gt,"A",{id:!0,class:!0,href:!0});var po=n(pe);sr=o(po,"SPAN",{});var fo=n(sr);z(Se.$$.fragment,fo),fo.forEach(r),po.forEach(r),Ot=c(gt),lr=o(gt,"SPAN",{});var ho=n(lr);Wt=d(ho,"NFC"),ho.forEach(r),gt.forEach(r),Jr=c(e),M=o(e,"DIV",{class:!0});var wt=n(M);z(Pe.$$.fragment,wt),jt=c(wt),ir=o(wt,"P",{});var uo=n(ir);Gt=d(uo,"NFC Unicode Normalizer"),uo.forEach(r),wt.forEach(r),Qr=c(e),O=o(e,"H2",{class:!0});var _t=n(O);fe=o(_t,"A",{id:!0,class:!0,href:!0});var $o=n(fe);mr=o($o,"SPAN",{});var vo=n(mr);z(Ae.$$.fragment,vo),vo.forEach(r),$o.forEach(r),Jt=c(_t),cr=o(_t,"SPAN",{});var zo=n(cr);Qt=d(zo,"NFD"),zo.forEach(r),_t.forEach(r),Xr=c(e),W=o(e,"DIV",{class:!0});var kt=n(W);z(xe.$$.fragment,kt),Xt=c(kt),pr=o(kt,"P",{});var go=n(pr);Yt=d(go,"NFD Unicode Normalizer"),go.forEach(r),kt.forEach(r),Yr=c(e),j=o(e,"H2",{class:!0});var Nt=n(j);he=o(Nt,"A",{id:!0,class:!0,href:!0});var wo=n(he);fr=o(wo,"SPAN",{});var _o=n(fr);z(De.$$.fragment,_o),_o.forEach(r),wo.forEach(r),Zt=c(Nt),hr=o(Nt,"SPAN",{});var ko=n(hr);ea=d(ko,"NFKC"),ko.forEach(r),Nt.forEach(r),Zr=c(e),G=o(e,"DIV",{class:!0});var bt=n(G);z(Fe.$$.fragment,bt),ra=c(bt),dr=o(bt,"P",{});var No=n(dr);ta=d(No,"NFKC Unicode Normalizer"),No.forEach(r),bt.forEach(r),et=c(e),J=o(e,"H2",{class:!0});var Et=n(J);de=o(Et,"A",{id:!0,class:!0,href:!0});var bo=n(de);ur=o(bo,"SPAN",{});var Eo=n(ur);z(Ie.$$.fragment,Eo),Eo.forEach(r),bo.forEach(r),aa=c(Et),$r=o(Et,"SPAN",{});var yo=n($r);oa=d(yo,"NFKD"),yo.forEach(r),Et.forEach(r),rt=c(e),Q=o(e,"DIV",{class:!0});var yt=n(Q);z(Ce.$$.fragment,yt),na=c(yt),vr=o(yt,"P",{});var So=n(vr);sa=d(So,"NFKD Unicode Normalizer"),So.forEach(r),yt.forEach(r),tt=c(e),X=o(e,"H2",{class:!0});var St=n(X);ue=o(St,"A",{id:!0,class:!0,href:!0});var Po=n(ue);zr=o(Po,"SPAN",{});var Ao=n(zr);z(Te.$$.fragment,Ao),Ao.forEach(r),Po.forEach(r),la=c(St),gr=o(St,"SPAN",{});var xo=n(gr);ia=d(xo,"Nmt"),xo.forEach(r),St.forEach(r),at=c(e),Y=o(e,"DIV",{class:!0});var Pt=n(Y);z(qe.$$.fragment,Pt),ma=c(Pt),wr=o(Pt,"P",{});var Do=n(wr);ca=d(Do,"Nmt normalizer"),Do.forEach(r),Pt.forEach(r),ot=c(e),Z=o(e,"H2",{class:!0});var At=n(Z);$e=o(At,"A",{id:!0,class:!0,href:!0});var Fo=n($e);_r=o(Fo,"SPAN",{});var Io=n(_r);z(Be.$$.fragment,Io),Io.forEach(r),Fo.forEach(r),pa=c(At),kr=o(At,"SPAN",{});var Co=n(kr);fa=d(Co,"Normalizer"),Co.forEach(r),At.forEach(r),nt=c(e),S=o(e,"DIV",{class:!0});var V=n(S);z(Ke.$$.fragment,V),ha=c(V),Nr=o(V,"P",{});var To=n(Nr);da=d(To,"Base class for all normalizers"),To.forEach(r),ua=c(V),br=o(V,"P",{});var qo=n(br);$a=d(qo,`This class is not supposed to be instantiated directly. Instead, any implementation of a
Normalizer will return an instance of this class when instantiated.`),qo.forEach(r),va=c(V),L=o(V,"DIV",{class:!0});var rr=n(L);z(Le.$$.fragment,rr),za=c(rr),Re=o(rr,"P",{});var xt=n(Re);ga=d(xt,"Normalize a "),Er=o(xt,"CODE",{});var Bo=n(Er);wa=d(Bo,"NormalizedString"),Bo.forEach(r),_a=d(xt," in-place"),xt.forEach(r),ka=c(rr),ve=o(rr,"P",{});var Or=n(ve);Na=d(Or,"This method allows to modify a "),yr=o(Or,"CODE",{});var Ko=n(yr);ba=d(Ko,"NormalizedString"),Ko.forEach(r),Ea=d(Or,` to
keep track of the alignment information. If you just want to see the result
of the normalization on a raw string, you can use
`),Sr=o(Or,"CODE",{});var Lo=n(Sr);ya=d(Lo,"normalize_str()"),Lo.forEach(r),Or.forEach(r),rr.forEach(r),Sa=c(V),R=o(V,"DIV",{class:!0});var tr=n(R);z(Ve.$$.fragment,tr),Pa=c(tr),Pr=o(tr,"P",{});var Ro=n(Pr);Aa=d(Ro,"Normalize the given string"),Ro.forEach(r),xa=c(tr),ze=o(tr,"P",{});var Wr=n(ze);Da=d(Wr,`This method provides a way to visualize the effect of a
`),Ze=o(Wr,"A",{href:!0});var Vo=n(Ze);Fa=d(Vo,"Normalizer"),Vo.forEach(r),Ia=d(Wr,` but it does not keep track of the alignment
information. If you need to get/convert offsets, you can use
`),Ar=o(Wr,"CODE",{});var Ho=n(Ar);Ca=d(Ho,"normalize()"),Ho.forEach(r),Wr.forEach(r),tr.forEach(r),V.forEach(r),st=c(e),ee=o(e,"H2",{class:!0});var Dt=n(ee);ge=o(Dt,"A",{id:!0,class:!0,href:!0});var Uo=n(ge);xr=o(Uo,"SPAN",{});var Mo=n(xr);z(He.$$.fragment,Mo),Mo.forEach(r),Uo.forEach(r),Ta=c(Dt),Dr=o(Dt,"SPAN",{});var Oo=n(Dr);qa=d(Oo,"Precompiled"),Oo.forEach(r),Dt.forEach(r),lt=c(e),re=o(e,"DIV",{class:!0});var Ft=n(re);z(Ue.$$.fragment,Ft),Ba=c(Ft),Fr=o(Ft,"P",{});var Wo=n(Fr);Ka=d(Wo,`Precompiled normalizer
Don\u2019t use manually it is used for compatiblity for SentencePiece.`),Wo.forEach(r),Ft.forEach(r),it=c(e),te=o(e,"H2",{class:!0});var It=n(te);we=o(It,"A",{id:!0,class:!0,href:!0});var jo=n(we);Ir=o(jo,"SPAN",{});var Go=n(Ir);z(Me.$$.fragment,Go),Go.forEach(r),jo.forEach(r),La=c(It),Cr=o(It,"SPAN",{});var Jo=n(Cr);Ra=d(Jo,"Replace"),Jo.forEach(r),It.forEach(r),mt=c(e),ae=o(e,"DIV",{class:!0});var Ct=n(ae);z(Oe.$$.fragment,Ct),Va=c(Ct),Tr=o(Ct,"P",{});var Qo=n(Tr);Ha=d(Qo,"Replace normalizer"),Qo.forEach(r),Ct.forEach(r),ct=c(e),oe=o(e,"H2",{class:!0});var Tt=n(oe);_e=o(Tt,"A",{id:!0,class:!0,href:!0});var Xo=n(_e);qr=o(Xo,"SPAN",{});var Yo=n(qr);z(We.$$.fragment,Yo),Yo.forEach(r),Xo.forEach(r),Ua=c(Tt),Br=o(Tt,"SPAN",{});var Zo=n(Br);Ma=d(Zo,"Sequence"),Zo.forEach(r),Tt.forEach(r),pt=c(e),ne=o(e,"DIV",{class:!0});var qt=n(ne);z(je.$$.fragment,qt),Oa=c(qt),Kr=o(qt,"P",{});var en=n(Kr);Wa=d(en,`Allows concatenating multiple other Normalizer as a Sequence.
All the normalizers run in sequence in the given order`),en.forEach(r),qt.forEach(r),ft=c(e),se=o(e,"H2",{class:!0});var Bt=n(se);ke=o(Bt,"A",{id:!0,class:!0,href:!0});var rn=n(ke);Lr=o(rn,"SPAN",{});var tn=n(Lr);z(Ge.$$.fragment,tn),tn.forEach(r),rn.forEach(r),ja=c(Bt),Rr=o(Bt,"SPAN",{});var an=n(Rr);Ga=d(an,"Strip"),an.forEach(r),Bt.forEach(r),ht=c(e),le=o(e,"DIV",{class:!0});var Kt=n(le);z(Je.$$.fragment,Kt),Ja=c(Kt),Vr=o(Kt,"P",{});var on=n(Vr);Qa=d(on,"Strip normalizer"),on.forEach(r),Kt.forEach(r),dt=c(e),ie=o(e,"H2",{class:!0});var Lt=n(ie);Ne=o(Lt,"A",{id:!0,class:!0,href:!0});var nn=n(Ne);Hr=o(nn,"SPAN",{});var sn=n(Hr);z(Qe.$$.fragment,sn),sn.forEach(r),nn.forEach(r),Xa=c(Lt),Ur=o(Lt,"SPAN",{});var ln=n(Ur);Ya=d(ln,"StripAccents"),ln.forEach(r),Lt.forEach(r),ut=c(e),me=o(e,"DIV",{class:!0});var Rt=n(me);z(Xe.$$.fragment,Rt),Za=c(Rt),Mr=o(Rt,"P",{});var mn=n(Mr);eo=d(mn,"StripAccents normalizer"),mn.forEach(r),Rt.forEach(r),this.h()},h(){s($,"id","tokenizers.normalizers.BertNormalizer"),s($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s($,"href","#tokenizers.normalizers.BertNormalizer"),s(i,"class","relative group"),s(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(ce,"id","tokenizers.normalizers.Lowercase"),s(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ce,"href","#tokenizers.normalizers.Lowercase"),s(B,"class","relative group"),s(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(pe,"id","tokenizers.normalizers.NFC"),s(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(pe,"href","#tokenizers.normalizers.NFC"),s(U,"class","relative group"),s(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(fe,"id","tokenizers.normalizers.NFD"),s(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(fe,"href","#tokenizers.normalizers.NFD"),s(O,"class","relative group"),s(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(he,"id","tokenizers.normalizers.NFKC"),s(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(he,"href","#tokenizers.normalizers.NFKC"),s(j,"class","relative group"),s(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(de,"id","tokenizers.normalizers.NFKD"),s(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(de,"href","#tokenizers.normalizers.NFKD"),s(J,"class","relative group"),s(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(ue,"id","tokenizers.normalizers.Nmt"),s(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ue,"href","#tokenizers.normalizers.Nmt"),s(X,"class","relative group"),s(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s($e,"id","tokenizers.normalizers.Normalizer"),s($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s($e,"href","#tokenizers.normalizers.Normalizer"),s(Z,"class","relative group"),s(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(Ze,"href","/docs/tokenizers/v0.13.2/en/api/normalizers#tokenizers.normalizers.Normalizer"),s(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(ge,"id","tokenizers.normalizers.Precompiled"),s(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ge,"href","#tokenizers.normalizers.Precompiled"),s(ee,"class","relative group"),s(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(we,"id","tokenizers.normalizers.Replace"),s(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(we,"href","#tokenizers.normalizers.Replace"),s(te,"class","relative group"),s(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(_e,"id","tokenizers.normalizers.Sequence"),s(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(_e,"href","#tokenizers.normalizers.Sequence"),s(oe,"class","relative group"),s(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(ke,"id","tokenizers.normalizers.Strip"),s(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ke,"href","#tokenizers.normalizers.Strip"),s(se,"class","relative group"),s(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),s(Ne,"id","tokenizers.normalizers.StripAccents"),s(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ne,"href","#tokenizers.normalizers.StripAccents"),s(ie,"class","relative group"),s(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,p){f(e,i,p),t(i,$),t($,l),g(u,l,null),t(i,b),t(i,E),t(E,A),f(e,F,p),f(e,y,p),g(T,y,null),t(y,q),t(y,K),t(K,N),t(y,x),t(y,I),t(I,Ye),f(e,be,p),f(e,B,p),t(B,ce),t(ce,ar),g(Ee,ar,null),t(B,Vt),t(B,or),t(or,Ht),f(e,jr,p),f(e,H,p),g(ye,H,null),t(H,Ut),t(H,nr),t(nr,Mt),f(e,Gr,p),f(e,U,p),t(U,pe),t(pe,sr),g(Se,sr,null),t(U,Ot),t(U,lr),t(lr,Wt),f(e,Jr,p),f(e,M,p),g(Pe,M,null),t(M,jt),t(M,ir),t(ir,Gt),f(e,Qr,p),f(e,O,p),t(O,fe),t(fe,mr),g(Ae,mr,null),t(O,Jt),t(O,cr),t(cr,Qt),f(e,Xr,p),f(e,W,p),g(xe,W,null),t(W,Xt),t(W,pr),t(pr,Yt),f(e,Yr,p),f(e,j,p),t(j,he),t(he,fr),g(De,fr,null),t(j,Zt),t(j,hr),t(hr,ea),f(e,Zr,p),f(e,G,p),g(Fe,G,null),t(G,ra),t(G,dr),t(dr,ta),f(e,et,p),f(e,J,p),t(J,de),t(de,ur),g(Ie,ur,null),t(J,aa),t(J,$r),t($r,oa),f(e,rt,p),f(e,Q,p),g(Ce,Q,null),t(Q,na),t(Q,vr),t(vr,sa),f(e,tt,p),f(e,X,p),t(X,ue),t(ue,zr),g(Te,zr,null),t(X,la),t(X,gr),t(gr,ia),f(e,at,p),f(e,Y,p),g(qe,Y,null),t(Y,ma),t(Y,wr),t(wr,ca),f(e,ot,p),f(e,Z,p),t(Z,$e),t($e,_r),g(Be,_r,null),t(Z,pa),t(Z,kr),t(kr,fa),f(e,nt,p),f(e,S,p),g(Ke,S,null),t(S,ha),t(S,Nr),t(Nr,da),t(S,ua),t(S,br),t(br,$a),t(S,va),t(S,L),g(Le,L,null),t(L,za),t(L,Re),t(Re,ga),t(Re,Er),t(Er,wa),t(Re,_a),t(L,ka),t(L,ve),t(ve,Na),t(ve,yr),t(yr,ba),t(ve,Ea),t(ve,Sr),t(Sr,ya),t(S,Sa),t(S,R),g(Ve,R,null),t(R,Pa),t(R,Pr),t(Pr,Aa),t(R,xa),t(R,ze),t(ze,Da),t(ze,Ze),t(Ze,Fa),t(ze,Ia),t(ze,Ar),t(Ar,Ca),f(e,st,p),f(e,ee,p),t(ee,ge),t(ge,xr),g(He,xr,null),t(ee,Ta),t(ee,Dr),t(Dr,qa),f(e,lt,p),f(e,re,p),g(Ue,re,null),t(re,Ba),t(re,Fr),t(Fr,Ka),f(e,it,p),f(e,te,p),t(te,we),t(we,Ir),g(Me,Ir,null),t(te,La),t(te,Cr),t(Cr,Ra),f(e,mt,p),f(e,ae,p),g(Oe,ae,null),t(ae,Va),t(ae,Tr),t(Tr,Ha),f(e,ct,p),f(e,oe,p),t(oe,_e),t(_e,qr),g(We,qr,null),t(oe,Ua),t(oe,Br),t(Br,Ma),f(e,pt,p),f(e,ne,p),g(je,ne,null),t(ne,Oa),t(ne,Kr),t(Kr,Wa),f(e,ft,p),f(e,se,p),t(se,ke),t(ke,Lr),g(Ge,Lr,null),t(se,ja),t(se,Rr),t(Rr,Ga),f(e,ht,p),f(e,le,p),g(Je,le,null),t(le,Ja),t(le,Vr),t(Vr,Qa),f(e,dt,p),f(e,ie,p),t(ie,Ne),t(Ne,Hr),g(Qe,Hr,null),t(ie,Xa),t(ie,Ur),t(Ur,Ya),f(e,ut,p),f(e,me,p),g(Xe,me,null),t(me,Za),t(me,Mr),t(Mr,eo),$t=!0},p:un,i(e){$t||(w(u.$$.fragment,e),w(T.$$.fragment,e),w(Ee.$$.fragment,e),w(ye.$$.fragment,e),w(Se.$$.fragment,e),w(Pe.$$.fragment,e),w(Ae.$$.fragment,e),w(xe.$$.fragment,e),w(De.$$.fragment,e),w(Fe.$$.fragment,e),w(Ie.$$.fragment,e),w(Ce.$$.fragment,e),w(Te.$$.fragment,e),w(qe.$$.fragment,e),w(Be.$$.fragment,e),w(Ke.$$.fragment,e),w(Le.$$.fragment,e),w(Ve.$$.fragment,e),w(He.$$.fragment,e),w(Ue.$$.fragment,e),w(Me.$$.fragment,e),w(Oe.$$.fragment,e),w(We.$$.fragment,e),w(je.$$.fragment,e),w(Ge.$$.fragment,e),w(Je.$$.fragment,e),w(Qe.$$.fragment,e),w(Xe.$$.fragment,e),$t=!0)},o(e){_(u.$$.fragment,e),_(T.$$.fragment,e),_(Ee.$$.fragment,e),_(ye.$$.fragment,e),_(Se.$$.fragment,e),_(Pe.$$.fragment,e),_(Ae.$$.fragment,e),_(xe.$$.fragment,e),_(De.$$.fragment,e),_(Fe.$$.fragment,e),_(Ie.$$.fragment,e),_(Ce.$$.fragment,e),_(Te.$$.fragment,e),_(qe.$$.fragment,e),_(Be.$$.fragment,e),_(Ke.$$.fragment,e),_(Le.$$.fragment,e),_(Ve.$$.fragment,e),_(He.$$.fragment,e),_(Ue.$$.fragment,e),_(Me.$$.fragment,e),_(Oe.$$.fragment,e),_(We.$$.fragment,e),_(je.$$.fragment,e),_(Ge.$$.fragment,e),_(Je.$$.fragment,e),_(Qe.$$.fragment,e),_(Xe.$$.fragment,e),$t=!1},d(e){e&&r(i),k(u),e&&r(F),e&&r(y),k(T),e&&r(be),e&&r(B),k(Ee),e&&r(jr),e&&r(H),k(ye),e&&r(Gr),e&&r(U),k(Se),e&&r(Jr),e&&r(M),k(Pe),e&&r(Qr),e&&r(O),k(Ae),e&&r(Xr),e&&r(W),k(xe),e&&r(Yr),e&&r(j),k(De),e&&r(Zr),e&&r(G),k(Fe),e&&r(et),e&&r(J),k(Ie),e&&r(rt),e&&r(Q),k(Ce),e&&r(tt),e&&r(X),k(Te),e&&r(at),e&&r(Y),k(qe),e&&r(ot),e&&r(Z),k(Be),e&&r(nt),e&&r(S),k(Ke),k(Le),k(Ve),e&&r(st),e&&r(ee),k(He),e&&r(lt),e&&r(re),k(Ue),e&&r(it),e&&r(te),k(Me),e&&r(mt),e&&r(ae),k(Oe),e&&r(ct),e&&r(oe),k(We),e&&r(pt),e&&r(ne),k(je),e&&r(ft),e&&r(se),k(Ge),e&&r(ht),e&&r(le),k(Je),e&&r(dt),e&&r(ie),k(Qe),e&&r(ut),e&&r(me),k(Xe)}}}function zn(C){let i,$;return i=new ro({props:{$$slots:{default:[vn]},$$scope:{ctx:C}}}),{c(){v(i.$$.fragment)},l(l){z(i.$$.fragment,l)},m(l,u){g(i,l,u),$=!0},p(l,u){const b={};u&2&&(b.$$scope={dirty:u,ctx:l}),i.$set(b)},i(l){$||(w(i.$$.fragment,l),$=!0)},o(l){_(i.$$.fragment,l),$=!1},d(l){k(i,l)}}}function gn(C){let i,$,l,u,b;return{c(){i=a("p"),$=h("The Rust API Reference is available directly on the "),l=a("a"),u=h("Docs.rs"),b=h(" website."),this.h()},l(E){i=o(E,"P",{});var A=n(i);$=d(A,"The Rust API Reference is available directly on the "),l=o(A,"A",{href:!0,rel:!0});var F=n(l);u=d(F,"Docs.rs"),F.forEach(r),b=d(A," website."),A.forEach(r),this.h()},h(){s(l,"href","https://docs.rs/tokenizers/latest/tokenizers/"),s(l,"rel","nofollow")},m(E,A){f(E,i,A),t(i,$),t(i,l),t(l,u),t(i,b)},d(E){E&&r(i)}}}function wn(C){let i,$;return i=new ro({props:{$$slots:{default:[gn]},$$scope:{ctx:C}}}),{c(){v(i.$$.fragment)},l(l){z(i.$$.fragment,l)},m(l,u){g(i,l,u),$=!0},p(l,u){const b={};u&2&&(b.$$scope={dirty:u,ctx:l}),i.$set(b)},i(l){$||(w(i.$$.fragment,l),$=!0)},o(l){_(i.$$.fragment,l),$=!1},d(l){k(i,l)}}}function _n(C){let i,$;return{c(){i=a("p"),$=h("The node API has not been documented yet.")},l(l){i=o(l,"P",{});var u=n(i);$=d(u,"The node API has not been documented yet."),u.forEach(r)},m(l,u){f(l,i,u),t(i,$)},d(l){l&&r(i)}}}function kn(C){let i,$;return i=new ro({props:{$$slots:{default:[_n]},$$scope:{ctx:C}}}),{c(){v(i.$$.fragment)},l(l){z(i.$$.fragment,l)},m(l,u){g(i,l,u),$=!0},p(l,u){const b={};u&2&&(b.$$scope={dirty:u,ctx:l}),i.$set(b)},i(l){$||(w(i.$$.fragment,l),$=!0)},o(l){_(i.$$.fragment,l),$=!1},d(l){k(i,l)}}}function Nn(C){let i,$,l,u,b,E,A,F,y,T,q,K;return E=new D({}),q=new $n({props:{python:!0,rust:!0,node:!0,$$slots:{node:[kn],rust:[wn],python:[zn]},$$scope:{ctx:C}}}),{c(){i=a("meta"),$=m(),l=a("h1"),u=a("a"),b=a("span"),v(E.$$.fragment),A=m(),F=a("span"),y=h("Normalizers"),T=m(),v(q.$$.fragment),this.h()},l(N){const x=hn('[data-svelte="svelte-1phssyn"]',document.head);i=o(x,"META",{name:!0,content:!0}),x.forEach(r),$=c(N),l=o(N,"H1",{class:!0});var I=n(l);u=o(I,"A",{id:!0,class:!0,href:!0});var Ye=n(u);b=o(Ye,"SPAN",{});var be=n(b);z(E.$$.fragment,be),be.forEach(r),Ye.forEach(r),A=c(I),F=o(I,"SPAN",{});var B=n(F);y=d(B,"Normalizers"),B.forEach(r),I.forEach(r),T=c(N),z(q.$$.fragment,N),this.h()},h(){s(i,"name","hf:doc:metadata"),s(i,"content",JSON.stringify(bn)),s(u,"id","normalizers"),s(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(u,"href","#normalizers"),s(l,"class","relative group")},m(N,x){t(document.head,i),f(N,$,x),f(N,l,x),t(l,u),t(u,b),g(E,b,null),t(l,A),t(l,F),t(F,y),f(N,T,x),g(q,N,x),K=!0},p(N,[x]){const I={};x&2&&(I.$$scope={dirty:x,ctx:N}),q.$set(I)},i(N){K||(w(E.$$.fragment,N),w(q.$$.fragment,N),K=!0)},o(N){_(E.$$.fragment,N),_(q.$$.fragment,N),K=!1},d(N){r(i),N&&r($),N&&r(l),k(E),N&&r(T),k(q,N)}}}const bn={local:"normalizers",sections:[{local:"tokenizers.normalizers.BertNormalizer",title:"BertNormalizer"},{local:"tokenizers.normalizers.Lowercase",title:"Lowercase"},{local:"tokenizers.normalizers.NFC",title:"NFC"},{local:"tokenizers.normalizers.NFD",title:"NFD"},{local:"tokenizers.normalizers.NFKC",title:"NFKC"},{local:"tokenizers.normalizers.NFKD",title:"NFKD"},{local:"tokenizers.normalizers.Nmt",title:"Nmt"},{local:"tokenizers.normalizers.Normalizer",title:"Normalizer"},{local:"tokenizers.normalizers.Precompiled",title:"Precompiled"},{local:"tokenizers.normalizers.Replace",title:"Replace"},{local:"tokenizers.normalizers.Sequence",title:"Sequence"},{local:"tokenizers.normalizers.Strip",title:"Strip"},{local:"tokenizers.normalizers.StripAccents",title:"StripAccents"}],title:"Normalizers"};function En(C){return dn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xn extends cn{constructor(i){super();pn(this,i,En,Nn,fn,{})}}export{xn as default,bn as metadata};
